1. Dual Cross-Attention Learning for Fine-Grained Visual Categorization and Object Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Dual_Cross-Attention_Learning_for_Fine-Grained_Visual_Categorization_and_Object_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Dual_Cross-Attention_Learning_for_Fine-Grained_Visual_Categorization_and_Object_Re-Identification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Dual_Cross-Attention_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.02151)
2. SimAN- Exploring Self-Supervised Representation Learning of Scene Text via Similarity-Aware Normalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Luo_SimAN_Exploring_Self-Supervised_Representation_Learning_of_Scene_Text_via_Similarity-Aware_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_SimAN_Exploring_Self-Supervised_Representation_Learning_of_Scene_Text_via_Similarity-Aware_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Luo_SimAN_Exploring_Self-Supervised_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10492)
3. Weakly Supervised Semantic Segmentation by Pixel-to-Prototype Contrast | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Du_Weakly_Supervised_Semantic_Segmentation_by_Pixel-to-Prototype_Contrast_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Weakly_Supervised_Semantic_Segmentation_by_Pixel-to-Prototype_Contrast_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2110.07110)
4. Controllable Animation of Fluid Elements in Still Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mahapatra_Controllable_Animation_of_Fluid_Elements_in_Still_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mahapatra_Controllable_Animation_of_Fluid_Elements_in_Still_Images_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.03051)
5. Recurrent Dynamic Embedding for Video Object Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Recurrent_Dynamic_Embedding_for_Video_Object_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Recurrent_Dynamic_Embedding_for_Video_Object_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Recurrent_Dynamic_Embedding_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.03761)
6. Deep Hierarchical Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Deep_Hierarchical_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Deep_Hierarchical_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Deep_Hierarchical_Semantic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14335)
7. f-SfT- Shape-From-Template With a Physics-Based Deformation Model | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kairanda_f-SfT_Shape-From-Template_With_a_Physics-Based_Deformation_Model_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kairanda_f-SfT_Shape-From-Template_With_a_Physics-Based_Deformation_Model_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kairanda_f-SfT_Shape-From-Template_With_CVPR_2022_supplemental.pdf)
8. TWIST- Two-Way Inter-Label Self-Training for Semi-Supervised 3D Instance Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chu_TWIST_Two-Way_Inter-Label_Self-Training_for_Semi-Supervised_3D_Instance_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chu_TWIST_Two-Way_Inter-Label_Self-Training_for_Semi-Supervised_3D_Instance_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chu_TWIST_Two-Way_Inter-Label_CVPR_2022_supplemental.pdf)
9. Do Learned Representations Respect Causal Relationships- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Do_Learned_Representations_Respect_Causal_Relationships_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Do_Learned_Representations_Respect_Causal_Relationships_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Do_Learned_Representations_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00762)
10. Multi-Class Token Transformer for Weakly Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Multi-Class_Token_Transformer_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Multi-Class_Token_Transformer_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Multi-Class_Token_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02891)
11. 3D Moments From Near-Duplicate Photos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_3D_Moments_From_Near-Duplicate_Photos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_3D_Moments_From_Near-Duplicate_Photos_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.06255)
12. Blind2Unblind- Self-Supervised Image Denoising With Visible Blind Spots | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Blind2Unblind_Self-Supervised_Image_Denoising_With_Visible_Blind_Spots_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Blind2Unblind_Self-Supervised_Image_Denoising_With_Visible_Blind_Spots_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Blind2Unblind_Self-Supervised_Image_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06967)
13. CLRNet- Cross Layer Refinement Network for Lane Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_CLRNet_Cross_Layer_Refinement_Network_for_Lane_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_CLRNet_Cross_Layer_Refinement_Network_for_Lane_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_CLRNet_Cross_Layer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10350)
14. Pointly-Supervised Instance Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Pointly-Supervised_Instance_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Pointly-Supervised_Instance_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cheng_Pointly-Supervised_Instance_Segmentation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.06404)
15. LGT-Net- Indoor Panoramic Room Layout Estimation With Geometry-Aware Transformer Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_LGT-Net_Indoor_Panoramic_Room_Layout_Estimation_With_Geometry-Aware_Transformer_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_LGT-Net_Indoor_Panoramic_Room_Layout_Estimation_With_Geometry-Aware_Transformer_Network_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jiang_LGT-Net_Indoor_Panoramic_CVPR_2022_supplemental.pdf)
16. Sparse Local Patch Transformer for Robust Face Alignment and Landmarks Inherent Relation Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xia_Sparse_Local_Patch_Transformer_for_Robust_Face_Alignment_and_Landmarks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Sparse_Local_Patch_Transformer_for_Robust_Face_Alignment_and_Landmarks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xia_Sparse_Local_Patch_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06541)
17. Rotationally Equivariant 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Rotationally_Equivariant_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Rotationally_Equivariant_3D_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_Rotationally_Equivariant_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.13630)
18. Accelerating DETR Convergence via Semantic-Aligned Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Accelerating_DETR_Convergence_via_Semantic-Aligned_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Accelerating_DETR_Convergence_via_Semantic-Aligned_Matching_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Accelerating_DETR_Convergence_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06883)
19. Vision Transformer With Deformable Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xia_Vision_Transformer_With_Deformable_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Vision_Transformer_With_Deformable_Attention_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xia_Vision_Transformer_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.00520)
20. RM-Depth- Unsupervised Learning of Recurrent Monocular Depth in Dynamic Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hui_RM-Depth_Unsupervised_Learning_of_Recurrent_Monocular_Depth_in_Dynamic_Scenes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hui_RM-Depth_Unsupervised_Learning_of_Recurrent_Monocular_Depth_in_Dynamic_Scenes_CVPR_2022_paper.pdf)
21. Cloning Outfits From Real-World Images to 3D Characters for Generalizable Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Cloning_Outfits_From_Real-World_Images_to_3D_Characters_for_Generalizable_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Cloning_Outfits_From_Real-World_Images_to_3D_Characters_for_Generalizable_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Cloning_Outfits_From_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02611)
22. ABPN- Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lei_ABPN_Adaptive_Blend_Pyramid_Network_for_Real-Time_Local_Retouching_of_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_ABPN_Adaptive_Blend_Pyramid_Network_for_Real-Time_Local_Retouching_of_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lei_ABPN_Adaptive_Blend_CVPR_2022_supplemental.pdf)
23. Portrait Eyeglasses and Shadow Removal by Leveraging 3D Synthetic Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lyu_Portrait_Eyeglasses_and_Shadow_Removal_by_Leveraging_3D_Synthetic_Data_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lyu_Portrait_Eyeglasses_and_Shadow_Removal_by_Leveraging_3D_Synthetic_Data_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lyu_Portrait_Eyeglasses_and_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.10474)
24. Open-World Instance Segmentation- Exploiting Pseudo Ground Truth From Learned Pairwise Affinity | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Open-World_Instance_Segmentation_Exploiting_Pseudo_Ground_Truth_From_Learned_Pairwise_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Open-World_Instance_Segmentation_Exploiting_Pseudo_Ground_Truth_From_Learned_Pairwise_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Open-World_Instance_Segmentation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.06107)
25. HandOccNet- Occlusion-Robust 3D Hand Mesh Estimation Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Park_HandOccNet_Occlusion-Robust_3D_Hand_Mesh_Estimation_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_HandOccNet_Occlusion-Robust_3D_Hand_Mesh_Estimation_Network_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Park_HandOccNet_Occlusion-Robust_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14564)
26. Modular Action Concept Grounding in Semantic Video Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Modular_Action_Concept_Grounding_in_Semantic_Video_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Modular_Action_Concept_Grounding_in_Semantic_Video_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_Modular_Action_Concept_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2011.11201)
27. Sub-Word Level Lip Reading With Visual Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Prajwal_Sub-Word_Level_Lip_Reading_With_Visual_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Prajwal_Sub-Word_Level_Lip_Reading_With_Visual_Attention_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2110.07603)
28. Weakly Supervised High-Fidelity Clothing Model Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Weakly_Supervised_High-Fidelity_Clothing_Model_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Weakly_Supervised_High-Fidelity_Clothing_Model_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Feng_Weakly_Supervised_High-Fidelity_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.07200)
29. Knowledge Mining With Scene Text for Fine-Grained Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Knowledge_Mining_With_Scene_Text_for_Fine-Grained_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Knowledge_Mining_With_Scene_Text_for_Fine-Grained_Recognition_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.14215)
30. TransGeo- Transformer Is All You Need for Cross-View Image Geo-Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_TransGeo_Transformer_Is_All_You_Need_for_Cross-View_Image_Geo-Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_TransGeo_Transformer_Is_All_You_Need_for_Cross-View_Image_Geo-Localization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_TransGeo_Transformer_Is_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00097)
31. R(Det)2- Randomized Decision Routing for Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_RDet2_Randomized_Decision_Routing_for_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_RDet2_Randomized_Decision_Routing_for_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_RDet2_Randomized_Decision_CVPR_2022_supplemental.pdf)
32. SASIC- Stereo Image Compression With Latent Shifts and Stereo Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wodlinger_SASIC_Stereo_Image_Compression_With_Latent_Shifts_and_Stereo_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wodlinger_SASIC_Stereo_Image_Compression_With_Latent_Shifts_and_Stereo_Attention_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wodlinger_SASIC_Stereo_Image_CVPR_2022_supplemental.pdf)
33. CVNet- Contour Vibration Network for Building Extraction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_CVNet_Contour_Vibration_Network_for_Building_Extraction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_CVNet_Contour_Vibration_Network_for_Building_Extraction_CVPR_2022_paper.pdf)
34. Hyperbolic Image Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Atigh_Hyperbolic_Image_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Atigh_Hyperbolic_Image_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Atigh_Hyperbolic_Image_Segmentation_CVPR_2022_supplemental.pdf)
35. CLIMS- Cross Language Image Matching for Weakly Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_CLIMS_Cross_Language_Image_Matching_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_CLIMS_Cross_Language_Image_Matching_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xie_CLIMS_Cross_Language_CVPR_2022_supplemental.pdf)
36. TransRank- Self-Supervised Video Representation Learning via Ranking-Based Transformation Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Duan_TransRank_Self-Supervised_Video_Representation_Learning_via_Ranking-Based_Transformation_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_TransRank_Self-Supervised_Video_Representation_Learning_via_Ranking-Based_Transformation_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Duan_TransRank_Self-Supervised_Video_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.02028)
37. Invariant Grounding for Video Question Answering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Invariant_Grounding_for_Video_Question_Answering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Invariant_Grounding_for_Video_Question_Answering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Invariant_Grounding_for_CVPR_2022_supplemental.pdf)
38. Prompt Distribution Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Prompt_Distribution_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Prompt_Distribution_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lu_Prompt_Distribution_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.03340)
39. Temporal Alignment Networks for Long-Term Video | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Han_Temporal_Alignment_Networks_for_Long-Term_Video_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Temporal_Alignment_Networks_for_Long-Term_Video_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Han_Temporal_Alignment_Networks_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.02968)
40. LAR-SR- A Local Autoregressive Model for Image Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_LAR-SR_A_Local_Autoregressive_Model_for_Image_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_LAR-SR_A_Local_Autoregressive_Model_for_Image_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_LAR-SR_A_Local_CVPR_2022_supplemental.pdf)
41. Democracy Does Matter- Comprehensive Feature Mining for Co-Salient Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Democracy_Does_Matter_Comprehensive_Feature_Mining_for_Co-Salient_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Democracy_Does_Matter_Comprehensive_Feature_Mining_for_Co-Salient_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_Democracy_Does_Matter_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05787)
42. Doodle It Yourself- Class Incremental Learning by Drawing a Few Sketches | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bhunia_Doodle_It_Yourself_Class_Incremental_Learning_by_Drawing_a_Few_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bhunia_Doodle_It_Yourself_Class_Incremental_Learning_by_Drawing_a_Few_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bhunia_Doodle_It_Yourself_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14843)
43. Self-Supervised Predictive Learning- A Negative-Free Method for Sound Source Localization in Visual Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Song_Self-Supervised_Predictive_Learning_A_Negative-Free_Method_for_Sound_Source_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Song_Self-Supervised_Predictive_Learning_A_Negative-Free_Method_for_Sound_Source_Localization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Song_Self-Supervised_Predictive_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13412)
44. Comparing Correspondences- Video Prediction With Correspondence-Wise Losses | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Geng_Comparing_Correspondences_Video_Prediction_With_Correspondence-Wise_Losses_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Geng_Comparing_Correspondences_Video_Prediction_With_Correspondence-Wise_Losses_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2104.09498)
45. Non-Iterative Recovery From Nonlinear Observations Using Generative Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Non-Iterative_Recovery_From_Nonlinear_Observations_Using_Generative_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Non-Iterative_Recovery_From_Nonlinear_Observations_Using_Generative_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Non-Iterative_Recovery_From_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2205.15749)
46. Partially Does It- Towards Scene-Level FG-SBIR With Partial Input | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chowdhury_Partially_Does_It_Towards_Scene-Level_FG-SBIR_With_Partial_Input_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chowdhury_Partially_Does_It_Towards_Scene-Level_FG-SBIR_With_Partial_Input_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chowdhury_Partially_Does_It_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14804)
47. Density-Preserving Deep Point Cloud Compression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_Density-Preserving_Deep_Point_Cloud_Compression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Density-Preserving_Deep_Point_Cloud_Compression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_Density-Preserving_Deep_Point_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.12684)
48. Fast and Unsupervised Action Boundary Detection for Action Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Du_Fast_and_Unsupervised_Action_Boundary_Detection_for_Action_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Fast_and_Unsupervised_Action_Boundary_Detection_for_Action_Segmentation_CVPR_2022_paper.pdf)
49. Robust Optimization As Data Augmentation for Large-Scale Graphs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kong_Robust_Optimization_As_Data_Augmentation_for_Large-Scale_Graphs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_Robust_Optimization_As_Data_Augmentation_for_Large-Scale_Graphs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kong_Robust_Optimization_As_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2010.09891)
50. 360MonoDepth- High-Resolution 360deg Monocular Depth Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rey-Area_360MonoDepth_High-Resolution_360deg_Monocular_Depth_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rey-Area_360MonoDepth_High-Resolution_360deg_Monocular_Depth_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rey-Area_360MonoDepth_High-Resolution_360deg_CVPR_2022_supplemental.pdf)
51. MUSE-VAE- Multi-Scale VAE for Environment-Aware Long Term Trajectory Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_MUSE-VAE_Multi-Scale_VAE_for_Environment-Aware_Long_Term_Trajectory_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_MUSE-VAE_Multi-Scale_VAE_for_Environment-Aware_Long_Term_Trajectory_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_MUSE-VAE_Multi-Scale_VAE_CVPR_2022_supplemental.pdf)
52. GazeOnce- Real-Time Multi-Person Gaze Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_GazeOnce_Real-Time_Multi-Person_Gaze_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_GazeOnce_Real-Time_Multi-Person_Gaze_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_GazeOnce_Real-Time_Multi-Person_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.09480)
53. Depth-Aware Generative Adversarial Network for Talking Head Video Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Depth-Aware_Generative_Adversarial_Network_for_Talking_Head_Video_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Depth-Aware_Generative_Adversarial_Network_for_Talking_Head_Video_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hong_Depth-Aware_Generative_Adversarial_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06605)
54. Clipped Hyperbolic Classifiers Are Super-Hyperbolic Classifiers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Clipped_Hyperbolic_Classifiers_Are_Super-Hyperbolic_Classifiers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Clipped_Hyperbolic_Classifiers_Are_Super-Hyperbolic_Classifiers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_Clipped_Hyperbolic_Classifiers_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2107.11472)
55. Implicit Feature Decoupling With Depthwise Quantization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fostiropoulos_Implicit_Feature_Decoupling_With_Depthwise_Quantization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fostiropoulos_Implicit_Feature_Decoupling_With_Depthwise_Quantization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fostiropoulos_Implicit_Feature_Decoupling_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08080)
56. Graph-Context Attention Networks for Size-Varied Deep Graph Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Graph-Context_Attention_Networks_for_Size-Varied_Deep_Graph_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Graph-Context_Attention_Networks_for_Size-Varied_Deep_Graph_Matching_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jiang_Graph-Context_Attention_Networks_CVPR_2022_supplemental.pdf)
57. Measuring Compositional Consistency for Video Question Answering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gandhi_Measuring_Compositional_Consistency_for_Video_Question_Answering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gandhi_Measuring_Compositional_Consistency_for_Video_Question_Answering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gandhi_Measuring_Compositional_Consistency_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07190)
58. Category Contrast for Unsupervised Domain Adaptation in Visual Tasks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Category_Contrast_for_Unsupervised_Domain_Adaptation_in_Visual_Tasks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Category_Contrast_for_Unsupervised_Domain_Adaptation_in_Visual_Tasks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Category_Contrast_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.02885)
59. SwapMix- Diagnosing and Regularizing the Over-Reliance on Visual Context in Visual Question Answering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gupta_SwapMix_Diagnosing_and_Regularizing_the_Over-Reliance_on_Visual_Context_in_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gupta_SwapMix_Diagnosing_and_Regularizing_the_Over-Reliance_on_Visual_Context_in_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.02285)
60. Mutual Information-Driven Pan-Sharpening | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Mutual_Information-Driven_Pan-Sharpening_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Mutual_Information-Driven_Pan-Sharpening_CVPR_2022_paper.pdf)
61. FLOAT- Factorized Learning of Object Attributes for Improved Multi-Object Multi-Part Scene Parsing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Singh_FLOAT_Factorized_Learning_of_Object_Attributes_for_Improved_Multi-Object_Multi-Part_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_FLOAT_Factorized_Learning_of_Object_Attributes_for_Improved_Multi-Object_Multi-Part_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16168)
62. FocusCut- Diving Into a Focus View in Interactive Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_FocusCut_Diving_Into_a_Focus_View_in_Interactive_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_FocusCut_Diving_Into_a_Focus_View_in_Interactive_Segmentation_CVPR_2022_paper.pdf)
63. Medial Spectral Coordinates for 3D Shape Analysis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rezanejad_Medial_Spectral_Coordinates_for_3D_Shape_Analysis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rezanejad_Medial_Spectral_Coordinates_for_3D_Shape_Analysis_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.13295)
64. Dressing in the Wild by Watching Dance Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Dressing_in_the_Wild_by_Watching_Dance_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Dressing_in_the_Wild_by_Watching_Dance_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_Dressing_in_the_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15320)
65. SeeThroughNet- Resurrection of Auxiliary Loss by Preserving Class Probability Information | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Han_SeeThroughNet_Resurrection_of_Auxiliary_Loss_by_Preserving_Class_Probability_Information_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_SeeThroughNet_Resurrection_of_Auxiliary_Loss_by_Preserving_Class_Probability_Information_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Han_SeeThroughNet_Resurrection_of_CVPR_2022_supplemental.pdf)
66. Learning To Restore 3D Face From In-the-Wild Degraded Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Learning_To_Restore_3D_Face_From_In-the-Wild_Degraded_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Learning_To_Restore_3D_Face_From_In-the-Wild_Degraded_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Learning_To_Restore_CVPR_2022_supplemental.pdf)
67. SmartAdapt- Multi-Branch Object Detection Framework for Videos on Mobiles | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_SmartAdapt_Multi-Branch_Object_Detection_Framework_for_Videos_on_Mobiles_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_SmartAdapt_Multi-Branch_Object_Detection_Framework_for_Videos_on_Mobiles_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_SmartAdapt_Multi-Branch_Object_CVPR_2022_supplemental.pdf)
68. VL-Adapter- Parameter-Efficient Transfer Learning for Vision-and-Language Tasks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sung_VL-Adapter_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Tasks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sung_VL-Adapter_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Tasks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sung_VL-Adapter_Parameter-Efficient_Transfer_CVPR_2022_supplemental.pdf)
69. Deep Hybrid Models for Out-of-Distribution Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cao_Deep_Hybrid_Models_for_Out-of-Distribution_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_Deep_Hybrid_Models_for_Out-of-Distribution_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cao_Deep_Hybrid_Models_CVPR_2022_supplemental.pdf)
70. Accelerating Video Object Segmentation With Compressed Video | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Accelerating_Video_Object_Segmentation_With_Compressed_Video_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Accelerating_Video_Object_Segmentation_With_Compressed_Video_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Accelerating_Video_Object_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2107.12192)
71. FastDOG- Fast Discrete Optimization on GPU | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Abbas_FastDOG_Fast_Discrete_Optimization_on_GPU_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Abbas_FastDOG_Fast_Discrete_Optimization_on_GPU_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Abbas_FastDOG_Fast_Discrete_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.10270)
72. Self-Supervised Equivariant Learning for Oriented Keypoint Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Self-Supervised_Equivariant_Learning_for_Oriented_Keypoint_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Self-Supervised_Equivariant_Learning_for_Oriented_Keypoint_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Self-Supervised_Equivariant_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.08613)
73. Focal and Global Knowledge Distillation for Detectors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Focal_and_Global_Knowledge_Distillation_for_Detectors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Focal_and_Global_Knowledge_Distillation_for_Detectors_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.11837)
74. Learning To Prompt for Continual Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Learning_To_Prompt_for_Continual_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learning_To_Prompt_for_Continual_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Learning_To_Prompt_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.08654)
75. Human Mesh Recovery From Multiple Shots | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pavlakos_Human_Mesh_Recovery_From_Multiple_Shots_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pavlakos_Human_Mesh_Recovery_From_Multiple_Shots_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Pavlakos_Human_Mesh_Recovery_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2012.09843)
76. GANSeg- Learning To Segment by Unsupervised Hierarchical Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_GANSeg_Learning_To_Segment_by_Unsupervised_Hierarchical_Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_GANSeg_Learning_To_Segment_by_Unsupervised_Hierarchical_Image_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_GANSeg_Learning_To_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01036)
77. Dense Learning Based Semi-Supervised Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Dense_Learning_Based_Semi-Supervised_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Dense_Learning_Based_Semi-Supervised_Object_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.07300)
78. Fixing Malfunctional Objects With Learned Physical Simulation and Functional Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Fixing_Malfunctional_Objects_With_Learned_Physical_Simulation_and_Functional_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Fixing_Malfunctional_Objects_With_Learned_Physical_Simulation_and_Functional_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hong_Fixing_Malfunctional_Objects_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.02834)
79. Convolution of Convolution- Let Kernels Spatially Collaborate | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Convolution_of_Convolution_Let_Kernels_Spatially_Collaborate_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Convolution_of_Convolution_Let_Kernels_Spatially_Collaborate_CVPR_2022_paper.pdf)
80. Video-Text Representation Learning via Differentiable Weak Temporal Alignment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ko_Video-Text_Representation_Learning_via_Differentiable_Weak_Temporal_Alignment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ko_Video-Text_Representation_Learning_via_Differentiable_Weak_Temporal_Alignment_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ko_Video-Text_Representation_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16784)
81. Progressive Minimal Path Method With Embedded CNN | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liao_Progressive_Minimal_Path_Method_With_Embedded_CNN_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Progressive_Minimal_Path_Method_With_Embedded_CNN_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.00944)
82. 3D Human Tongue Reconstruction From Single "In-the-Wild" Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ploumpis_3D_Human_Tongue_Reconstruction_From_Single_In-the-Wild_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ploumpis_3D_Human_Tongue_Reconstruction_From_Single_In-the-Wild_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ploumpis_3D_Human_Tongue_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.12302)
83. A Simple Multi-Modality Transfer Learning Baseline for Sign Language Translation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_A_Simple_Multi-Modality_Transfer_Learning_Baseline_for_Sign_Language_Translation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_A_Simple_Multi-Modality_Transfer_Learning_Baseline_for_Sign_Language_Translation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_A_Simple_Multi-Modality_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04287)
84. MonoDTR- Monocular 3D Object Detection With Depth-Aware Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_MonoDTR_Monocular_3D_Object_Detection_With_Depth-Aware_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_MonoDTR_Monocular_3D_Object_Detection_With_Depth-Aware_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_MonoDTR_Monocular_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10981)
85. Learning Graph Regularisation for Guided Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/de_Lutio_Learning_Graph_Regularisation_for_Guided_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/de_Lutio_Learning_Graph_Regularisation_for_Guided_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/de_Lutio_Learning_Graph_Regularisation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14297)
86. Voxel Field Fusion for 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Voxel_Field_Fusion_for_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Voxel_Field_Fusion_for_3D_Object_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.15938)
87. Fast Algorithm for Low-Rank Tensor Completion in Delay-Embedded Space | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yamamoto_Fast_Algorithm_for_Low-Rank_Tensor_Completion_in_Delay-Embedded_Space_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yamamoto_Fast_Algorithm_for_Low-Rank_Tensor_Completion_in_Delay-Embedded_Space_CVPR_2022_paper.pdf)
88. Panoptic, Instance and Semantic Relations- A Relational Context Encoder To Enhance Panoptic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Borse_Panoptic_Instance_and_Semantic_Relations_A_Relational_Context_Encoder_To_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Borse_Panoptic_Instance_and_Semantic_Relations_A_Relational_Context_Encoder_To_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Borse_Panoptic_Instance_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.05370)
89. ETHSeg- An Amodel Instance Segmentation Network and a Real-World Dataset for X-Ray Waste Inspection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qiu_ETHSeg_An_Amodel_Instance_Segmentation_Network_and_a_Real-World_Dataset_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qiu_ETHSeg_An_Amodel_Instance_Segmentation_Network_and_a_Real-World_Dataset_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Qiu_ETHSeg_An_Amodel_CVPR_2022_supplemental.pdf)
90. Killing Two Birds With One Stone- Efficient and Robust Training of Face Recognition CNNs by Partial FC | [link](https://openaccess.thecvf.com/content/CVPR2022/html/An_Killing_Two_Birds_With_One_Stone_Efficient_and_Robust_Training_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/An_Killing_Two_Birds_With_One_Stone_Efficient_and_Robust_Training_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.15565)
91. FineDiving- A Fine-Grained Dataset for Procedure-Aware Action Quality Assessment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_FineDiving_A_Fine-Grained_Dataset_for_Procedure-Aware_Action_Quality_Assessment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_FineDiving_A_Fine-Grained_Dataset_for_Procedure-Aware_Action_Quality_Assessment_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_FineDiving_A_Fine-Grained_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03646)
92. HEAT- Holistic Edge Attention Transformer for Structured Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_HEAT_Holistic_Edge_Attention_Transformer_for_Structured_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_HEAT_Holistic_Edge_Attention_Transformer_for_Structured_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_HEAT_Holistic_Edge_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15143)
93. Exploiting Pseudo Labels in a Self-Supervised Learning Framework for Improved Monocular Depth Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Petrovai_Exploiting_Pseudo_Labels_in_a_Self-Supervised_Learning_Framework_for_Improved_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Petrovai_Exploiting_Pseudo_Labels_in_a_Self-Supervised_Learning_Framework_for_Improved_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Petrovai_Exploiting_Pseudo_Labels_CVPR_2022_supplemental.pdf)
94. VideoINR- Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_VideoINR_Learning_Video_Implicit_Neural_Representation_for_Continuous_Space-Time_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_VideoINR_Learning_Video_Implicit_Neural_Representation_for_Continuous_Space-Time_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_VideoINR_Learning_Video_CVPR_2022_supplemental.pdf)
95. Towards End-to-End Unified Scene Text Detection and Layout Analysis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Long_Towards_End-to-End_Unified_Scene_Text_Detection_and_Layout_Analysis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Long_Towards_End-to-End_Unified_Scene_Text_Detection_and_Layout_Analysis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Long_Towards_End-to-End_Unified_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15143)
96. AutoSDF- Shape Priors for 3D Completion, Reconstruction and Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mittal_AutoSDF_Shape_Priors_for_3D_Completion_Reconstruction_and_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mittal_AutoSDF_Shape_Priors_for_3D_Completion_Reconstruction_and_Generation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.09516)
97. ISNAS-DIP- Image-Specific Neural Architecture Search for Deep Image Prior | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Arican_ISNAS-DIP_Image-Specific_Neural_Architecture_Search_for_Deep_Image_Prior_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Arican_ISNAS-DIP_Image-Specific_Neural_Architecture_Search_for_Deep_Image_Prior_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Arican_ISNAS-DIP_Image-Specific_Neural_CVPR_2022_supplemental.pdf)
98. End-to-End Referring Video Object Segmentation With Multimodal Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Botach_End-to-End_Referring_Video_Object_Segmentation_With_Multimodal_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Botach_End-to-End_Referring_Video_Object_Segmentation_With_Multimodal_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Botach_End-to-End_Referring_Video_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14821)
99. Unpaired Cartoon Image Synthesis via Gated Cycle Mapping | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Men_Unpaired_Cartoon_Image_Synthesis_via_Gated_Cycle_Mapping_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Men_Unpaired_Cartoon_Image_Synthesis_via_Gated_Cycle_Mapping_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Men_Unpaired_Cartoon_Image_CVPR_2022_supplemental.zip)
100. Detecting Camouflaged Object in Frequency Domain | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_Detecting_Camouflaged_Object_in_Frequency_Domain_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Detecting_Camouflaged_Object_in_Frequency_Domain_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhong_Detecting_Camouflaged_Object_CVPR_2022_supplemental.pdf)
101. Style-Based Global Appearance Flow for Virtual Try-On | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_Style-Based_Global_Appearance_Flow_for_Virtual_Try-On_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Style-Based_Global_Appearance_Flow_for_Virtual_Try-On_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.01046)
102. Active Learning for Open-Set Annotation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ning_Active_Learning_for_Open-Set_Annotation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ning_Active_Learning_for_Open-Set_Annotation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2201.06758)
103. Semi-Supervised Video Semantic Segmentation With Inter-Frame Feature Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhuang_Semi-Supervised_Video_Semantic_Segmentation_With_Inter-Frame_Feature_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhuang_Semi-Supervised_Video_Semantic_Segmentation_With_Inter-Frame_Feature_Reconstruction_CVPR_2022_paper.pdf)
104. GenDR- A Generalized Differentiable Renderer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Petersen_GenDR_A_Generalized_Differentiable_Renderer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Petersen_GenDR_A_Generalized_Differentiable_Renderer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Petersen_GenDR_A_Generalized_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.13845)
105. XYLayoutLM- Towards Layout-Aware Multimodal Networks for Visually-Rich Document Understanding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gu_XYLayoutLM_Towards_Layout-Aware_Multimodal_Networks_for_Visually-Rich_Document_Understanding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_XYLayoutLM_Towards_Layout-Aware_Multimodal_Networks_for_Visually-Rich_Document_Understanding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gu_XYLayoutLM_Towards_Layout-Aware_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06947)
106. Amodal Segmentation Through Out-of-Task and Out-of-Distribution Generalization With a Bayesian Model | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Amodal_Segmentation_Through_Out-of-Task_and_Out-of-Distribution_Generalization_With_a_Bayesian_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Amodal_Segmentation_Through_Out-of-Task_and_Out-of-Distribution_Generalization_With_a_Bayesian_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sun_Amodal_Segmentation_Through_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2010.13175)
107. Canonical Voting- Towards Robust Oriented Bounding Box Detection in 3D Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/You_Canonical_Voting_Towards_Robust_Oriented_Bounding_Box_Detection_in_3D_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/You_Canonical_Voting_Towards_Robust_Oriented_Bounding_Box_Detection_in_3D_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/You_Canonical_Voting_Towards_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2011.12001)
108. Object-Aware Video-Language Pre-Training for Retrieval | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Object-Aware_Video-Language_Pre-Training_for_Retrieval_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Object-Aware_Video-Language_Pre-Training_for_Retrieval_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.00656)
109. OSKDet- Orientation-Sensitive Keypoint Localization for Rotated Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lu_OSKDet_Orientation-Sensitive_Keypoint_Localization_for_Rotated_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_OSKDet_Orientation-Sensitive_Keypoint_Localization_for_Rotated_Object_Detection_CVPR_2022_paper.pdf)
110. Exploring Geometric Consistency for Monocular 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lian_Exploring_Geometric_Consistency_for_Monocular_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lian_Exploring_Geometric_Consistency_for_Monocular_3D_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lian_Exploring_Geometric_Consistency_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.05858)
111. Neural Window Fully-Connected CRFs for Monocular Depth Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_Neural_Window_Fully-Connected_CRFs_for_Monocular_Depth_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Neural_Window_Fully-Connected_CRFs_for_Monocular_Depth_Estimation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.01502)
112. CodedVTR- Codebook-Based Sparse Voxel Transformer With Geometric Guidance | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_CodedVTR_Codebook-Based_Sparse_Voxel_Transformer_With_Geometric_Guidance_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_CodedVTR_Codebook-Based_Sparse_Voxel_Transformer_With_Geometric_Guidance_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_CodedVTR_Codebook-Based_Sparse_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09887)
113. Coherent Point Drift Revisited for Non-Rigid Shape Matching and Registration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Coherent_Point_Drift_Revisited_for_Non-Rigid_Shape_Matching_and_Registration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Coherent_Point_Drift_Revisited_for_Non-Rigid_Shape_Matching_and_Registration_CVPR_2022_paper.pdf)
114. Align and Prompt- Video-and-Language Pre-Training With Entity Prompts | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Align_and_Prompt_Video-and-Language_Pre-Training_With_Entity_Prompts_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Align_and_Prompt_Video-and-Language_Pre-Training_With_Entity_Prompts_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.09583)
115. It's About Time- Analog Clock Reading in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Its_About_Time_Analog_Clock_Reading_in_the_Wild_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Its_About_Time_Analog_Clock_Reading_in_the_Wild_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Its_About_Time_CVPR_2022_supplemental.pdf)
116. Cross Modal Retrieval With Querybank Normalisation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bogolin_Cross_Modal_Retrieval_With_Querybank_Normalisation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bogolin_Cross_Modal_Retrieval_With_Querybank_Normalisation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bogolin_Cross_Modal_Retrieval_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.12777)
117. Hire-MLP- Vision MLP via Hierarchical Rearrangement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Hire-MLP_Vision_MLP_via_Hierarchical_Rearrangement_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Hire-MLP_Vision_MLP_via_Hierarchical_Rearrangement_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_Hire-MLP_Vision_MLP_CVPR_2022_supplemental.pdf)
118. Occluded Human Mesh Recovery | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Khirodkar_Occluded_Human_Mesh_Recovery_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Khirodkar_Occluded_Human_Mesh_Recovery_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Khirodkar_Occluded_Human_Mesh_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13349)
119. MAD- A Scalable Dataset for Language Grounding in Videos From Movie Audio Descriptions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Soldan_MAD_A_Scalable_Dataset_for_Language_Grounding_in_Videos_From_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Soldan_MAD_A_Scalable_Dataset_for_Language_Grounding_in_Videos_From_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Soldan_MAD_A_Scalable_CVPR_2022_supplemental.pdf)
120. ArtiBoost- Boosting Articulated 3D Hand-Object Pose Estimation via Online Exploration and Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_ArtiBoost_Boosting_Articulated_3D_Hand-Object_Pose_Estimation_via_Online_Exploration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_ArtiBoost_Boosting_Articulated_3D_Hand-Object_Pose_Estimation_via_Online_Exploration_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_ArtiBoost_Boosting_Articulated_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2109.05488)
121. Disentangled3D- Learning a 3D Generative Model With Disentangled Geometry and Appearance From Monocular Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tewari_Disentangled3D_Learning_a_3D_Generative_Model_With_Disentangled_Geometry_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tewari_Disentangled3D_Learning_a_3D_Generative_Model_With_Disentangled_Geometry_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tewari_Disentangled3D_Learning_a_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15926)
122. Revisiting Random Channel Pruning for Neural Network Compression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Revisiting_Random_Channel_Pruning_for_Neural_Network_Compression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Revisiting_Random_Channel_Pruning_for_Neural_Network_Compression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Revisiting_Random_Channel_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.05676)
123. Does Text Attract Attention on E-Commerce Images- A Novel Saliency Prediction Dataset and Method | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Does_Text_Attract_Attention_on_E-Commerce_Images_A_Novel_Saliency_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Does_Text_Attract_Attention_on_E-Commerce_Images_A_Novel_Saliency_CVPR_2022_paper.pdf)
124. Topologically-Aware Deformation Fields for Single-View 3D Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Duggal_Topologically-Aware_Deformation_Fields_for_Single-View_3D_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Duggal_Topologically-Aware_Deformation_Fields_for_Single-View_3D_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Duggal_Topologically-Aware_Deformation_Fields_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.06267)
125. Sparse Non-Local CRF | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Veksler_Sparse_Non-Local_CRF_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Veksler_Sparse_Non-Local_CRF_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Veksler_Sparse_Non-Local_CRF_CVPR_2022_supplemental.pdf)
126. EPro-PnP- Generalized End-to-End Probabilistic Perspective-N-Points for Monocular Object Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_EPro-PnP_Generalized_End-to-End_Probabilistic_Perspective-N-Points_for_Monocular_Object_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_EPro-PnP_Generalized_End-to-End_Probabilistic_Perspective-N-Points_for_Monocular_Object_Pose_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_EPro-PnP_Generalized_End-to-End_CVPR_2022_supplemental.pdf)
127. Generating Diverse and Natural 3D Human Motions From Text | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Generating_Diverse_and_Natural_3D_Human_Motions_From_Text_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Generating_Diverse_and_Natural_3D_Human_Motions_From_Text_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_Generating_Diverse_and_CVPR_2022_supplemental.pdf)
128. Multi-Frame Self-Supervised Depth With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guizilini_Multi-Frame_Self-Supervised_Depth_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guizilini_Multi-Frame_Self-Supervised_Depth_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guizilini_Multi-Frame_Self-Supervised_Depth_CVPR_2022_supplemental.pdf)
129. Self-Supervised Keypoint Discovery in Behavioral Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Self-Supervised_Keypoint_Discovery_in_Behavioral_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Self-Supervised_Keypoint_Discovery_in_Behavioral_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sun_Self-Supervised_Keypoint_Discovery_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.05121)
130. IRISformer- Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_IRISformer_Dense_Vision_Transformers_for_Single-Image_Inverse_Rendering_in_Indoor_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_IRISformer_Dense_Vision_Transformers_for_Single-Image_Inverse_Rendering_in_Indoor_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_IRISformer_Dense_Vision_CVPR_2022_supplemental.pdf)
131. Connecting the Complementary-View Videos- Joint Camera Identification and Subject Association | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Han_Connecting_the_Complementary-View_Videos_Joint_Camera_Identification_and_Subject_Association_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Connecting_the_Complementary-View_Videos_Joint_Camera_Identification_and_Subject_Association_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Han_Connecting_the_Complementary-View_CVPR_2022_supplemental.pdf)
132. End-to-End Trajectory Distribution Prediction Based on Occupancy Grid Maps | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_End-to-End_Trajectory_Distribution_Prediction_Based_on_Occupancy_Grid_Maps_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_End-to-End_Trajectory_Distribution_Prediction_Based_on_Occupancy_Grid_Maps_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_End-to-End_Trajectory_Distribution_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16910)
133. Weakly Supervised Temporal Action Localization via Representative Snippet Knowledge Propagation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Weakly_Supervised_Temporal_Action_Localization_via_Representative_Snippet_Knowledge_Propagation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Weakly_Supervised_Temporal_Action_Localization_via_Representative_Snippet_Knowledge_Propagation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Weakly_Supervised_Temporal_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02925)
134. E2EC- An End-to-End Contour-Based Method for High-Quality High-Speed Instance Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_E2EC_An_End-to-End_Contour-Based_Method_for_High-Quality_High-Speed_Instance_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_E2EC_An_End-to-End_Contour-Based_Method_for_High-Quality_High-Speed_Instance_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.04074)
135. Self-Supervised Image-Specific Prototype Exploration for Weakly Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Self-Supervised_Image-Specific_Prototype_Exploration_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Self-Supervised_Image-Specific_Prototype_Exploration_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.02909)
136. Clothes-Changing Person Re-Identification With RGB Modality Only | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gu_Clothes-Changing_Person_Re-Identification_With_RGB_Modality_Only_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Clothes-Changing_Person_Re-Identification_With_RGB_Modality_Only_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gu_Clothes-Changing_Person_Re-Identification_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.06890)
137. Chitransformer- Towards Reliable Stereo From Cues | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Su_Chitransformer_Towards_Reliable_Stereo_From_Cues_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Su_Chitransformer_Towards_Reliable_Stereo_From_Cues_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Su_Chitransformer_Towards_Reliable_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04554)
138. Modality-Agnostic Learning for Radar-Lidar Fusion in Vehicle Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Modality-Agnostic_Learning_for_Radar-Lidar_Fusion_in_Vehicle_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Modality-Agnostic_Learning_for_Radar-Lidar_Fusion_in_Vehicle_Detection_CVPR_2022_paper.pdf)
139. A Re-Balancing Strategy for Class-Imbalanced Classification Based on Instance Difficulty | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_A_Re-Balancing_Strategy_for_Class-Imbalanced_Classification_Based_on_Instance_Difficulty_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_A_Re-Balancing_Strategy_for_Class-Imbalanced_Classification_Based_on_Instance_Difficulty_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_A_Re-Balancing_Strategy_CVPR_2022_supplemental.pdf)
140. Tracking People by Predicting 3D Appearance, Location and Pose | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rajasegaran_Tracking_People_by_Predicting_3D_Appearance_Location_and_Pose_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rajasegaran_Tracking_People_by_Predicting_3D_Appearance_Location_and_Pose_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rajasegaran_Tracking_People_by_CVPR_2022_supplemental.pdf)
141. Tencent-MVSE- A Large-Scale Benchmark Dataset for Multi-Modal Video Similarity Evaluation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zeng_Tencent-MVSE_A_Large-Scale_Benchmark_Dataset_for_Multi-Modal_Video_Similarity_Evaluation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_Tencent-MVSE_A_Large-Scale_Benchmark_Dataset_for_Multi-Modal_Video_Similarity_Evaluation_CVPR_2022_paper.pdf)
142. Deep Orientation-Aware Functional Maps- Tackling Symmetry Issues in Shape Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Donati_Deep_Orientation-Aware_Functional_Maps_Tackling_Symmetry_Issues_in_Shape_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Donati_Deep_Orientation-Aware_Functional_Maps_Tackling_Symmetry_Issues_in_Shape_Matching_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Donati_Deep_Orientation-Aware_Functional_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.13453)
143. Video Shadow Detection via Spatio-Temporal Interpolation Consistency Training | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Video_Shadow_Detection_via_Spatio-Temporal_Interpolation_Consistency_Training_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Video_Shadow_Detection_via_Spatio-Temporal_Interpolation_Consistency_Training_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lu_Video_Shadow_Detection_CVPR_2022_supplemental.pdf)
144. Robust and Accurate Superquadric Recovery- A Probabilistic Approach | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Robust_and_Accurate_Superquadric_Recovery_A_Probabilistic_Approach_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Robust_and_Accurate_Superquadric_Recovery_A_Probabilistic_Approach_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Robust_and_Accurate_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14517)
145. Zero-Shot Text-Guided Object Generation With Dream Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jain_Zero-Shot_Text-Guided_Object_Generation_With_Dream_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jain_Zero-Shot_Text-Guided_Object_Generation_With_Dream_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jain_Zero-Shot_Text-Guided_Object_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01455)
146. Sparse Instance Activation for Real-Time Instance Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Sparse_Instance_Activation_for_Real-Time_Instance_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Sparse_Instance_Activation_for_Real-Time_Instance_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.12827)
147. Can You Spot the Chameleon- Adversarially Camouflaging Images From Co-Salient Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gao_Can_You_Spot_the_Chameleon_Adversarially_Camouflaging_Images_From_Co-Salient_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Can_You_Spot_the_Chameleon_Adversarially_Camouflaging_Images_From_Co-Salient_CVPR_2022_paper.pdf)
148. Learning From Temporal Gradient for Semi-Supervised Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xiao_Learning_From_Temporal_Gradient_for_Semi-Supervised_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xiao_Learning_From_Temporal_Gradient_for_Semi-Supervised_Action_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xiao_Learning_From_Temporal_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13241)
149. Audio-Driven Neural Gesture Reenactment With Video Motion Graphs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Audio-Driven_Neural_Gesture_Reenactment_With_Video_Motion_Graphs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Audio-Driven_Neural_Gesture_Reenactment_With_Video_Motion_Graphs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Audio-Driven_Neural_Gesture_CVPR_2022_supplemental.zip)
150. SoftCollage- A Differentiable Probabilistic Tree Generator for Image Collage | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_SoftCollage_A_Differentiable_Probabilistic_Tree_Generator_for_Image_Collage_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_SoftCollage_A_Differentiable_Probabilistic_Tree_Generator_for_Image_Collage_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_SoftCollage_A_Differentiable_CVPR_2022_supplemental.pdf)
151. A Unified Framework for Implicit Sinkhorn Differentiation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Eisenberger_A_Unified_Framework_for_Implicit_Sinkhorn_Differentiation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Eisenberger_A_Unified_Framework_for_Implicit_Sinkhorn_Differentiation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Eisenberger_A_Unified_Framework_CVPR_2022_supplemental.pdf)
152. DGECN- A Depth-Guided Edge Convolutional Network for End-to-End 6D Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cao_DGECN_A_Depth-Guided_Edge_Convolutional_Network_for_End-to-End_6D_Pose_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_DGECN_A_Depth-Guided_Edge_Convolutional_Network_for_End-to-End_6D_Pose_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cao_DGECN_A_Depth-Guided_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.09983)
153. Winoground- Probing Vision and Language Models for Visio-Linguistic Compositionality | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Thrush_Winoground_Probing_Vision_and_Language_Models_for_Visio-Linguistic_Compositionality_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Thrush_Winoground_Probing_Vision_and_Language_Models_for_Visio-Linguistic_Compositionality_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Thrush_Winoground_Probing_Vision_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03162)
154. Progressive Attention on Multi-Level Dense Difference Maps for Generic Event Boundary Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Progressive_Attention_on_Multi-Level_Dense_Difference_Maps_for_Generic_Event_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Progressive_Attention_on_Multi-Level_Dense_Difference_Maps_for_Generic_Event_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_Progressive_Attention_on_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.04771)
155. 3D Scene Painting via Semantic Image Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jeong_3D_Scene_Painting_via_Semantic_Image_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jeong_3D_Scene_Painting_via_Semantic_Image_Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jeong_3D_Scene_Painting_CVPR_2022_supplemental.pdf)
156. Revisiting Weakly Supervised Pre-Training of Visual Perception Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Singh_Revisiting_Weakly_Supervised_Pre-Training_of_Visual_Perception_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_Revisiting_Weakly_Supervised_Pre-Training_of_Visual_Perception_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Singh_Revisiting_Weakly_Supervised_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.08371)
157. Meta Convolutional Neural Networks for Single Domain Generalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wan_Meta_Convolutional_Neural_Networks_for_Single_Domain_Generalization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wan_Meta_Convolutional_Neural_Networks_for_Single_Domain_Generalization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wan_Meta_Convolutional_Neural_CVPR_2022_supplemental.pdf)
158. Generalizing Gaze Estimation With Rotation Consistency | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bao_Generalizing_Gaze_Estimation_With_Rotation_Consistency_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_Generalizing_Gaze_Estimation_With_Rotation_Consistency_CVPR_2022_paper.pdf)
159. Accelerating Neural Network Optimization Through an Automated Control Theory Lens | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Accelerating_Neural_Network_Optimization_Through_an_Automated_Control_Theory_Lens_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Accelerating_Neural_Network_Optimization_Through_an_Automated_Control_Theory_Lens_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Accelerating_Neural_Network_CVPR_2022_supplemental.pdf)
160. Learning To Learn Across Diverse Data Biases in Deep Face Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_To_Learn_Across_Diverse_Data_Biases_in_Deep_Face_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_To_Learn_Across_Diverse_Data_Biases_in_Deep_Face_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Learning_To_Learn_CVPR_2022_supplemental.pdf)
161. Online Convolutional Re-Parameterization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Online_Convolutional_Re-Parameterization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Online_Convolutional_Re-Parameterization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_Online_Convolutional_Re-Parameterization_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00826)
162. Smooth Maximum Unit- Smooth Activation Function for Deep Networks Using Smoothing Maximum Technique | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Biswas_Smooth_Maximum_Unit_Smooth_Activation_Function_for_Deep_Networks_Using_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Biswas_Smooth_Maximum_Unit_Smooth_Activation_Function_for_Deep_Networks_Using_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Biswas_Smooth_Maximum_Unit_CVPR_2022_supplemental.pdf)
163. Learning Invisible Markers for Hidden Codes in Offline-to-Online Photography | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jia_Learning_Invisible_Markers_for_Hidden_Codes_in_Offline-to-Online_Photography_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_Learning_Invisible_Markers_for_Hidden_Codes_in_Offline-to-Online_Photography_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jia_Learning_Invisible_Markers_CVPR_2022_supplemental.pdf)
164. Noise Is Also Useful- Negative Correlation-Steered Latent Contrastive Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yan_Noise_Is_Also_Useful_Negative_Correlation-Steered_Latent_Contrastive_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Noise_Is_Also_Useful_Negative_Correlation-Steered_Latent_Contrastive_Learning_CVPR_2022_paper.pdf)
165. Decoupled Multi-Task Learning With Cyclical Self-Regulation for Face Parsing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Decoupled_Multi-Task_Learning_With_Cyclical_Self-Regulation_for_Face_Parsing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Decoupled_Multi-Task_Learning_With_Cyclical_Self-Regulation_for_Face_Parsing_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.14448)
166. AUV-Net- Learning Aligned UV Maps for Texture Transfer and Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_AUV-Net_Learning_Aligned_UV_Maps_for_Texture_Transfer_and_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_AUV-Net_Learning_Aligned_UV_Maps_for_Texture_Transfer_and_Synthesis_CVPR_2022_paper.pdf)
167. Eigencontours- Novel Contour Descriptors Based on Low-Rank Approximation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Park_Eigencontours_Novel_Contour_Descriptors_Based_on_Low-Rank_Approximation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Eigencontours_Novel_Contour_Descriptors_Based_on_Low-Rank_Approximation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Park_Eigencontours_Novel_Contour_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.15259)
168. Efficient Deep Embedded Subspace Clustering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cai_Efficient_Deep_Embedded_Subspace_Clustering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Efficient_Deep_Embedded_Subspace_Clustering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cai_Efficient_Deep_Embedded_CVPR_2022_supplemental.pdf)
169. Spatial-Temporal Space Hand-in-Hand- Spatial-Temporal Video Super-Resolution via Cycle-Projected Mutual Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Spatial-Temporal_Space_Hand-in-Hand_Spatial-Temporal_Video_Super-Resolution_via_Cycle-Projected_Mutual_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Spatial-Temporal_Space_Hand-in-Hand_Spatial-Temporal_Video_Super-Resolution_via_Cycle-Projected_Mutual_Learning_CVPR_2022_paper.pdf)
170. Revisiting Near-Remote Sensing With Geospatial Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Workman_Revisiting_NearRemote_Sensing_With_Geospatial_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Workman_Revisiting_NearRemote_Sensing_With_Geospatial_Attention_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Workman_Revisiting_NearRemote_Sensing_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01807)
171. Slot-VPS- Object-Centric Representation Learning for Video Panoptic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Slot-VPS_Object-Centric_Representation_Learning_for_Video_Panoptic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Slot-VPS_Object-Centric_Representation_Learning_for_Video_Panoptic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Slot-VPS_Object-Centric_Representation_CVPR_2022_supplemental.pdf)
172. Efficient Video Instance Segmentation via Tracklet Query and Proposal | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Efficient_Video_Instance_Segmentation_via_Tracklet_Query_and_Proposal_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Efficient_Video_Instance_Segmentation_via_Tracklet_Query_and_Proposal_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Efficient_Video_Instance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01853)
173. NeuralHDHair- Automatic High-Fidelity Hair Modeling From a Single Image Using Implicit Neural Representations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_NeuralHDHair_Automatic_High-Fidelity_Hair_Modeling_From_a_Single_Image_Using_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_NeuralHDHair_Automatic_High-Fidelity_Hair_Modeling_From_a_Single_Image_Using_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_NeuralHDHair_Automatic_High-Fidelity_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.04175)
174. Exploring Frequency Adversarial Attacks for Face Forgery Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jia_Exploring_Frequency_Adversarial_Attacks_for_Face_Forgery_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_Exploring_Frequency_Adversarial_Attacks_for_Face_Forgery_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.15674)
175. Signing at Scale- Learning to Co-Articulate Signs for Large-Scale Photo-Realistic Sign Language Production | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Saunders_Signing_at_Scale_Learning_to_Co-Articulate_Signs_for_Large-Scale_Photo-Realistic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Saunders_Signing_at_Scale_Learning_to_Co-Articulate_Signs_for_Large-Scale_Photo-Realistic_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Saunders_Signing_at_Scale_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15354)
176. Explore Spatio-Temporal Aggregation for Insubstantial Object Detection- Benchmark Dataset and Baseline | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Explore_Spatio-Temporal_Aggregation_for_Insubstantial_Object_Detection_Benchmark_Dataset_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Explore_Spatio-Temporal_Aggregation_for_Insubstantial_Object_Detection_Benchmark_Dataset_and_CVPR_2022_paper.pdf)
177. Learning Bayesian Sparse Networks With Full Experience Replay for Continual Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yan_Learning_Bayesian_Sparse_Networks_With_Full_Experience_Replay_for_Continual_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Learning_Bayesian_Sparse_Networks_With_Full_Experience_Replay_for_Continual_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2202.10203)
178. Graph-Based Spatial Transformer With Memory Replay for Multi-Future Pedestrian Trajectory Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Graph-Based_Spatial_Transformer_With_Memory_Replay_for_Multi-Future_Pedestrian_Trajectory_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Graph-Based_Spatial_Transformer_With_Memory_Replay_for_Multi-Future_Pedestrian_Trajectory_CVPR_2022_paper.pdf)
179. TableFormer- Table Structure Understanding With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nassar_TableFormer_Table_Structure_Understanding_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nassar_TableFormer_Table_Structure_Understanding_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nassar_TableFormer_Table_Structure_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01017)
180. Exemplar-Based Pattern Synthesis With Implicit Periodic Field Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Exemplar-Based_Pattern_Synthesis_With_Implicit_Periodic_Field_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Exemplar-Based_Pattern_Synthesis_With_Implicit_Periodic_Field_Network_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.01671)
181. Generating 3D Bio-Printable Patches Using Wound Segmentation and Reconstruction To Treat Diabetic Foot Ulcers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chae_Generating_3D_Bio-Printable_Patches_Using_Wound_Segmentation_and_Reconstruction_To_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chae_Generating_3D_Bio-Printable_Patches_Using_Wound_Segmentation_and_Reconstruction_To_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chae_Generating_3D_Bio-Printable_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.03814)
182. OmniFusion- 360 Monocular Depth Estimation via Geometry-Aware Fusion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_OmniFusion_360_Monocular_Depth_Estimation_via_Geometry-Aware_Fusion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_OmniFusion_360_Monocular_Depth_Estimation_via_Geometry-Aware_Fusion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_OmniFusion_360_Monocular_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.00838)
183. Semi-Weakly-Supervised Learning of Complex Actions From Instructional Task Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shen_Semi-Weakly-Supervised_Learning_of_Complex_Actions_From_Instructional_Task_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Semi-Weakly-Supervised_Learning_of_Complex_Actions_From_Instructional_Task_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shen_Semi-Weakly-Supervised_Learning_of_CVPR_2022_supplemental.pdf)
184. VALHALLA- Visual Hallucination for Machine Translation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_VALHALLA_Visual_Hallucination_for_Machine_Translation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_VALHALLA_Visual_Hallucination_for_Machine_Translation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_VALHALLA_Visual_Hallucination_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2206.00100)
185. Advancing High-Resolution Video-Language Representation With Large-Scale Video Transcriptions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Advancing_High-Resolution_Video-Language_Representation_With_Large-Scale_Video_Transcriptions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Advancing_High-Resolution_Video-Language_Representation_With_Large-Scale_Video_Transcriptions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xue_Advancing_High-Resolution_Video-Language_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.10337)
186. Neural Face Identification in a 2D Wireframe Projection of a Manifold Object | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Neural_Face_Identification_in_a_2D_Wireframe_Projection_of_a_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Neural_Face_Identification_in_a_2D_Wireframe_Projection_of_a_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Neural_Face_Identification_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04229)
187. Nonuniform-to-Uniform Quantization- Towards Accurate Quantization via Generalized Straight-Through Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Nonuniform-to-Uniform_Quantization_Towards_Accurate_Quantization_via_Generalized_Straight-Through_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Nonuniform-to-Uniform_Quantization_Towards_Accurate_Quantization_via_Generalized_Straight-Through_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Nonuniform-to-Uniform_Quantization_Towards_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14826)
188. Learning 3D Object Shape and Layout Without 3D Supervision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gkioxari_Learning_3D_Object_Shape_and_Layout_Without_3D_Supervision_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gkioxari_Learning_3D_Object_Shape_and_Layout_Without_3D_Supervision_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gkioxari_Learning_3D_Object_CVPR_2022_supplemental.pdf)
189. SimVP- Simpler Yet Better Video Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gao_SimVP_Simpler_Yet_Better_Video_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_SimVP_Simpler_Yet_Better_Video_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gao_SimVP_Simpler_Yet_CVPR_2022_supplemental.pdf)
190. Object Localization Under Single Coarse Point Supervision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Object_Localization_Under_Single_Coarse_Point_Supervision_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Object_Localization_Under_Single_Coarse_Point_Supervision_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_Object_Localization_Under_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09338)
191. Bayesian Nonparametric Submodular Video Partition for Robust Anomaly Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sapkota_Bayesian_Nonparametric_Submodular_Video_Partition_for_Robust_Anomaly_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sapkota_Bayesian_Nonparametric_Submodular_Video_Partition_for_Robust_Anomaly_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sapkota_Bayesian_Nonparametric_Submodular_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12840)
192. FocalClick- Towards Practical Interactive Image Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_FocalClick_Towards_Practical_Interactive_Image_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_FocalClick_Towards_Practical_Interactive_Image_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.02574)
193. ISDNet- Integrating Shallow and Deep Networks for Efficient Ultra-High Resolution Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_ISDNet_Integrating_Shallow_and_Deep_Networks_for_Efficient_Ultra-High_Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_ISDNet_Integrating_Shallow_and_Deep_Networks_for_Efficient_Ultra-High_Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_ISDNet_Integrating_Shallow_CVPR_2022_supplemental.pdf)
194. Understanding Uncertainty Maps in Vision With Statistical Testing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nazarovs_Understanding_Uncertainty_Maps_in_Vision_With_Statistical_Testing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nazarovs_Understanding_Uncertainty_Maps_in_Vision_With_Statistical_Testing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nazarovs_Understanding_Uncertainty_Maps_CVPR_2022_supplemental.pdf)
195. A Variational Bayesian Method for Similarity Learning in Non-Rigid Image Registration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Grzech_A_Variational_Bayesian_Method_for_Similarity_Learning_in_Non-Rigid_Image_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Grzech_A_Variational_Bayesian_Method_for_Similarity_Learning_in_Non-Rigid_Image_CVPR_2022_paper.pdf)
196. Quarantine- Sparsity Can Uncover the Trojan Attack Trigger for Free | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Quarantine_Sparsity_Can_Uncover_the_Trojan_Attack_Trigger_for_Free_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Quarantine_Sparsity_Can_Uncover_the_Trojan_Attack_Trigger_for_Free_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Quarantine_Sparsity_Can_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.11819)
197. Why Discard if You Can Recycle-- A Recycling Max Pooling Module for 3D Point Cloud Analysis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Why_Discard_if_You_Can_Recycle_A_Recycling_Max_Pooling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Why_Discard_if_You_Can_Recycle_A_Recycling_Max_Pooling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Why_Discard_if_CVPR_2022_supplemental.pdf)
198. Learning From Pixel-Level Noisy Label- A New Perspective for Light Field Saliency Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Learning_From_Pixel-Level_Noisy_Label_A_New_Perspective_for_Light_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Learning_From_Pixel-Level_Noisy_Label_A_New_Perspective_for_Light_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Feng_Learning_From_Pixel-Level_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.13456)
199. Multi-View Depth Estimation by Fusing Single-View Depth Probability With Multi-View Geometry | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bae_Multi-View_Depth_Estimation_by_Fusing_Single-View_Depth_Probability_With_Multi-View_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bae_Multi-View_Depth_Estimation_by_Fusing_Single-View_Depth_Probability_With_Multi-View_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bae_Multi-View_Depth_Estimation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.08177)
200. CLIP-NeRF- Text-and-Image Driven Manipulation of Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_CLIP-NeRF_Text-and-Image_Driven_Manipulation_of_Neural_Radiance_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_CLIP-NeRF_Text-and-Image_Driven_Manipulation_of_Neural_Radiance_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_CLIP-NeRF_Text-and-Image_Driven_CVPR_2022_supplemental.pdf)
201. Homography Loss for Monocular 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gu_Homography_Loss_for_Monocular_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Homography_Loss_for_Monocular_3D_Object_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.00754)
202. Dynamic Sparse R-CNN | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Dynamic_Sparse_R-CNN_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Dynamic_Sparse_R-CNN_CVPR_2022_paper.pdf)
203. Stable Long-Term Recurrent Video Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chiche_Stable_Long-Term_Recurrent_Video_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chiche_Stable_Long-Term_Recurrent_Video_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chiche_Stable_Long-Term_Recurrent_CVPR_2022_supplemental.pdf)
204. Dual-Generator Face Reenactment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hsu_Dual-Generator_Face_Reenactment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hsu_Dual-Generator_Face_Reenactment_CVPR_2022_paper.pdf)
205. A Hybrid Quantum-Classical Algorithm for Robust Fitting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Doan_A_Hybrid_Quantum-Classical_Algorithm_for_Robust_Fitting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Doan_A_Hybrid_Quantum-Classical_Algorithm_for_Robust_Fitting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Doan_A_Hybrid_Quantum-Classical_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.10110)
206. Human Instance Matting via Mutual Guidance and Multi-Instance Refinement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Human_Instance_Matting_via_Mutual_Guidance_and_Multi-Instance_Refinement_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Human_Instance_Matting_via_Mutual_Guidance_and_Multi-Instance_Refinement_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sun_Human_Instance_Matting_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.10767)
207. SwinTextSpotter- Scene Text Spotting via Better Synergy Between Text Detection and Text Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_SwinTextSpotter_Scene_Text_Spotting_via_Better_Synergy_Between_Text_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_SwinTextSpotter_Scene_Text_Spotting_via_Better_Synergy_Between_Text_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_SwinTextSpotter_Scene_Text_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10209)
208. Video Frame Interpolation With Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Video_Frame_Interpolation_With_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Video_Frame_Interpolation_With_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lu_Video_Frame_Interpolation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.07230)
209. TemporalUV- Capturing Loose Clothing With Temporally Coherent UV Coordinates | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_TemporalUV_Capturing_Loose_Clothing_With_Temporally_Coherent_UV_Coordinates_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_TemporalUV_Capturing_Loose_Clothing_With_Temporally_Coherent_UV_Coordinates_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xie_TemporalUV_Capturing_Loose_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03671)
210. An Iterative Quantum Approach for Transformation Estimation From Point Sets | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Meli_An_Iterative_Quantum_Approach_for_Transformation_Estimation_From_Point_Sets_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Meli_An_Iterative_Quantum_Approach_for_Transformation_Estimation_From_Point_Sets_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Meli_An_Iterative_Quantum_CVPR_2022_supplemental.pdf)
211. PhysFormer- Facial Video-Based Physiological Measurement With Temporal Difference Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_PhysFormer_Facial_Video-Based_Physiological_Measurement_With_Temporal_Difference_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_PhysFormer_Facial_Video-Based_Physiological_Measurement_With_Temporal_Difference_Transformer_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.12082)
212. Dimension Embeddings for Monocular 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Dimension_Embeddings_for_Monocular_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Dimension_Embeddings_for_Monocular_3D_Object_Detection_CVPR_2022_paper.pdf)
213. Blind Image Super-Resolution With Elaborate Degradation Modeling on Noise and Kernel | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yue_Blind_Image_Super-Resolution_With_Elaborate_Degradation_Modeling_on_Noise_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yue_Blind_Image_Super-Resolution_With_Elaborate_Degradation_Modeling_on_Noise_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yue_Blind_Image_Super-Resolution_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2107.00986)
214. Progressive End-to-End Object Detection in Crowded Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Progressive_End-to-End_Object_Detection_in_Crowded_Scenes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Progressive_End-to-End_Object_Detection_in_Crowded_Scenes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_Progressive_End-to-End_Object_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.07669)
215. Robust Combination of Distributed Gradients Under Adversarial Perturbations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Robust_Combination_of_Distributed_Gradients_Under_Adversarial_Perturbations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Robust_Combination_of_Distributed_Gradients_Under_Adversarial_Perturbations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Robust_Combination_of_CVPR_2022_supplemental.pdf)
216. Automatic Synthesis of Diverse Weak Supervision Sources for Behavior Analysis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tseng_Automatic_Synthesis_of_Diverse_Weak_Supervision_Sources_for_Behavior_Analysis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tseng_Automatic_Synthesis_of_Diverse_Weak_Supervision_Sources_for_Behavior_Analysis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tseng_Automatic_Synthesis_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15186)
217. Habitat-Web- Learning Embodied Object-Search Strategies From Human Demonstrations at Scale | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ramrakhya_Habitat-Web_Learning_Embodied_Object-Search_Strategies_From_Human_Demonstrations_at_Scale_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ramrakhya_Habitat-Web_Learning_Embodied_Object-Search_Strategies_From_Human_Demonstrations_at_Scale_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ramrakhya_Habitat-Web_Learning_Embodied_CVPR_2022_supplemental.pdf)
218. The Probabilistic Normal Epipolar Constraint for Frame-to-Frame Rotation Optimization Under Uncertain Feature Positions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Muhle_The_Probabilistic_Normal_Epipolar_Constraint_for_Frame-to-Frame_Rotation_Optimization_Under_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Muhle_The_Probabilistic_Normal_Epipolar_Constraint_for_Frame-to-Frame_Rotation_Optimization_Under_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Muhle_The_Probabilistic_Normal_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02256)
219. DyRep- Bootstrapping Training With Dynamic Re-Parameterization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_DyRep_Bootstrapping_Training_With_Dynamic_Re-Parameterization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_DyRep_Bootstrapping_Training_With_Dynamic_Re-Parameterization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_DyRep_Bootstrapping_Training_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12868)
220. CDGNet- Class Distribution Guided Network for Human Parsing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_CDGNet_Class_Distribution_Guided_Network_for_Human_Parsing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_CDGNet_Class_Distribution_Guided_Network_for_Human_Parsing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_CDGNet_Class_Distribution_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14173)
221. Deep Safe Multi-View Clustering- Reducing the Risk of Clustering Performance Degradation Caused by View Increase | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Deep_Safe_Multi-View_Clustering_Reducing_the_Risk_of_Clustering_Performance_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Deep_Safe_Multi-View_Clustering_Reducing_the_Risk_of_Clustering_Performance_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_Deep_Safe_Multi-View_CVPR_2022_supplemental.pdf)
222. HP-Capsule- Unsupervised Face Part Discovery by Hierarchical Parsing Capsule Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_HP-Capsule_Unsupervised_Face_Part_Discovery_by_Hierarchical_Parsing_Capsule_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_HP-Capsule_Unsupervised_Face_Part_Discovery_by_Hierarchical_Parsing_Capsule_Network_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_HP-Capsule_Unsupervised_Face_CVPR_2022_supplemental.pdf)
223. MuKEA- Multimodal Knowledge Extraction and Accumulation for Knowledge-Based Visual Question Answering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_MuKEA_Multimodal_Knowledge_Extraction_and_Accumulation_for_Knowledge-Based_Visual_Question_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_MuKEA_Multimodal_Knowledge_Extraction_and_Accumulation_for_Knowledge-Based_Visual_Question_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ding_MuKEA_Multimodal_Knowledge_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09138)
224. Transform-Retrieve-Generate- Natural Language-Centric Outside-Knowledge Visual Question Answering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gao_Transform-Retrieve-Generate_Natural_Language-Centric_Outside-Knowledge_Visual_Question_Answering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Transform-Retrieve-Generate_Natural_Language-Centric_Outside-Knowledge_Visual_Question_Answering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gao_Transform-Retrieve-Generate_Natural_Language-Centric_CVPR_2022_supplemental.pdf)
225. Nested Hyperbolic Spaces for Dimensionality Reduction and Hyperbolic NN Design | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Nested_Hyperbolic_Spaces_for_Dimensionality_Reduction_and_Hyperbolic_NN_Design_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Nested_Hyperbolic_Spaces_for_Dimensionality_Reduction_and_Hyperbolic_NN_Design_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fan_Nested_Hyperbolic_Spaces_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.03402)
226. BNUDC- A Two-Branched Deep Neural Network for Restoring Images From Under-Display Cameras | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Koh_BNUDC_A_Two-Branched_Deep_Neural_Network_for_Restoring_Images_From_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Koh_BNUDC_A_Two-Branched_Deep_Neural_Network_for_Restoring_Images_From_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Koh_BNUDC_A_Two-Branched_CVPR_2022_supplemental.pdf)
227. Training Object Detectors From Scratch- An Empirical Study in the Era of Vision Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Training_Object_Detectors_From_Scratch_An_Empirical_Study_in_the_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Training_Object_Detectors_From_Scratch_An_Empirical_Study_in_the_CVPR_2022_paper.pdf)
228. C2SLR- Consistency-Enhanced Continuous Sign Language Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zuo_C2SLR_Consistency-Enhanced_Continuous_Sign_Language_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zuo_C2SLR_Consistency-Enhanced_Continuous_Sign_Language_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zuo_C2SLR_Consistency-Enhanced_Continuous_CVPR_2022_supplemental.pdf)
229. Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Label_Relation_Graphs_Enhanced_Hierarchical_Residual_Network_for_Hierarchical_Multi-Granularity_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Label_Relation_Graphs_Enhanced_Hierarchical_Residual_Network_for_Hierarchical_Multi-Granularity_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Label_Relation_Graphs_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.03194)
230. Enhancing Face Recognition With Self-Supervised 3D Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_Enhancing_Face_Recognition_With_Self-Supervised_3D_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Enhancing_Face_Recognition_With_Self-Supervised_3D_Reconstruction_CVPR_2022_paper.pdf)
231. FvOR- Robust Joint Shape and Pose Optimization for Few-View Object Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_FvOR_Robust_Joint_Shape_and_Pose_Optimization_for_Few-View_Object_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_FvOR_Robust_Joint_Shape_and_Pose_Optimization_for_Few-View_Object_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_FvOR_Robust_Joint_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.07763)
232. Few Could Be Better Than All- Feature Sampling and Grouping for Scene Text Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Few_Could_Be_Better_Than_All_Feature_Sampling_and_Grouping_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Few_Could_Be_Better_Than_All_Feature_Sampling_and_Grouping_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_Few_Could_Be_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15221)
233. IDR- Self-Supervised Image Denoising via Iterative Data Refinement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_IDR_Self-Supervised_Image_Denoising_via_Iterative_Data_Refinement_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_IDR_Self-Supervised_Image_Denoising_via_Iterative_Data_Refinement_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_IDR_Self-Supervised_Image_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14358)
234. MogFace- Towards a Deeper Appreciation on Face Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_MogFace_Towards_a_Deeper_Appreciation_on_Face_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_MogFace_Towards_a_Deeper_Appreciation_on_Face_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_MogFace_Towards_a_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2103.11139)
235. Multi-Label Iterated Learning for Image Classification With Label Ambiguity | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rajeswar_Multi-Label_Iterated_Learning_for_Image_Classification_With_Label_Ambiguity_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rajeswar_Multi-Label_Iterated_Learning_for_Image_Classification_With_Label_Ambiguity_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rajeswar_Multi-Label_Iterated_Learning_CVPR_2022_supplemental.pdf)
236. Pushing the Envelope of Gradient Boosting Forests via Globally-Optimized Oblique Trees | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gabidolla_Pushing_the_Envelope_of_Gradient_Boosting_Forests_via_Globally-Optimized_Oblique_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gabidolla_Pushing_the_Envelope_of_Gradient_Boosting_Forests_via_Globally-Optimized_Oblique_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gabidolla_Pushing_the_Envelope_CVPR_2022_supplemental.pdf)
237. Deformable Sprites for Unsupervised Video Decomposition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Deformable_Sprites_for_Unsupervised_Video_Decomposition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Deformable_Sprites_for_Unsupervised_Video_Decomposition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_Deformable_Sprites_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07151)
238. Learning To Detect Mobile Objects From LiDAR Scans Without Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/You_Learning_To_Detect_Mobile_Objects_From_LiDAR_Scans_Without_Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/You_Learning_To_Detect_Mobile_Objects_From_LiDAR_Scans_Without_Labels_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/You_Learning_To_Detect_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15882)
239. Time3D- End-to-End Joint Monocular 3D Object Detection and Tracking for Autonomous Driving | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Time3D_End-to-End_Joint_Monocular_3D_Object_Detection_and_Tracking_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Time3D_End-to-End_Joint_Monocular_3D_Object_Detection_and_Tracking_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Time3D_End-to-End_Joint_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.14882)
240. MonoJSG- Joint Semantic and Geometric Cost Volume for Monocular 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lian_MonoJSG_Joint_Semantic_and_Geometric_Cost_Volume_for_Monocular_3D_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lian_MonoJSG_Joint_Semantic_and_Geometric_Cost_Volume_for_Monocular_3D_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lian_MonoJSG_Joint_Semantic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08563)
241. Efficient Classification of Very Large Images With Tiny Objects | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kong_Efficient_Classification_of_Very_Large_Images_With_Tiny_Objects_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_Efficient_Classification_of_Very_Large_Images_With_Tiny_Objects_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kong_Efficient_Classification_of_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2106.02694)
242. SWEM- Towards Real-Time Video Object Segmentation With Sequential Weighted Expectation-Maximization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_SWEM_Towards_Real-Time_Video_Object_Segmentation_With_Sequential_Weighted_Expectation-Maximization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SWEM_Towards_Real-Time_Video_Object_Segmentation_With_Sequential_Weighted_Expectation-Maximization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_SWEM_Towards_Real-Time_CVPR_2022_supplemental.pdf)
243. Generating Diverse 3D Reconstructions From a Single Occluded Face Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dey_Generating_Diverse_3D_Reconstructions_From_a_Single_Occluded_Face_Image_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dey_Generating_Diverse_3D_Reconstructions_From_a_Single_Occluded_Face_Image_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dey_Generating_Diverse_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00879)
244. RBGNet- Ray-Based Grouping for 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_RBGNet_Ray-Based_Grouping_for_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RBGNet_Ray-Based_Grouping_for_3D_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_RBGNet_Ray-Based_Grouping_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02251)
245. Stand-Alone Inter-Frame Attention in Video Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Long_Stand-Alone_Inter-Frame_Attention_in_Video_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Long_Stand-Alone_Inter-Frame_Attention_in_Video_Models_CVPR_2022_paper.pdf)
246. Memory-Augmented Deep Conditional Unfolding Network for Pan-Sharpening | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Memory-Augmented_Deep_Conditional_Unfolding_Network_for_Pan-Sharpening_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Memory-Augmented_Deep_Conditional_Unfolding_Network_for_Pan-Sharpening_CVPR_2022_paper.pdf)
247. Large-Scale Pre-Training for Person Re-Identification With Noisy Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fu_Large-Scale_Pre-Training_for_Person_Re-Identification_With_Noisy_Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_Large-Scale_Pre-Training_for_Person_Re-Identification_With_Noisy_Labels_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fu_Large-Scale_Pre-Training_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16533)
248. Feature Erasing and Diffusion Network for Occluded Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Feature_Erasing_and_Diffusion_Network_for_Occluded_Person_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Feature_Erasing_and_Diffusion_Network_for_Occluded_Person_Re-Identification_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.08740)
249. Semantic Segmentation by Early Region Proxy | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Semantic_Segmentation_by_Early_Region_Proxy_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Semantic_Segmentation_by_Early_Region_Proxy_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Semantic_Segmentation_by_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14043)
250. GIQE- Generic Image Quality Enhancement via Nth Order Iterative Degradation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shyam_GIQE_Generic_Image_Quality_Enhancement_via_Nth_Order_Iterative_Degradation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shyam_GIQE_Generic_Image_Quality_Enhancement_via_Nth_Order_Iterative_Degradation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shyam_GIQE_Generic_Image_CVPR_2022_supplemental.pdf)
251. Instance Segmentation With Mask-Supervised Polygonal Boundary Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lazarow_Instance_Segmentation_With_Mask-Supervised_Polygonal_Boundary_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lazarow_Instance_Segmentation_With_Mask-Supervised_Polygonal_Boundary_Transformers_CVPR_2022_paper.pdf)
252. Single-Stage 3D Geometry-Preserving Depth Estimation Model Training on Dataset Mixtures With Uncalibrated Stereo Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Patakin_Single-Stage_3D_Geometry-Preserving_Depth_Estimation_Model_Training_on_Dataset_Mixtures_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Patakin_Single-Stage_3D_Geometry-Preserving_Depth_Estimation_Model_Training_on_Dataset_Mixtures_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Patakin_Single-Stage_3D_Geometry-Preserving_CVPR_2022_supplemental.pdf)
253. LD-ConGR- A Large RGB-D Video Dataset for Long-Distance Continuous Gesture Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_LD-ConGR_A_Large_RGB-D_Video_Dataset_for_Long-Distance_Continuous_Gesture_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_LD-ConGR_A_Large_RGB-D_Video_Dataset_for_Long-Distance_Continuous_Gesture_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_LD-ConGR_A_Large_CVPR_2022_supplemental.pdf)
254. SimVQA- Exploring Simulated Environments for Visual Question Answering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cascante-Bonilla_SimVQA_Exploring_Simulated_Environments_for_Visual_Question_Answering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cascante-Bonilla_SimVQA_Exploring_Simulated_Environments_for_Visual_Question_Answering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cascante-Bonilla_SimVQA_Exploring_Simulated_CVPR_2022_supplemental.pdf)
255. Thin-Plate Spline Motion Model for Image Animation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Thin-Plate_Spline_Motion_Model_for_Image_Animation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Thin-Plate_Spline_Motion_Model_for_Image_Animation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_Thin-Plate_Spline_Motion_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14367)
256. Learning Local Displacements for Point Cloud Completion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Learning_Local_Displacements_for_Point_Cloud_Completion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learning_Local_Displacements_for_Point_Cloud_Completion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Learning_Local_Displacements_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16600)
257. Human Hands As Probes for Interactive Object Understanding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Goyal_Human_Hands_As_Probes_for_Interactive_Object_Understanding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Goyal_Human_Hands_As_Probes_for_Interactive_Object_Understanding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Goyal_Human_Hands_As_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.09120)
258. Understanding and Increasing Efficiency of Frank-Wolfe Adversarial Training | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tsiligkaridis_Understanding_and_Increasing_Efficiency_of_Frank-Wolfe_Adversarial_Training_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tsiligkaridis_Understanding_and_Increasing_Efficiency_of_Frank-Wolfe_Adversarial_Training_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tsiligkaridis_Understanding_and_Increasing_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2012.12368)
259. RADU- Ray-Aligned Depth Update Convolutions for ToF Data Denoising | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Schelling_RADU_Ray-Aligned_Depth_Update_Convolutions_for_ToF_Data_Denoising_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Schelling_RADU_Ray-Aligned_Depth_Update_Convolutions_for_ToF_Data_Denoising_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Schelling_RADU_Ray-Aligned_Depth_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15513)
260. Rethinking Visual Geo-Localization for Large-Scale Applications | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Berton_Rethinking_Visual_Geo-Localization_for_Large-Scale_Applications_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Berton_Rethinking_Visual_Geo-Localization_for_Large-Scale_Applications_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Berton_Rethinking_Visual_Geo-Localization_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02287)
261. ViM- Out-of-Distribution With Virtual-Logit Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ViM_Out-of-Distribution_With_Virtual-Logit_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ViM_Out-of-Distribution_With_Virtual-Logit_Matching_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_ViM_Out-of-Distribution_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10807)
262. Towards Accurate Facial Landmark Detection via Cascaded Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Towards_Accurate_Facial_Landmark_Detection_via_Cascaded_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_Accurate_Facial_Landmark_Detection_via_Cascaded_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Towards_Accurate_Facial_CVPR_2022_supplemental.pdf)
263. Long-Term Visual Map Sparsification With Heterogeneous GNN | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chang_Long-Term_Visual_Map_Sparsification_With_Heterogeneous_GNN_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_Long-Term_Visual_Map_Sparsification_With_Heterogeneous_GNN_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chang_Long-Term_Visual_Map_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15182)
264. Dual-AI- Dual-Path Actor Interaction Learning for Group Activity Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Han_Dual-AI_Dual-Path_Actor_Interaction_Learning_for_Group_Activity_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Dual-AI_Dual-Path_Actor_Interaction_Learning_for_Group_Activity_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Han_Dual-AI_Dual-Path_Actor_CVPR_2022_supplemental.pdf)
265. A Brand New Dance Partner- Music-Conditioned Pluralistic Dancing Controlled by Multiple Dance Genres | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_A_Brand_New_Dance_Partner_Music-Conditioned_Pluralistic_Dancing_Controlled_by_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_A_Brand_New_Dance_Partner_Music-Conditioned_Pluralistic_Dancing_Controlled_by_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_A_Brand_New_CVPR_2022_supplemental.pdf)
266. Adaptive Early-Learning Correction for Segmentation From Noisy Annotations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Adaptive_Early-Learning_Correction_for_Segmentation_From_Noisy_Annotations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Adaptive_Early-Learning_Correction_for_Segmentation_From_Noisy_Annotations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Adaptive_Early-Learning_Correction_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.03740)
267. Multi-Scale Memory-Based Video Deblurring | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ji_Multi-Scale_Memory-Based_Video_Deblurring_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ji_Multi-Scale_Memory-Based_Video_Deblurring_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ji_Multi-Scale_Memory-Based_Video_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02977)
268. A Scalable Combinatorial Solver for Elastic Geometrically Consistent 3D Shape Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Roetzer_A_Scalable_Combinatorial_Solver_for_Elastic_Geometrically_Consistent_3D_Shape_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Roetzer_A_Scalable_Combinatorial_Solver_for_Elastic_Geometrically_Consistent_3D_Shape_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Roetzer_A_Scalable_Combinatorial_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.12805)
269. Geometric Structure Preserving Warp for Natural Image Stitching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Du_Geometric_Structure_Preserving_Warp_for_Natural_Image_Stitching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Geometric_Structure_Preserving_Warp_for_Natural_Image_Stitching_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Du_Geometric_Structure_Preserving_CVPR_2022_supplemental.pdf)
270. Focal Length and Object Pose Estimation via Render and Compare | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ponimatkin_Focal_Length_and_Object_Pose_Estimation_via_Render_and_Compare_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ponimatkin_Focal_Length_and_Object_Pose_Estimation_via_Render_and_Compare_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ponimatkin_Focal_Length_and_CVPR_2022_supplemental.pdf)
271. Dynamic 3D Gaze From Afar- Deep Gaze Estimation From Temporal Eye-Head-Body Coordination | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nonaka_Dynamic_3D_Gaze_From_Afar_Deep_Gaze_Estimation_From_Temporal_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nonaka_Dynamic_3D_Gaze_From_Afar_Deep_Gaze_Estimation_From_Temporal_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nonaka_Dynamic_3D_Gaze_CVPR_2022_supplemental.zip)
272. Expressive Talking Head Generation With Granular Audio-Visual Control | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Expressive_Talking_Head_Generation_With_Granular_Audio-Visual_Control_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Expressive_Talking_Head_Generation_With_Granular_Audio-Visual_Control_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liang_Expressive_Talking_Head_CVPR_2022_supplemental.zip)
273. HairMapper- Removing Hair From Portraits Using GANs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_HairMapper_Removing_Hair_From_Portraits_Using_GANs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_HairMapper_Removing_Hair_From_Portraits_Using_GANs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_HairMapper_Removing_Hair_CVPR_2022_supplemental.zip)
274. Out-of-Distribution Generalization With Causal Invariant Transformations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Out-of-Distribution_Generalization_With_Causal_Invariant_Transformations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Out-of-Distribution_Generalization_With_Causal_Invariant_Transformations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Out-of-Distribution_Generalization_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11528)
275. Learning Motion-Dependent Appearance for High-Fidelity Rendering of Dynamic Humans From a Single Camera | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yoon_Learning_Motion-Dependent_Appearance_for_High-Fidelity_Rendering_of_Dynamic_Humans_From_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yoon_Learning_Motion-Dependent_Appearance_for_High-Fidelity_Rendering_of_Dynamic_Humans_From_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yoon_Learning_Motion-Dependent_Appearance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12780)
276. Perturbed and Strict Mean Teachers for Semi-Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Perturbed_and_Strict_Mean_Teachers_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Perturbed_and_Strict_Mean_Teachers_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Perturbed_and_Strict_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12903)
277. IFRNet- Intermediate Feature Refine Network for Efficient Frame Interpolation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kong_IFRNet_Intermediate_Feature_Refine_Network_for_Efficient_Frame_Interpolation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_IFRNet_Intermediate_Feature_Refine_Network_for_Efficient_Frame_Interpolation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kong_IFRNet_Intermediate_Feature_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.14620)
278. Toward Practical Monocular Indoor Depth Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Toward_Practical_Monocular_Indoor_Depth_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Toward_Practical_Monocular_Indoor_Depth_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Toward_Practical_Monocular_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02306)
279. Speed Up Object Detection on Gigapixel-Level Images With Patch Arrangement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Speed_Up_Object_Detection_on_Gigapixel-Level_Images_With_Patch_Arrangement_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Speed_Up_Object_Detection_on_Gigapixel-Level_Images_With_Patch_Arrangement_CVPR_2022_paper.pdf)
280. Neural Recognition of Dashed Curves With Gestalt Law of Continuity | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Neural_Recognition_of_Dashed_Curves_With_Gestalt_Law_of_Continuity_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Neural_Recognition_of_Dashed_Curves_With_Gestalt_Law_of_Continuity_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Neural_Recognition_of_CVPR_2022_supplemental.pdf)
281. HODOR- High-Level Object Descriptors for Object Re-Segmentation in Video Learned From Static Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Athar_HODOR_High-Level_Object_Descriptors_for_Object_Re-Segmentation_in_Video_Learned_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Athar_HODOR_High-Level_Object_Descriptors_for_Object_Re-Segmentation_in_Video_Learned_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Athar_HODOR_High-Level_Object_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2112.09131)
282. MLSLT- Towards Multilingual Sign Language Translation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yin_MLSLT_Towards_Multilingual_Sign_Language_Translation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_MLSLT_Towards_Multilingual_Sign_Language_Translation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yin_MLSLT_Towards_Multilingual_CVPR_2022_supplemental.pdf)
283. Contrastive Test-Time Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Contrastive_Test-Time_Adaptation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Contrastive_Test-Time_Adaptation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.10377)
284. Collaborative Learning for Hand and Object Reconstruction With Attention-Guided Graph Convolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tse_Collaborative_Learning_for_Hand_and_Object_Reconstruction_With_Attention-Guided_Graph_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tse_Collaborative_Learning_for_Hand_and_Object_Reconstruction_With_Attention-Guided_Graph_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tse_Collaborative_Learning_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.13062)
285. Regional Semantic Contrast and Aggregation for Weakly Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Regional_Semantic_Contrast_and_Aggregation_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Regional_Semantic_Contrast_and_Aggregation_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Regional_Semantic_Contrast_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09653)
286. Class Re-Activation Maps for Weakly-Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Class_Re-Activation_Maps_for_Weakly-Supervised_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Class_Re-Activation_Maps_for_Weakly-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.00962)
287. TransWeather- Transformer-Based Restoration of Images Degraded by Adverse Weather Conditions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Valanarasu_TransWeather_Transformer-Based_Restoration_of_Images_Degraded_by_Adverse_Weather_Conditions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Valanarasu_TransWeather_Transformer-Based_Restoration_of_Images_Degraded_by_Adverse_Weather_Conditions_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.14813)
288. P3Depth- Monocular Depth Estimation With a Piecewise Planarity Prior | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Patil_P3Depth_Monocular_Depth_Estimation_With_a_Piecewise_Planarity_Prior_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Patil_P3Depth_Monocular_Depth_Estimation_With_a_Piecewise_Planarity_Prior_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Patil_P3Depth_Monocular_Depth_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02091)
289. MLP-3D- A MLP-Like 3D Architecture With Grouped Time Mixing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qiu_MLP-3D_A_MLP-Like_3D_Architecture_With_Grouped_Time_Mixing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qiu_MLP-3D_A_MLP-Like_3D_Architecture_With_Grouped_Time_Mixing_CVPR_2022_paper.pdf)
290. BANMo- Building Animatable 3D Neural Models From Many Casual Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_BANMo_Building_Animatable_3D_Neural_Models_From_Many_Casual_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_BANMo_Building_Animatable_3D_Neural_Models_From_Many_Casual_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_BANMo_Building_Animatable_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.12761)
291. Language As Queries for Referring Video Object Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Language_As_Queries_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Language_As_Queries_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Language_As_Queries_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.00487)
292. Investigating the Impact of Multi-LiDAR Placement on Object Detection for Autonomous Driving | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Investigating_the_Impact_of_Multi-LiDAR_Placement_on_Object_Detection_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Investigating_the_Impact_of_Multi-LiDAR_Placement_on_Object_Detection_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_Investigating_the_Impact_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2105.00373)
293. MViTv2- Improved Multiscale Vision Transformers for Classification and Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_MViTv2_Improved_Multiscale_Vision_Transformers_for_Classification_and_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_MViTv2_Improved_Multiscale_Vision_Transformers_for_Classification_and_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_MViTv2_Improved_Multiscale_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01526)
294. Self-Supervised Arbitrary-Scale Point Clouds Upsampling via Implicit Neural Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Self-Supervised_Arbitrary-Scale_Point_Clouds_Upsampling_via_Implicit_Neural_Representation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Self-Supervised_Arbitrary-Scale_Point_Clouds_Upsampling_via_Implicit_Neural_Representation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.08196)
295. AIM- An Auto-Augmenter for Images and Meshes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Singh_AIM_An_Auto-Augmenter_for_Images_and_Meshes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_AIM_An_Auto-Augmenter_for_Images_and_Meshes_CVPR_2022_paper.pdf)
296. VISOLO- Grid-Based Space-Time Aggregation for Efficient Online Video Instance Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Han_VISOLO_Grid-Based_Space-Time_Aggregation_for_Efficient_Online_Video_Instance_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_VISOLO_Grid-Based_Space-Time_Aggregation_for_Efficient_Online_Video_Instance_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Han_VISOLO_Grid-Based_Space-Time_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.04177)
297. Incremental Learning in Semantic Segmentation From Image Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cermelli_Incremental_Learning_in_Semantic_Segmentation_From_Image_Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cermelli_Incremental_Learning_in_Semantic_Segmentation_From_Image_Labels_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cermelli_Incremental_Learning_in_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01882)
298. Playable Environments- Video Manipulation in Space and Time | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Menapace_Playable_Environments_Video_Manipulation_in_Space_and_Time_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Menapace_Playable_Environments_Video_Manipulation_in_Space_and_Time_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Menapace_Playable_Environments_Video_CVPR_2022_supplemental.pdf)
299. CO-SNE- Dimensionality Reduction and Visualization for Hyperbolic Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_CO-SNE_Dimensionality_Reduction_and_Visualization_for_Hyperbolic_Data_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_CO-SNE_Dimensionality_Reduction_and_Visualization_for_Hyperbolic_Data_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_CO-SNE_Dimensionality_Reduction_CVPR_2022_supplemental.pdf)
300. Revisiting Skeleton-Based Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Duan_Revisiting_Skeleton-Based_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_Revisiting_Skeleton-Based_Action_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Duan_Revisiting_Skeleton-Based_Action_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2104.13586)
301. LOLNerf- Learn From One Look | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rebain_LOLNerf_Learn_From_One_Look_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rebain_LOLNerf_Learn_From_One_Look_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rebain_LOLNerf_Learn_From_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.09996)
302. Geometry-Aware Guided Loss for Deep Crack Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Geometry-Aware_Guided_Loss_for_Deep_Crack_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Geometry-Aware_Guided_Loss_for_Deep_Crack_Recognition_CVPR_2022_paper.pdf)
303. Maintaining Reasoning Consistency in Compositional Visual Question Answering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jing_Maintaining_Reasoning_Consistency_in_Compositional_Visual_Question_Answering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jing_Maintaining_Reasoning_Consistency_in_Compositional_Visual_Question_Answering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jing_Maintaining_Reasoning_Consistency_CVPR_2022_supplemental.pdf)
304. Structure-Aware Motion Transfer With Deformable Anchor Model | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tao_Structure-Aware_Motion_Transfer_With_Deformable_Anchor_Model_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Structure-Aware_Motion_Transfer_With_Deformable_Anchor_Model_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tao_Structure-Aware_Motion_Transfer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.05018)
305. Pix2NeRF- Unsupervised Conditional p-GAN for Single Image to Neural Radiance Fields Translation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cai_Pix2NeRF_Unsupervised_Conditional_p-GAN_for_Single_Image_to_Neural_Radiance_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Pix2NeRF_Unsupervised_Conditional_p-GAN_for_Single_Image_to_Neural_Radiance_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cai_Pix2NeRF_Unsupervised_Conditional_CVPR_2022_supplemental.pdf)
306. Rethinking Image Cropping- Exploring Diverse Compositions From Global Views | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jia_Rethinking_Image_Cropping_Exploring_Diverse_Compositions_From_Global_Views_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_Rethinking_Image_Cropping_Exploring_Diverse_Compositions_From_Global_Views_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jia_Rethinking_Image_Cropping_CVPR_2022_supplemental.pdf)
307. Threshold Matters in WSSS- Manipulating the Activation for the Robust and Accurate Segmentation Model Against Thresholds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Threshold_Matters_in_WSSS_Manipulating_the_Activation_for_the_Robust_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Threshold_Matters_in_WSSS_Manipulating_the_Activation_for_the_Robust_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Threshold_Matters_in_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.16045)
308. Data-Free Network Compression via Parametric Non-Uniform Mixed Precision Quantization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chikin_Data-Free_Network_Compression_via_Parametric_Non-Uniform_Mixed_Precision_Quantization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chikin_Data-Free_Network_Compression_via_Parametric_Non-Uniform_Mixed_Precision_Quantization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chikin_Data-Free_Network_Compression_CVPR_2022_supplemental.pdf)
309. ROCA- Robust CAD Model Retrieval and Alignment From a Single Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gumeli_ROCA_Robust_CAD_Model_Retrieval_and_Alignment_From_a_Single_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gumeli_ROCA_Robust_CAD_Model_Retrieval_and_Alignment_From_a_Single_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gumeli_ROCA_Robust_CAD_CVPR_2022_supplemental.pdf)
310. Wnet- Audio-Guided Video Object Segmentation via Wavelet-Based Cross-Modal Denoising Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pan_Wnet_Audio-Guided_Video_Object_Segmentation_via_Wavelet-Based_Cross-Modal_Denoising_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Wnet_Audio-Guided_Video_Object_Segmentation_via_Wavelet-Based_Cross-Modal_Denoising_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Pan_Wnet_Audio-Guided_Video_CVPR_2022_supplemental.zip)
311. PubTables-1M- Towards Comprehensive Table Extraction From Unstructured Documents | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Smock_PubTables-1M_Towards_Comprehensive_Table_Extraction_From_Unstructured_Documents_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Smock_PubTables-1M_Towards_Comprehensive_Table_Extraction_From_Unstructured_Documents_CVPR_2022_paper.pdf)
312. Meta-Attention for ViT-Backed Continual Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Meta-Attention_for_ViT-Backed_Continual_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Meta-Attention_for_ViT-Backed_Continual_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xue_Meta-Attention_for_ViT-Backed_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11684)
313. Photorealistic Monocular 3D Reconstruction of Humans Wearing Clothing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Alldieck_Photorealistic_Monocular_3D_Reconstruction_of_Humans_Wearing_Clothing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Alldieck_Photorealistic_Monocular_3D_Reconstruction_of_Humans_Wearing_Clothing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Alldieck_Photorealistic_Monocular_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.08906)
314. Generalizing Interactive Backpropagating Refinement for Dense Prediction Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Generalizing_Interactive_Backpropagating_Refinement_for_Dense_Prediction_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Generalizing_Interactive_Backpropagating_Refinement_for_Dense_Prediction_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_Generalizing_Interactive_Backpropagating_CVPR_2022_supplemental.pdf)
315. Look Outside the Room- Synthesizing a Consistent Long-Term 3D Scene Video From a Single Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Look_Outside_the_Room_Synthesizing_a_Consistent_Long-Term_3D_Scene_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Look_Outside_the_Room_Synthesizing_a_Consistent_Long-Term_3D_Scene_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ren_Look_Outside_the_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09457)
316. Full-Range Virtual Try-On With Recurrent Tri-Level Transform | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Full-Range_Virtual_Try-On_With_Recurrent_Tri-Level_Transform_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Full-Range_Virtual_Try-On_With_Recurrent_Tri-Level_Transform_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Full-Range_Virtual_Try-On_CVPR_2022_supplemental.pdf)
317. Multiview Transformers for Video Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yan_Multiview_Transformers_for_Video_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Multiview_Transformers_for_Video_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yan_Multiview_Transformers_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.04288)
318. Learning Structured Gaussians To Approximate Deep Ensembles | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Simpson_Learning_Structured_Gaussians_To_Approximate_Deep_Ensembles_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Simpson_Learning_Structured_Gaussians_To_Approximate_Deep_Ensembles_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Simpson_Learning_Structured_Gaussians_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.15485)
319. Total Variation Optimization Layers for Computer Vision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yeh_Total_Variation_Optimization_Layers_for_Computer_Vision_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yeh_Total_Variation_Optimization_Layers_for_Computer_Vision_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.03643)
320. Defensive Patches for Robust Recognition in the Physical World | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Defensive_Patches_for_Robust_Recognition_in_the_Physical_World_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Defensive_Patches_for_Robust_Recognition_in_the_Physical_World_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Defensive_Patches_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.06213)
321. Sequential Voting With Relational Box Fields for Active Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fu_Sequential_Voting_With_Relational_Box_Fields_for_Active_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_Sequential_Voting_With_Relational_Box_Fields_for_Active_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fu_Sequential_Voting_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.11524)
322. Learning Transferable Human-Object Interaction Detector With Natural Language Supervision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Learning_Transferable_Human-Object_Interaction_Detector_With_Natural_Language_Supervision_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learning_Transferable_Human-Object_Interaction_Detector_With_Natural_Language_Supervision_CVPR_2022_paper.pdf)
323. Fourier Document Restoration for Robust Document Dewarping and Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Fourier_Document_Restoration_for_Robust_Document_Dewarping_and_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Fourier_Document_Restoration_for_Robust_Document_Dewarping_and_Recognition_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.09910)
324. Consistency Learning via Decoding Path Augmentation for Transformers in Human Object Interaction Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Park_Consistency_Learning_via_Decoding_Path_Augmentation_for_Transformers_in_Human_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Consistency_Learning_via_Decoding_Path_Augmentation_for_Transformers_in_Human_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Park_Consistency_Learning_via_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04836)
325. Learning With Neighbor Consistency for Noisy Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Iscen_Learning_With_Neighbor_Consistency_for_Noisy_Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Iscen_Learning_With_Neighbor_Consistency_for_Noisy_Labels_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Iscen_Learning_With_Neighbor_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.02200)
326. Depth Estimation by Combining Binocular Stereo and Monocular Structured-Light | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Depth_Estimation_by_Combining_Binocular_Stereo_and_Monocular_Structured-Light_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Depth_Estimation_by_Combining_Binocular_Stereo_and_Monocular_Structured-Light_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Depth_Estimation_by_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10493)
327. Object-Region Video Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Herzig_Object-Region_Video_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Herzig_Object-Region_Video_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Herzig_Object-Region_Video_Transformers_CVPR_2022_supplemental.pdf)
328. AME- Attention and Memory Enhancement in Hyper-Parameter Optimization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_AME_Attention_and_Memory_Enhancement_in_Hyper-Parameter_Optimization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_AME_Attention_and_Memory_Enhancement_in_Hyper-Parameter_Optimization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_AME_Attention_and_CVPR_2022_supplemental.pdf)
329. RepMLPNet- Hierarchical Vision MLP With Re-Parameterized Locality | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_RepMLPNet_Hierarchical_Vision_MLP_With_Re-Parameterized_Locality_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_RepMLPNet_Hierarchical_Vision_MLP_With_Re-Parameterized_Locality_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ding_RepMLPNet_Hierarchical_Vision_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.11081)
330. DR.VIC- Decomposition and Reasoning for Video Individual Counting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Han_DR.VIC_Decomposition_and_Reasoning_for_Video_Individual_Counting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_DR.VIC_Decomposition_and_Reasoning_for_Video_Individual_Counting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Han_DR.VIC_Decomposition_and_CVPR_2022_supplemental.pdf)
331. Revisiting Document Image Dewarping by Grid Regularization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Revisiting_Document_Image_Dewarping_by_Grid_Regularization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Revisiting_Document_Image_Dewarping_by_Grid_Regularization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jiang_Revisiting_Document_Image_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16850)
332. CMT-DeepLab- Clustering Mask Transformers for Panoptic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_CMT-DeepLab_Clustering_Mask_Transformers_for_Panoptic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_CMT-DeepLab_Clustering_Mask_Transformers_for_Panoptic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_CMT-DeepLab_Clustering_Mask_CVPR_2022_supplemental.pdf)
333. Novel Class Discovery in Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Novel_Class_Discovery_in_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Novel_Class_Discovery_in_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_Novel_Class_Discovery_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01900)
334. GCFSR- A Generative and Controllable Face Super Resolution Method Without Facial and GAN Priors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_GCFSR_A_Generative_and_Controllable_Face_Super_Resolution_Method_Without_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_GCFSR_A_Generative_and_Controllable_Face_Super_Resolution_Method_Without_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_GCFSR_A_Generative_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.07319)
335. Using 3D Topological Connectivity for Ghost Particle Reduction in Flow Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tsalicoglou_Using_3D_Topological_Connectivity_for_Ghost_Particle_Reduction_in_Flow_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tsalicoglou_Using_3D_Topological_Connectivity_for_Ghost_Particle_Reduction_in_Flow_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tsalicoglou_Using_3D_Topological_CVPR_2022_supplemental.pdf)
336. On the Integration of Self-Attention and Convolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pan_On_the_Integration_of_Self-Attention_and_Convolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_On_the_Integration_of_Self-Attention_and_Convolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Pan_On_the_Integration_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14556)
337. Consistency Driven Sequential Transformers Attention Model for Partially Observable Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rangrej_Consistency_Driven_Sequential_Transformers_Attention_Model_for_Partially_Observable_Scenes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rangrej_Consistency_Driven_Sequential_Transformers_Attention_Model_for_Partially_Observable_Scenes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rangrej_Consistency_Driven_Sequential_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00656)
338. DiffusionCLIP- Text-Guided Diffusion Models for Robust Image Manipulation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_DiffusionCLIP_Text-Guided_Diffusion_Models_for_Robust_Image_Manipulation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_DiffusionCLIP_Text-Guided_Diffusion_Models_for_Robust_Image_Manipulation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_DiffusionCLIP_Text-Guided_Diffusion_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.02711)
339. GlideNet- Global, Local and Intrinsic Based Dense Embedding NETwork for Multi-Category Attributes Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Metwaly_GlideNet_Global_Local_and_Intrinsic_Based_Dense_Embedding_NETwork_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Metwaly_GlideNet_Global_Local_and_Intrinsic_Based_Dense_Embedding_NETwork_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Metwaly_GlideNet_Global_Local_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03079)
340. Towards Better Plasticity-Stability Trade-Off in Incremental Learning- A Simple Linear Connector | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Towards_Better_Plasticity-Stability_Trade-Off_in_Incremental_Learning_A_Simple_Linear_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Towards_Better_Plasticity-Stability_Trade-Off_in_Incremental_Learning_A_Simple_Linear_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2110.07905)
341. Delving Into the Estimation Shift of Batch Normalization in a Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Delving_Into_the_Estimation_Shift_of_Batch_Normalization_in_a_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Delving_Into_the_Estimation_Shift_of_Batch_Normalization_in_a_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Delving_Into_the_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.10778)
342. Joint Forecasting of Panoptic Segmentations With Difference Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Graber_Joint_Forecasting_of_Panoptic_Segmentations_With_Difference_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Graber_Joint_Forecasting_of_Panoptic_Segmentations_With_Difference_Attention_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Graber_Joint_Forecasting_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07157)
343. Imposing Consistency for Optical Flow Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jeong_Imposing_Consistency_for_Optical_Flow_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jeong_Imposing_Consistency_for_Optical_Flow_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jeong_Imposing_Consistency_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07262)
344. Towards Robust and Reproducible Active Learning Using Neural Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Munjal_Towards_Robust_and_Reproducible_Active_Learning_Using_Neural_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Munjal_Towards_Robust_and_Reproducible_Active_Learning_Using_Neural_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Munjal_Towards_Robust_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2002.09564)
345. Temporally Efficient Vision Transformer for Video Instance Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Temporally_Efficient_Vision_Transformer_for_Video_Instance_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Temporally_Efficient_Vision_Transformer_for_Video_Instance_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.08412)
346. The Devil Is in the Margin- Margin-Based Label Smoothing for Network Calibration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_The_Devil_Is_in_the_Margin_Margin-Based_Label_Smoothing_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_The_Devil_Is_in_the_Margin_Margin-Based_Label_Smoothing_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_The_Devil_Is_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15430)
347. Revealing Occlusions With 4D Neural Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Van_Hoorick_Revealing_Occlusions_With_4D_Neural_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Van_Hoorick_Revealing_Occlusions_With_4D_Neural_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Van_Hoorick_Revealing_Occlusions_With_CVPR_2022_supplemental.pdf)
348. Self-Supervised Deep Image Restoration via Adaptive Stochastic Gradient Langevin Dynamics | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Self-Supervised_Deep_Image_Restoration_via_Adaptive_Stochastic_Gradient_Langevin_Dynamics_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Self-Supervised_Deep_Image_Restoration_via_Adaptive_Stochastic_Gradient_Langevin_Dynamics_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Self-Supervised_Deep_Image_CVPR_2022_supplemental.pdf)
349. AutoLoss-Zero- Searching Loss Functions From Scratch for Generic Tasks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_AutoLoss-Zero_Searching_Loss_Functions_From_Scratch_for_Generic_Tasks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_AutoLoss-Zero_Searching_Loss_Functions_From_Scratch_for_Generic_Tasks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_AutoLoss-Zero_Searching_Loss_CVPR_2022_supplemental.pdf)
350. Scalable Penalized Regression for Noise Detection in Learning With Noisy Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Scalable_Penalized_Regression_for_Noise_Detection_in_Learning_With_Noisy_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Scalable_Penalized_Regression_for_Noise_Detection_in_Learning_With_Noisy_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.07788)
351. Registering Explicit to Implicit- Towards High-Fidelity Garment Mesh Reconstruction From Single Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Registering_Explicit_to_Implicit_Towards_High-Fidelity_Garment_Mesh_Reconstruction_From_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Registering_Explicit_to_Implicit_Towards_High-Fidelity_Garment_Mesh_Reconstruction_From_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Registering_Explicit_to_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15007)
352. Layered Depth Refinement With Mask Guidance | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Layered_Depth_Refinement_With_Mask_Guidance_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Layered_Depth_Refinement_With_Mask_Guidance_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Layered_Depth_Refinement_CVPR_2022_supplemental.zip)
353. LAKe-Net- Topology-Aware Point Cloud Completion by Localizing Aligned Keypoints | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_LAKe-Net_Topology-Aware_Point_Cloud_Completion_by_Localizing_Aligned_Keypoints_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_LAKe-Net_Topology-Aware_Point_Cloud_Completion_by_Localizing_Aligned_Keypoints_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_LAKe-Net_Topology-Aware_Point_CVPR_2022_supplemental.pdf)
354. Scribble-Supervised LiDAR Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Unal_Scribble-Supervised_LiDAR_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Unal_Scribble-Supervised_LiDAR_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Unal_Scribble-Supervised_LiDAR_Semantic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08537)
355. Vision Transformer Slimming- Multi-Dimension Searching in Continuous Optimization Space | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chavan_Vision_Transformer_Slimming_Multi-Dimension_Searching_in_Continuous_Optimization_Space_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chavan_Vision_Transformer_Slimming_Multi-Dimension_Searching_in_Continuous_Optimization_Space_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2201.00814)
356. Brain-Inspired Multilayer Perceptron With Spiking Neurons | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Brain-Inspired_Multilayer_Perceptron_With_Spiking_Neurons_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Brain-Inspired_Multilayer_Perceptron_With_Spiking_Neurons_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.14679)
357. Learning To Estimate Robust 3D Human Mesh From In-the-Wild Crowded Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Choi_Learning_To_Estimate_Robust_3D_Human_Mesh_From_In-the-Wild_Crowded_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Choi_Learning_To_Estimate_Robust_3D_Human_Mesh_From_In-the-Wild_Crowded_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Choi_Learning_To_Estimate_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.07300)
358. ObjectFormer for Image Manipulation Detection and Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ObjectFormer_for_Image_Manipulation_Detection_and_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ObjectFormer_for_Image_Manipulation_Detection_and_Localization_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.14681)
359. Towards Semi-Supervised Deep Facial Expression Recognition With an Adaptive Confidence Margin | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Towards_Semi-Supervised_Deep_Facial_Expression_Recognition_With_an_Adaptive_Confidence_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_Semi-Supervised_Deep_Facial_Expression_Recognition_With_an_Adaptive_Confidence_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Towards_Semi-Supervised_Deep_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12341)
360. Masked-Attention Mask Transformer for Universal Image Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Masked-Attention_Mask_Transformer_for_Universal_Image_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Masked-Attention_Mask_Transformer_for_Universal_Image_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cheng_Masked-Attention_Mask_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01527)
361. Language-Bridged Spatial-Temporal Interaction for Referring Video Object Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Language-Bridged_Spatial-Temporal_Interaction_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Language-Bridged_Spatial-Temporal_Interaction_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.pdf)
362. Adaptive Hierarchical Representation Learning for Long-Tailed Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Adaptive_Hierarchical_Representation_Learning_for_Long-Tailed_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Adaptive_Hierarchical_Representation_Learning_for_Long-Tailed_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Adaptive_Hierarchical_Representation_CVPR_2022_supplemental.pdf)
363. Whose Hands Are These- Hand Detection and Hand-Body Association in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Narasimhaswamy_Whose_Hands_Are_These_Hand_Detection_and_Hand-Body_Association_in_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Narasimhaswamy_Whose_Hands_Are_These_Hand_Detection_and_Hand-Body_Association_in_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Narasimhaswamy_Whose_Hands_Are_CVPR_2022_supplemental.pdf)
364. Training Quantised Neural Networks With STE Variants- The Additive Noise Annealing Algorithm | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Spallanzani_Training_Quantised_Neural_Networks_With_STE_Variants_The_Additive_Noise_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Spallanzani_Training_Quantised_Neural_Networks_With_STE_Variants_The_Additive_Noise_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Spallanzani_Training_Quantised_Neural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11323)
365. Split Hierarchical Variational Compression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ryder_Split_Hierarchical_Variational_Compression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ryder_Split_Hierarchical_Variational_Compression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ryder_Split_Hierarchical_Variational_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02071)
366. Video Swin Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Video_Swin_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Video_Swin_Transformer_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2106.13230)
367. BoxeR- Box-Attention for 2D and 3D Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_BoxeR_Box-Attention_for_2D_and_3D_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_BoxeR_Box-Attention_for_2D_and_3D_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nguyen_BoxeR_Box-Attention_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13087)
368. A Proposal-Based Paradigm for Self-Supervised Sound Source Localization in Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xuan_A_Proposal-Based_Paradigm_for_Self-Supervised_Sound_Source_Localization_in_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xuan_A_Proposal-Based_Paradigm_for_Self-Supervised_Sound_Source_Localization_in_Videos_CVPR_2022_paper.pdf)
369. P3IV- Probabilistic Procedure Planning From Instructional Videos With Weak Supervision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_P3IV_Probabilistic_Procedure_Planning_From_Instructional_Videos_With_Weak_Supervision_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_P3IV_Probabilistic_Procedure_Planning_From_Instructional_Videos_With_Weak_Supervision_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_P3IV_Probabilistic_Procedure_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.02300)
370. Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sarfraz_Hierarchical_Nearest_Neighbor_Graph_Embedding_for_Efficient_Dimensionality_Reduction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sarfraz_Hierarchical_Nearest_Neighbor_Graph_Embedding_for_Efficient_Dimensionality_Reduction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sarfraz_Hierarchical_Nearest_Neighbor_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12997)
371. Semi-Supervised Video Paragraph Grounding With Contrastive Encoder | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Semi-Supervised_Video_Paragraph_Grounding_With_Contrastive_Encoder_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Semi-Supervised_Video_Paragraph_Grounding_With_Contrastive_Encoder_CVPR_2022_paper.pdf)
372. BARC- Learning To Regress 3D Dog Shape From Images by Exploiting Breed Information | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ruegg_BARC_Learning_To_Regress_3D_Dog_Shape_From_Images_by_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ruegg_BARC_Learning_To_Regress_3D_Dog_Shape_From_Images_by_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ruegg_BARC_Learning_To_CVPR_2022_supplemental.pdf)
373. Frame Averaging for Equivariant Shape Space Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Atzmon_Frame_Averaging_for_Equivariant_Shape_Space_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Atzmon_Frame_Averaging_for_Equivariant_Shape_Space_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Atzmon_Frame_Averaging_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01741)
374. Panoptic SegFormer- Delving Deeper Into Panoptic Segmentation With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Panoptic_SegFormer_Delving_Deeper_Into_Panoptic_Segmentation_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Panoptic_SegFormer_Delving_Deeper_Into_Panoptic_Segmentation_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Panoptic_SegFormer_Delving_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2109.03814)
375. Hypergraph-Induced Semantic Tuplet Loss for Deep Metric Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lim_Hypergraph-Induced_Semantic_Tuplet_Loss_for_Deep_Metric_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lim_Hypergraph-Induced_Semantic_Tuplet_Loss_for_Deep_Metric_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lim_Hypergraph-Induced_Semantic_Tuplet_CVPR_2022_supplemental.pdf)
376. Computing Wasserstein-p Distance Between Images With Linear Cost | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Computing_Wasserstein-p_Distance_Between_Images_With_Linear_Cost_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Computing_Wasserstein-p_Distance_Between_Images_With_Linear_Cost_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Computing_Wasserstein-p_Distance_CVPR_2022_supplemental.pdf)
377. DLFormer- Discrete Latent Transformer for Video Inpainting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_DLFormer_Discrete_Latent_Transformer_for_Video_Inpainting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_DLFormer_Discrete_Latent_Transformer_for_Video_Inpainting_CVPR_2022_paper.pdf)
378. High Quality Segmentation for Ultra High-Resolution Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shen_High_Quality_Segmentation_for_Ultra_High-Resolution_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_High_Quality_Segmentation_for_Ultra_High-Resolution_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shen_High_Quality_Segmentation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14482)
379. Aesthetic Text Logo Synthesis via Content-Aware Layout Inferring | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Aesthetic_Text_Logo_Synthesis_via_Content-Aware_Layout_Inferring_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Aesthetic_Text_Logo_Synthesis_via_Content-Aware_Layout_Inferring_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Aesthetic_Text_Logo_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.02701)
380. Oriented RepPoints for Aerial Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Oriented_RepPoints_for_Aerial_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Oriented_RepPoints_for_Aerial_Object_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2105.11111)
381. OccAM's Laser- Occlusion-Based Attribution Maps for 3D Object Detectors on LiDAR Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Schinagl_OccAMs_Laser_Occlusion-Based_Attribution_Maps_for_3D_Object_Detectors_on_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Schinagl_OccAMs_Laser_Occlusion-Based_Attribution_Maps_for_3D_Object_Detectors_on_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Schinagl_OccAMs_Laser_Occlusion-Based_CVPR_2022_supplemental.pdf)
382. Pre-Train, Self-Train, Distill- A Simple Recipe for Supersizing 3D Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Alwala_Pre-Train_Self-Train_Distill_A_Simple_Recipe_for_Supersizing_3D_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Alwala_Pre-Train_Self-Train_Distill_A_Simple_Recipe_for_Supersizing_3D_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Alwala_Pre-Train_Self-Train_Distill_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03642)
383. Meta Distribution Alignment for Generalizable Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ni_Meta_Distribution_Alignment_for_Generalizable_Person_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ni_Meta_Distribution_Alignment_for_Generalizable_Person_Re-Identification_CVPR_2022_paper.pdf)
384. BoosterNet- Improving Domain Generalization of Deep Neural Nets Using Culpability-Ranked Features | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bayasi_BoosterNet_Improving_Domain_Generalization_of_Deep_Neural_Nets_Using_Culpability-Ranked_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bayasi_BoosterNet_Improving_Domain_Generalization_of_Deep_Neural_Nets_Using_Culpability-Ranked_CVPR_2022_paper.pdf)
385. Selective-Supervised Contrastive Learning With Noisy Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Selective-Supervised_Contrastive_Learning_With_Noisy_Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Selective-Supervised_Contrastive_Learning_With_Noisy_Labels_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Selective-Supervised_Contrastive_Learning_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.04181)
386. Co-Domain Symmetry for Complex-Valued Deep Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Singhal_Co-Domain_Symmetry_for_Complex-Valued_Deep_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Singhal_Co-Domain_Symmetry_for_Complex-Valued_Deep_Learning_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.01525)
387. Neural Collaborative Graph Machines for Table Structure Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Neural_Collaborative_Graph_Machines_for_Table_Structure_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Neural_Collaborative_Graph_Machines_for_Table_Structure_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Neural_Collaborative_Graph_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13359)
388. Learning Affordance Grounding From Exocentric Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Luo_Learning_Affordance_Grounding_From_Exocentric_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Learning_Affordance_Grounding_From_Exocentric_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Luo_Learning_Affordance_Grounding_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09905)
389. C2AM- Contrastive Learning of Class-Agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_C2AM_Contrastive_Learning_of_Class-Agnostic_Activation_Map_for_Weakly_Supervised_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_C2AM_Contrastive_Learning_of_Class-Agnostic_Activation_Map_for_Weakly_Supervised_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xie_C2AM_Contrastive_Learning_CVPR_2022_supplemental.pdf)
390. Understanding 3D Object Articulation in Internet Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qian_Understanding_3D_Object_Articulation_in_Internet_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qian_Understanding_3D_Object_Articulation_in_Internet_Videos_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16531)
391. Multi-Level Representation Learning With Semantic Alignment for Referring Video Object Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Multi-Level_Representation_Learning_With_Semantic_Alignment_for_Referring_Video_Object_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Multi-Level_Representation_Learning_With_Semantic_Alignment_for_Referring_Video_Object_CVPR_2022_paper.pdf)
392. Paramixer- Parameterizing Mixing Links in Sparse Factors Works Better Than Dot-Product Self-Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Paramixer_Parameterizing_Mixing_Links_in_Sparse_Factors_Works_Better_Than_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Paramixer_Parameterizing_Mixing_Links_in_Sparse_Factors_Works_Better_Than_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_Paramixer_Parameterizing_Mixing_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.10670)
393. Pseudo-Stereo for Monocular 3D Object Detection in Autonomous Driving | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Pseudo-Stereo_for_Monocular_3D_Object_Detection_in_Autonomous_Driving_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Pseudo-Stereo_for_Monocular_3D_Object_Detection_in_Autonomous_Driving_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Pseudo-Stereo_for_Monocular_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02112)
394. Syntax-Aware Network for Handwritten Mathematical Expression Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_Syntax-Aware_Network_for_Handwritten_Mathematical_Expression_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Syntax-Aware_Network_for_Handwritten_Mathematical_Expression_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yuan_Syntax-Aware_Network_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01601)
395. Sketching Without Worrying- Noise-Tolerant Sketch-Based Image Retrieval | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bhunia_Sketching_Without_Worrying_Noise-Tolerant_Sketch-Based_Image_Retrieval_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bhunia_Sketching_Without_Worrying_Noise-Tolerant_Sketch-Based_Image_Retrieval_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bhunia_Sketching_Without_Worrying_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14817)
396. PUMP- Pyramidal and Uniqueness Matching Priors for Unsupervised Learning of Local Descriptors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Revaud_PUMP_Pyramidal_and_Uniqueness_Matching_Priors_for_Unsupervised_Learning_of_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Revaud_PUMP_Pyramidal_and_Uniqueness_Matching_Priors_for_Unsupervised_Learning_of_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Revaud_PUMP_Pyramidal_and_CVPR_2022_supplemental.pdf)
397. Deep Equilibrium Optical Flow Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bai_Deep_Equilibrium_Optical_Flow_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Deep_Equilibrium_Optical_Flow_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bai_Deep_Equilibrium_Optical_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.08442)
398. Joint Hand Motion and Interaction Hotspots Prediction From Egocentric Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Joint_Hand_Motion_and_Interaction_Hotspots_Prediction_From_Egocentric_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Joint_Hand_Motion_and_Interaction_Hotspots_Prediction_From_Egocentric_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Joint_Hand_Motion_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01696)
399. Revisiting the "Video" in Video-Language Understanding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Buch_Revisiting_the_Video_in_Video-Language_Understanding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Buch_Revisiting_the_Video_in_Video-Language_Understanding_CVPR_2022_paper.pdf)
400. Local Texture Estimator for Implicit Representation Function | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Local_Texture_Estimator_for_Implicit_Representation_Function_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Local_Texture_Estimator_for_Implicit_Representation_Function_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.08918)
401. A Voxel Graph CNN for Object Classification With Event Cameras | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Deng_A_Voxel_Graph_CNN_for_Object_Classification_With_Event_Cameras_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_A_Voxel_Graph_CNN_for_Object_Classification_With_Event_Cameras_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Deng_A_Voxel_Graph_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.00216)
402. ViSTA- Vision and Scene Text Aggregation for Cross-Modal Retrieval | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_ViSTA_Vision_and_Scene_Text_Aggregation_for_Cross-Modal_Retrieval_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_ViSTA_Vision_and_Scene_Text_Aggregation_for_Cross-Modal_Retrieval_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16778)
403. Likert Scoring With Grade Decoupling for Long-Term Action Assessment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Likert_Scoring_With_Grade_Decoupling_for_Long-Term_Action_Assessment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Likert_Scoring_With_Grade_Decoupling_for_Long-Term_Action_Assessment_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Likert_Scoring_With_CVPR_2022_supplemental.pdf)
404. Many-to-Many Splatting for Efficient Video Frame Interpolation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Many-to-Many_Splatting_for_Efficient_Video_Frame_Interpolation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Many-to-Many_Splatting_for_Efficient_Video_Frame_Interpolation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.03513)
405. Learning To Learn by Jointly Optimizing Neural Architecture and Weights | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Learning_To_Learn_by_Jointly_Optimizing_Neural_Architecture_and_Weights_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Learning_To_Learn_by_Jointly_Optimizing_Neural_Architecture_and_Weights_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ding_Learning_To_Learn_CVPR_2022_supplemental.pdf)
406. A Keypoint-Based Global Association Network for Lane Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_A_Keypoint-Based_Global_Association_Network_for_Lane_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_A_Keypoint-Based_Global_Association_Network_for_Lane_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.07335)
407. Few-Shot Incremental Learning for Label-to-Image Translation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Few-Shot_Incremental_Learning_for_Label-to-Image_Translation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Few-Shot_Incremental_Learning_for_Label-to-Image_Translation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Few-Shot_Incremental_Learning_CVPR_2022_supplemental.pdf)
408. Recurrent Variational Network- A Deep Learning Inverse Problem Solver Applied to the Task of Accelerated MRI Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yiasemis_Recurrent_Variational_Network_A_Deep_Learning_Inverse_Problem_Solver_Applied_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yiasemis_Recurrent_Variational_Network_A_Deep_Learning_Inverse_Problem_Solver_Applied_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yiasemis_Recurrent_Variational_Network_CVPR_2022_supplemental.pdf)
409. CroMo- Cross-Modal Learning for Monocular Depth Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Verdie_CroMo_Cross-Modal_Learning_for_Monocular_Depth_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Verdie_CroMo_Cross-Modal_Learning_for_Monocular_Depth_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Verdie_CroMo_Cross-Modal_Learning_CVPR_2022_supplemental.pdf)
410. PanopticDepth- A Unified Framework for Depth-Aware Panoptic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gao_PanopticDepth_A_Unified_Framework_for_Depth-Aware_Panoptic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_PanopticDepth_A_Unified_Framework_for_Depth-Aware_Panoptic_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2206.00468)
411. 3D Shape Reconstruction From 2D Images With Disentangled Attribute Flow | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wen_3D_Shape_Reconstruction_From_2D_Images_With_Disentangled_Attribute_Flow_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wen_3D_Shape_Reconstruction_From_2D_Images_With_Disentangled_Attribute_Flow_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.15190)
412. OpenTAL- Towards Open Set Temporal Action Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bao_OpenTAL_Towards_Open_Set_Temporal_Action_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_OpenTAL_Towards_Open_Set_Temporal_Action_Localization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bao_OpenTAL_Towards_Open_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05114)
413. Sparse and Complete Latent Organization for Geospatial Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Sparse_and_Complete_Latent_Organization_for_Geospatial_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Sparse_and_Complete_Latent_Organization_for_Geospatial_Semantic_Segmentation_CVPR_2022_paper.pdf)
414. ST++- Make Self-Training Work Better for Semi-Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_ST_Make_Self-Training_Work_Better_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_ST_Make_Self-Training_Work_Better_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_ST_Make_Self-Training_CVPR_2022_supplemental.pdf)
415. Interacting Attention Graph for Single Image Two-Hand Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Interacting_Attention_Graph_for_Single_Image_Two-Hand_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Interacting_Attention_Graph_for_Single_Image_Two-Hand_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Interacting_Attention_Graph_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09364)
416. Exploring and Evaluating Image Restoration Potential in Dynamic Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Exploring_and_Evaluating_Image_Restoration_Potential_in_Dynamic_Scenes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Exploring_and_Evaluating_Image_Restoration_Potential_in_Dynamic_Scenes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Exploring_and_Evaluating_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11754)
417. Simulated Adversarial Testing of Face Recognition Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ruiz_Simulated_Adversarial_Testing_of_Face_Recognition_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ruiz_Simulated_Adversarial_Testing_of_Face_Recognition_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ruiz_Simulated_Adversarial_Testing_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.04569), [](http://arxiv.org/abs/2106.04569)
418. CAT-Det- Contrastively Augmented Transformer for Multi-Modal 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_CAT-Det_Contrastively_Augmented_Transformer_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_CAT-Det_Contrastively_Augmented_Transformer_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_CAT-Det_Contrastively_Augmented_CVPR_2022_supplemental.pdf)
419. Diversity Matters- Fully Exploiting Depth Clues for Reliable Monocular 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Diversity_Matters_Fully_Exploiting_Depth_Clues_for_Reliable_Monocular_3D_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Diversity_Matters_Fully_Exploiting_Depth_Clues_for_Reliable_Monocular_3D_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.09373)
420. ST-MFNet- A Spatio-Temporal Multi-Flow Network for Frame Interpolation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Danier_ST-MFNet_A_Spatio-Temporal_Multi-Flow_Network_for_Frame_Interpolation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Danier_ST-MFNet_A_Spatio-Temporal_Multi-Flow_Network_for_Frame_Interpolation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Danier_ST-MFNet_A_Spatio-Temporal_CVPR_2022_supplemental.pdf)
421. Self-Supervised Super-Resolution for Multi-Exposure Push-Frame Satellites | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_Self-Supervised_Super-Resolution_for_Multi-Exposure_Push-Frame_Satellites_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_Self-Supervised_Super-Resolution_for_Multi-Exposure_Push-Frame_Satellites_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nguyen_Self-Supervised_Super-Resolution_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.02031)
422. Stability-Driven Contact Reconstruction From Monocular Color Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Stability-Driven_Contact_Reconstruction_From_Monocular_Color_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Stability-Driven_Contact_Reconstruction_From_Monocular_Color_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_Stability-Driven_Contact_Reconstruction_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.00848)
423. Texture-Based Error Analysis for Image Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Magid_Texture-Based_Error_Analysis_for_Image_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Magid_Texture-Based_Error_Analysis_for_Image_Super-Resolution_CVPR_2022_paper.pdf)
424. PILC- Practical Image Lossless Compression With an End-to-End GPU Oriented Neural Framework | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kang_PILC_Practical_Image_Lossless_Compression_With_an_End-to-End_GPU_Oriented_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_PILC_Practical_Image_Lossless_Compression_With_an_End-to-End_GPU_Oriented_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kang_PILC_Practical_Image_CVPR_2022_supplemental.pdf)
425. Learning To Align Sequential Actions in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_To_Align_Sequential_Actions_in_the_Wild_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_To_Align_Sequential_Actions_in_the_Wild_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Learning_To_Align_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.09301)
426. GCR- Gradient Coreset Based Replay Buffer Selection for Continual Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tiwari_GCR_Gradient_Coreset_Based_Replay_Buffer_Selection_for_Continual_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tiwari_GCR_Gradient_Coreset_Based_Replay_Buffer_Selection_for_Continual_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tiwari_GCR_Gradient_Coreset_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.11210)
427. Deep Color Consistent Network for Low-Light Image Enhancement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Deep_Color_Consistent_Network_for_Low-Light_Image_Enhancement_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Deep_Color_Consistent_Network_for_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf)
428. AdaSTE- An Adaptive Straight-Through Estimator To Train Binary Neural Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Le_AdaSTE_An_Adaptive_Straight-Through_Estimator_To_Train_Binary_Neural_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Le_AdaSTE_An_Adaptive_Straight-Through_Estimator_To_Train_Binary_Neural_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Le_AdaSTE_An_Adaptive_CVPR_2022_supplemental.pdf)
429. Pooling Revisited- Your Receptive Field Is Suboptimal | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jang_Pooling_Revisited_Your_Receptive_Field_Is_Suboptimal_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jang_Pooling_Revisited_Your_Receptive_Field_Is_Suboptimal_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jang_Pooling_Revisited_Your_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.15254)
430. Show Me What and Tell Me How- Video Synthesis via Multimodal Conditioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Han_Show_Me_What_and_Tell_Me_How_Video_Synthesis_via_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Show_Me_What_and_Tell_Me_How_Video_Synthesis_via_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Han_Show_Me_What_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02573)
431. Confidence Propagation Cluster- Unleash Full Potential of Object Detectors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shen_Confidence_Propagation_Cluster_Unleash_Full_Potential_of_Object_Detectors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Confidence_Propagation_Cluster_Unleash_Full_Potential_of_Object_Detectors_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.00342)
432. ISNet- Shape Matters for Infrared Small Target Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_ISNet_Shape_Matters_for_Infrared_Small_Target_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_ISNet_Shape_Matters_for_Infrared_Small_Target_Detection_CVPR_2022_paper.pdf)
433. Segment, Magnify and Reiterate- Detecting Camouflaged Objects the Hard Way | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jia_Segment_Magnify_and_Reiterate_Detecting_Camouflaged_Objects_the_Hard_Way_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_Segment_Magnify_and_Reiterate_Detecting_Camouflaged_Objects_the_Hard_Way_CVPR_2022_paper.pdf)
434. SIMBAR- Single Image-Based Scene Relighting for Effective Data Augmentation for Automated Driving Vision Tasks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_SIMBAR_Single_Image-Based_Scene_Relighting_for_Effective_Data_Augmentation_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_SIMBAR_Single_Image-Based_Scene_Relighting_for_Effective_Data_Augmentation_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_SIMBAR_Single_Image-Based_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00644)
435. Multi-Label Classification With Partial Annotations Using Class-Aware Selective Loss | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ben-Baruch_Multi-Label_Classification_With_Partial_Annotations_Using_Class-Aware_Selective_Loss_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ben-Baruch_Multi-Label_Classification_With_Partial_Annotations_Using_Class-Aware_Selective_Loss_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ben-Baruch_Multi-Label_Classification_With_CVPR_2022_supplemental.pdf)
436. Weakly-Supervised Metric Learning With Cross-Module Communications for the Classification of Anterior Chamber Angle Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Weakly-Supervised_Metric_Learning_With_Cross-Module_Communications_for_the_Classification_of_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Weakly-Supervised_Metric_Learning_With_Cross-Module_Communications_for_the_Classification_of_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Weakly-Supervised_Metric_Learning_CVPR_2022_supplemental.pdf)
437. Rethinking Semantic Segmentation- A Prototype View | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Rethinking_Semantic_Segmentation_A_Prototype_View_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Rethinking_Semantic_Segmentation_A_Prototype_View_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Rethinking_Semantic_Segmentation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15102)
438. Cross-Model Pseudo-Labeling for Semi-Supervised Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Cross-Model_Pseudo-Labeling_for_Semi-Supervised_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Cross-Model_Pseudo-Labeling_for_Semi-Supervised_Action_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Cross-Model_Pseudo-Labeling_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.09690)
439. UMT- Unified Multi-Modal Transformers for Joint Video Moment Retrieval and Highlight Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_UMT_Unified_Multi-Modal_Transformers_for_Joint_Video_Moment_Retrieval_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_UMT_Unified_Multi-Modal_Transformers_for_Joint_Video_Moment_Retrieval_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_UMT_Unified_Multi-Modal_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12745)
440. Image Disentanglement Autoencoder for Steganography Without Embedding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Image_Disentanglement_Autoencoder_for_Steganography_Without_Embedding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Image_Disentanglement_Autoencoder_for_Steganography_Without_Embedding_CVPR_2022_paper.pdf)
441. PolyWorld- Polygonal Building Extraction With Graph Neural Networks in Satellite Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zorzi_PolyWorld_Polygonal_Building_Extraction_With_Graph_Neural_Networks_in_Satellite_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zorzi_PolyWorld_Polygonal_Building_Extraction_With_Graph_Neural_Networks_in_Satellite_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zorzi_PolyWorld_Polygonal_Building_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15491)
442. Learning Pixel-Level Distinctions for Video Highlight Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wei_Learning_Pixel-Level_Distinctions_for_Video_Highlight_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Learning_Pixel-Level_Distinctions_for_Video_Highlight_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wei_Learning_Pixel-Level_Distinctions_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04615)
443. Noise Distribution Adaptive Self-Supervised Image Denoising Using Tweedie Distribution and Score Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Noise_Distribution_Adaptive_Self-Supervised_Image_Denoising_Using_Tweedie_Distribution_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Noise_Distribution_Adaptive_Self-Supervised_Image_Denoising_Using_Tweedie_Distribution_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Noise_Distribution_Adaptive_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.03696)
444. KNN Local Attention for Image Restoration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_KNN_Local_Attention_for_Image_Restoration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_KNN_Local_Attention_for_Image_Restoration_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_KNN_Local_Attention_CVPR_2022_supplemental.pdf)
445. Face Relighting With Geometrically Consistent Shadows | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hou_Face_Relighting_With_Geometrically_Consistent_Shadows_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_Face_Relighting_With_Geometrically_Consistent_Shadows_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hou_Face_Relighting_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16681)
446. Open-Set Text Recognition via Character-Context Decoupling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Open-Set_Text_Recognition_via_Character-Context_Decoupling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Open-Set_Text_Recognition_via_Character-Context_Decoupling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Open-Set_Text_Recognition_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.05535)
447. Image Animation With Perturbed Masks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shalev_Image_Animation_With_Perturbed_Masks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shalev_Image_Animation_With_Perturbed_Masks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shalev_Image_Animation_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2011.06922)
448. Domain Generalization via Shuffled Style Assembly for Face Anti-Spoofing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Domain_Generalization_via_Shuffled_Style_Assembly_for_Face_Anti-Spoofing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Domain_Generalization_via_Shuffled_Style_Assembly_for_Face_Anti-Spoofing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Domain_Generalization_via_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05340)
449. OcclusionFusion- Occlusion-Aware Motion Estimation for Real-Time Dynamic 3D Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_OcclusionFusion_Occlusion-Aware_Motion_Estimation_for_Real-Time_Dynamic_3D_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_OcclusionFusion_Occlusion-Aware_Motion_Estimation_for_Real-Time_Dynamic_3D_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_OcclusionFusion_Occlusion-Aware_Motion_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.07977)
450. MonoScene- Monocular 3D Semantic Scene Completion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cao_MonoScene_Monocular_3D_Semantic_Scene_Completion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_MonoScene_Monocular_3D_Semantic_Scene_Completion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cao_MonoScene_Monocular_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00726)
451. What's in Your Hands- 3D Reconstruction of Generic Objects in Hands | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Whats_in_Your_Hands_3D_Reconstruction_of_Generic_Objects_in_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Whats_in_Your_Hands_3D_Reconstruction_of_Generic_Objects_in_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_Whats_in_Your_CVPR_2022_supplemental.pdf)
452. RecDis-SNN- Rectifying Membrane Potential Distribution for Directly Training Spiking Neural Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_RecDis-SNN_Rectifying_Membrane_Potential_Distribution_for_Directly_Training_Spiking_Neural_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_RecDis-SNN_Rectifying_Membrane_Potential_Distribution_for_Directly_Training_Spiking_Neural_CVPR_2022_paper.pdf)
453. Human-Aware Object Placement for Visual Environment Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yi_Human-Aware_Object_Placement_for_Visual_Environment_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yi_Human-Aware_Object_Placement_for_Visual_Environment_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yi_Human-Aware_Object_Placement_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03609)
454. X-Pool- Cross-Modal Language-Video Attention for Text-Video Retrieval | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gorti_X-Pool_Cross-Modal_Language-Video_Attention_for_Text-Video_Retrieval_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gorti_X-Pool_Cross-Modal_Language-Video_Attention_for_Text-Video_Retrieval_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gorti_X-Pool_Cross-Modal_Language-Video_CVPR_2022_supplemental.pdf)
455. Towards Weakly-Supervised Text Spotting Using a Multi-Task Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kittenplon_Towards_Weakly-Supervised_Text_Spotting_Using_a_Multi-Task_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kittenplon_Towards_Weakly-Supervised_Text_Spotting_Using_a_Multi-Task_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kittenplon_Towards_Weakly-Supervised_Text_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.05508)
456. Gated2Gated- Self-Supervised Depth Estimation From Gated Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Walia_Gated2Gated_Self-Supervised_Depth_Estimation_From_Gated_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Walia_Gated2Gated_Self-Supervised_Depth_Estimation_From_Gated_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Walia_Gated2Gated_Self-Supervised_Depth_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02416)
457. Mask Transfiner for High-Quality Instance Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ke_Mask_Transfiner_for_High-Quality_Instance_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ke_Mask_Transfiner_for_High-Quality_Instance_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ke_Mask_Transfiner_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13673)
458. End-to-End Reconstruction-Classification Learning for Face Forgery Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cao_End-to-End_Reconstruction-Classification_Learning_for_Face_Forgery_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_End-to-End_Reconstruction-Classification_Learning_for_Face_Forgery_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cao_End-to-End_Reconstruction-Classification_Learning_CVPR_2022_supplemental.pdf)
459. Watch It Move- Unsupervised Discovery of 3D Joints for Re-Posing of Articulated Objects | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Noguchi_Watch_It_Move_Unsupervised_Discovery_of_3D_Joints_for_Re-Posing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Noguchi_Watch_It_Move_Unsupervised_Discovery_of_3D_Joints_for_Re-Posing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Noguchi_Watch_It_Move_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.11347)
460. Event-Based Video Reconstruction via Potential-Assisted Spiking Neural Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Event-Based_Video_Reconstruction_via_Potential-Assisted_Spiking_Neural_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Event-Based_Video_Reconstruction_via_Potential-Assisted_Spiking_Neural_Network_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Event-Based_Video_Reconstruction_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.10943)
461. Efficient Maximal Coding Rate Reduction by Variational Forms | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Baek_Efficient_Maximal_Coding_Rate_Reduction_by_Variational_Forms_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Baek_Efficient_Maximal_Coding_Rate_Reduction_by_Variational_Forms_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Baek_Efficient_Maximal_Coding_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00077)
462. AutoLoss-GMS- Searching Generalized Margin-Based Softmax Loss Function for Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gu_AutoLoss-GMS_Searching_Generalized_Margin-Based_Softmax_Loss_Function_for_Person_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_AutoLoss-GMS_Searching_Generalized_Margin-Based_Softmax_Loss_Function_for_Person_Re-Identification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gu_AutoLoss-GMS_Searching_Generalized_CVPR_2022_supplemental.pdf)
463. Sound-Guided Semantic Image Manipulation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Sound-Guided_Semantic_Image_Manipulation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Sound-Guided_Semantic_Image_Manipulation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Sound-Guided_Semantic_Image_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00007)
464. End-to-End Human-Gaze-Target Detection With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tu_End-to-End_Human-Gaze-Target_Detection_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tu_End-to-End_Human-Gaze-Target_Detection_With_Transformers_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.10433)
465. Compositional Temporal Grounding With Structured Variational Cross-Graph Correspondence Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Compositional_Temporal_Grounding_With_Structured_Variational_Cross-Graph_Correspondence_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Compositional_Temporal_Grounding_With_Structured_Variational_Cross-Graph_Correspondence_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Compositional_Temporal_Grounding_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13049)
466. Future Transformer for Long-Term Action Anticipation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gong_Future_Transformer_for_Long-Term_Action_Anticipation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_Future_Transformer_for_Long-Term_Action_Anticipation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gong_Future_Transformer_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.14022)
467. Self-Supervised Video Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ranasinghe_Self-Supervised_Video_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ranasinghe_Self-Supervised_Video_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ranasinghe_Self-Supervised_Video_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01514)
468. AutoRF- Learning 3D Object Radiance Fields From Single View Observations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Muller_AutoRF_Learning_3D_Object_Radiance_Fields_From_Single_View_Observations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Muller_AutoRF_Learning_3D_Object_Radiance_Fields_From_Single_View_Observations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Muller_AutoRF_Learning_3D_CVPR_2022_supplemental.pdf)
469. Condensing CNNs With Partial Differential Equations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kag_Condensing_CNNs_With_Partial_Differential_Equations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kag_Condensing_CNNs_With_Partial_Differential_Equations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kag_Condensing_CNNs_With_CVPR_2022_supplemental.pdf)
470. Unsupervised Hierarchical Semantic Segmentation With Multiview Cosegmentation and Clustering Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ke_Unsupervised_Hierarchical_Semantic_Segmentation_With_Multiview_Cosegmentation_and_Clustering_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ke_Unsupervised_Hierarchical_Semantic_Segmentation_With_Multiview_Cosegmentation_and_Clustering_Transformers_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.11432)
471. Kubric- A Scalable Dataset Generator | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Greff_Kubric_A_Scalable_Dataset_Generator_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Greff_Kubric_A_Scalable_Dataset_Generator_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Greff_Kubric_A_Scalable_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03570)
472. Unpaired Deep Image Deraining Using Dual Contrastive Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Unpaired_Deep_Image_Deraining_Using_Dual_Contrastive_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Unpaired_Deep_Image_Deraining_Using_Dual_Contrastive_Learning_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2109.02973)
473. TransFusion- Robust LiDAR-Camera Fusion for 3D Object Detection With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bai_TransFusion_Robust_LiDAR-Camera_Fusion_for_3D_Object_Detection_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_TransFusion_Robust_LiDAR-Camera_Fusion_for_3D_Object_Detection_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bai_TransFusion_Robust_LiDAR-Camera_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11496)
474. Complex Video Action Reasoning via Learnable Markov Logic Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jin_Complex_Video_Action_Reasoning_via_Learnable_Markov_Logic_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Complex_Video_Action_Reasoning_via_Learnable_Markov_Logic_Network_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jin_Complex_Video_Action_CVPR_2022_supplemental.pdf)
475. Per-Clip Video Object Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Park_Per-Clip_Video_Object_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Per-Clip_Video_Object_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Park_Per-Clip_Video_Object_CVPR_2022_supplemental.pdf)
476. Coarse-To-Fine Feature Mining for Video Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Coarse-To-Fine_Feature_Mining_for_Video_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Coarse-To-Fine_Feature_Mining_for_Video_Semantic_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.03330)
477. Compressing Models With Few Samples- Mimicking Then Replacing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Compressing_Models_With_Few_Samples_Mimicking_Then_Replacing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Compressing_Models_With_Few_Samples_Mimicking_Then_Replacing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Compressing_Models_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.02620)
478. Zoom in and Out- A Mixed-Scale Triplet Network for Camouflaged Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pang_Zoom_in_and_Out_A_Mixed-Scale_Triplet_Network_for_Camouflaged_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pang_Zoom_in_and_Out_A_Mixed-Scale_Triplet_Network_for_Camouflaged_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Pang_Zoom_in_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02688)
479. MISF- Multi-Level Interactive Siamese Filtering for High-Fidelity Image Inpainting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_MISF_Multi-Level_Interactive_Siamese_Filtering_for_High-Fidelity_Image_Inpainting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_MISF_Multi-Level_Interactive_Siamese_Filtering_for_High-Fidelity_Image_Inpainting_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.06304)
480. An Efficient Training Approach for Very Large Scale Face Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_An_Efficient_Training_Approach_for_Very_Large_Scale_Face_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_An_Efficient_Training_Approach_for_Very_Large_Scale_Face_Recognition_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2105.10375)
481. Long-Term Video Frame Interpolation via Feature Propagation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Argaw_Long-Term_Video_Frame_Interpolation_via_Feature_Propagation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Argaw_Long-Term_Video_Frame_Interpolation_via_Feature_Propagation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.15427)
482. Group Contextualization for Video Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hao_Group_Contextualization_for_Video_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hao_Group_Contextualization_for_Video_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hao_Group_Contextualization_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09694)
483. Single-Domain Generalized Object Detection in Urban Scene via Cyclic-Disentangled Self-Distillation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Single-Domain_Generalized_Object_Detection_in_Urban_Scene_via_Cyclic-Disentangled_Self-Distillation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Single-Domain_Generalized_Object_Detection_in_Urban_Scene_via_Cyclic-Disentangled_Self-Distillation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Single-Domain_Generalized_Object_CVPR_2022_supplemental.pdf)
484. Rethinking Bayesian Deep Learning Methods for Semi-Supervised Volumetric Medical Image Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Rethinking_Bayesian_Deep_Learning_Methods_for_Semi-Supervised_Volumetric_Medical_Image_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Rethinking_Bayesian_Deep_Learning_Methods_for_Semi-Supervised_Volumetric_Medical_Image_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Rethinking_Bayesian_Deep_CVPR_2022_supplemental.pdf)
485. Continual Learning With Lifelong Vision Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Continual_Learning_With_Lifelong_Vision_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Continual_Learning_With_Lifelong_Vision_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Continual_Learning_With_CVPR_2022_supplemental.pdf)
486. Accurate 3D Body Shape Regression Using Metric and Semantic Attributes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Choutas_Accurate_3D_Body_Shape_Regression_Using_Metric_and_Semantic_Attributes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Choutas_Accurate_3D_Body_Shape_Regression_Using_Metric_and_Semantic_Attributes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Choutas_Accurate_3D_Body_CVPR_2022_supplemental.pdf)
487. Privacy-Preserving Online AutoML for Domain-Specific Face Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yan_Privacy-Preserving_Online_AutoML_for_Domain-Specific_Face_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Privacy-Preserving_Online_AutoML_for_Domain-Specific_Face_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yan_Privacy-Preserving_Online_AutoML_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08399)
488. Self-Augmented Unpaired Image Dehazing via Density and Depth Decomposition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Self-Augmented_Unpaired_Image_Dehazing_via_Density_and_Depth_Decomposition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Self-Augmented_Unpaired_Image_Dehazing_via_Density_and_Depth_Decomposition_CVPR_2022_paper.pdf)
489. Sparse Object-Level Supervision for Instance Segmentation With Pixel Embeddings | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wolny_Sparse_Object-Level_Supervision_for_Instance_Segmentation_With_Pixel_Embeddings_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wolny_Sparse_Object-Level_Supervision_for_Instance_Segmentation_With_Pixel_Embeddings_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wolny_Sparse_Object-Level_Supervision_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2103.14572)
490. How Much More Data Do I Need- Estimating Requirements for Downstream Tasks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mahmood_How_Much_More_Data_Do_I_Need_Estimating_Requirements_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mahmood_How_Much_More_Data_Do_I_Need_Estimating_Requirements_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mahmood_How_Much_More_CVPR_2022_supplemental.pdf)
491. The Implicit Values of a Good Hand Shake- Handheld Multi-Frame Neural Depth Refinement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chugunov_The_Implicit_Values_of_a_Good_Hand_Shake_Handheld_Multi-Frame_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chugunov_The_Implicit_Values_of_a_Good_Hand_Shake_Handheld_Multi-Frame_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chugunov_The_Implicit_Values_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13738)
492. Towards Unsupervised Domain Generalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Towards_Unsupervised_Domain_Generalization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Towards_Unsupervised_Domain_Generalization_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2107.06219)
493. HyperTransformer- A Textural and Spectral Feature Fusion Transformer for Pansharpening | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bandara_HyperTransformer_A_Textural_and_Spectral_Feature_Fusion_Transformer_for_Pansharpening_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bandara_HyperTransformer_A_Textural_and_Spectral_Feature_Fusion_Transformer_for_Pansharpening_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bandara_HyperTransformer_A_Textural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02503)
494. Segment-Fusion- Hierarchical Context Fusion for Robust 3D Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Thyagharajan_Segment-Fusion_Hierarchical_Context_Fusion_for_Robust_3D_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Thyagharajan_Segment-Fusion_Hierarchical_Context_Fusion_for_Robust_3D_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Thyagharajan_Segment-Fusion_Hierarchical_Context_CVPR_2022_supplemental.pdf)
495. MonoGround- Detecting Monocular 3D Objects From the Ground | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qin_MonoGround_Detecting_Monocular_3D_Objects_From_the_Ground_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qin_MonoGround_Detecting_Monocular_3D_Objects_From_the_Ground_CVPR_2022_paper.pdf)
496. Semiconductor Defect Detection by Hybrid Classical-Quantum Deep Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Semiconductor_Defect_Detection_by_Hybrid_Classical-Quantum_Deep_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Semiconductor_Defect_Detection_by_Hybrid_Classical-Quantum_Deep_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Semiconductor_Defect_Detection_CVPR_2022_supplemental.pdf)
497. StyleGAN-V- A Continuous Video Generator With the Price, Image Quality and Perks of StyleGAN2 | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Skorokhodov_StyleGAN-V_A_Continuous_Video_Generator_With_the_Price_Image_Quality_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Skorokhodov_StyleGAN-V_A_Continuous_Video_Generator_With_the_Price_Image_Quality_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Skorokhodov_StyleGAN-V_A_Continuous_CVPR_2022_supplemental.pdf)
498. Pin the Memory- Learning To Generalize Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Pin_the_Memory_Learning_To_Generalize_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Pin_the_Memory_Learning_To_Generalize_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Pin_the_Memory_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03609)
499. Iterative Deep Homography Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cao_Iterative_Deep_Homography_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_Iterative_Deep_Homography_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cao_Iterative_Deep_Homography_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.15982)
500. Colar- Effective and Efficient Online Action Detection by Consulting Exemplars | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Colar_Effective_and_Efficient_Online_Action_Detection_by_Consulting_Exemplars_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Colar_Effective_and_Efficient_Online_Action_Detection_by_Consulting_Exemplars_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.01057)
501. Gaussian Process Modeling of Approximate Inference Errors for Variational Autoencoders | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Gaussian_Process_Modeling_of_Approximate_Inference_Errors_for_Variational_Autoencoders_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Gaussian_Process_Modeling_of_Approximate_Inference_Errors_for_Variational_Autoencoders_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Gaussian_Process_Modeling_CVPR_2022_supplemental.pdf)
502. SoftGroup for 3D Instance Segmentation on Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Vu_SoftGroup_for_3D_Instance_Segmentation_on_Point_Clouds_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Vu_SoftGroup_for_3D_Instance_Segmentation_on_Point_Clouds_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.01509)
503. SharpContour- A Contour-Based Boundary Refinement Approach for Efficient and Accurate Instance Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_SharpContour_A_Contour-Based_Boundary_Refinement_Approach_for_Efficient_and_Accurate_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_SharpContour_A_Contour-Based_Boundary_Refinement_Approach_for_Efficient_and_Accurate_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.13312)
504. Beyond Semantic to Instance Segmentation- Weakly-Supervised Instance Segmentation via Semantic Knowledge Transfer and Self-Refinement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Beyond_Semantic_to_Instance_Segmentation_Weakly-Supervised_Instance_Segmentation_via_Semantic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Beyond_Semantic_to_Instance_Segmentation_Weakly-Supervised_Instance_Segmentation_via_Semantic_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Beyond_Semantic_to_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2109.09477)
505. EDTER- Edge Detection With Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pu_EDTER_Edge_Detection_With_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pu_EDTER_Edge_Detection_With_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Pu_EDTER_Edge_Detection_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08566)
506. JIFF- Jointly-Aligned Implicit Face Function for High Quality Single View Clothed Human Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cao_JIFF_Jointly-Aligned_Implicit_Face_Function_for_High_Quality_Single_View_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_JIFF_Jointly-Aligned_Implicit_Face_Function_for_High_Quality_Single_View_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cao_JIFF_Jointly-Aligned_Implicit_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.10549)
507. Semantic-Aware Domain Generalized Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Peng_Semantic-Aware_Domain_Generalized_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Semantic-Aware_Domain_Generalized_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Peng_Semantic-Aware_Domain_Generalized_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00822)
508. Egocentric Scene Understanding via Multimodal Spatial Rectifier | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Do_Egocentric_Scene_Understanding_via_Multimodal_Spatial_Rectifier_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Do_Egocentric_Scene_Understanding_via_Multimodal_Spatial_Rectifier_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Do_Egocentric_Scene_Understanding_CVPR_2022_supplemental.pdf)
509. Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Semi-Supervised_Semantic_Segmentation_Using_Unreliable_Pseudo-Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Semi-Supervised_Semantic_Segmentation_Using_Unreliable_Pseudo-Labels_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Semi-Supervised_Semantic_Segmentation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03884)
510. Estimating Example Difficulty Using Variance of Gradients | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Agarwal_Estimating_Example_Difficulty_Using_Variance_of_Gradients_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Agarwal_Estimating_Example_Difficulty_Using_Variance_of_Gradients_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Agarwal_Estimating_Example_Difficulty_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2008.11600)
511. One Loss for Quantization- Deep Hashing With Discrete Wasserstein Distributional Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Doan_One_Loss_for_Quantization_Deep_Hashing_With_Discrete_Wasserstein_Distributional_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Doan_One_Loss_for_Quantization_Deep_Hashing_With_Discrete_Wasserstein_Distributional_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Doan_One_Loss_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.15721)
512. Pixel Screening Based Intermediate Correction for Blind Deblurring | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Pixel_Screening_Based_Intermediate_Correction_for_Blind_Deblurring_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Pixel_Screening_Based_Intermediate_Correction_for_Blind_Deblurring_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Pixel_Screening_Based_CVPR_2022_supplemental.pdf)
513. Continual Object Detection via Prototypical Task Correlation Guided Gating Mechanism | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Continual_Object_Detection_via_Prototypical_Task_Correlation_Guided_Gating_Mechanism_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Continual_Object_Detection_via_Prototypical_Task_Correlation_Guided_Gating_Mechanism_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Continual_Object_Detection_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.03055)
514. DATA- Domain-Aware and Task-Aware Self-Supervised Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chang_DATA_Domain-Aware_and_Task-Aware_Self-Supervised_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_DATA_Domain-Aware_and_Task-Aware_Self-Supervised_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chang_DATA_Domain-Aware_and_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.09041)
515. Voxel Set Transformer- A Set-to-Set Approach to 3D Object Detection From Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_Voxel_Set_Transformer_A_Set-to-Set_Approach_to_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Voxel_Set_Transformer_A_Set-to-Set_Approach_to_3D_Object_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.10314)
516. Siamese Contrastive Embedding Network for Compositional Zero-Shot Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Siamese_Contrastive_Embedding_Network_for_Compositional_Zero-Shot_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Siamese_Contrastive_Embedding_Network_for_Compositional_Zero-Shot_Learning_CVPR_2022_paper.pdf)
517. ZebraPose- Coarse To Fine Surface Encoding for 6DoF Object Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Su_ZebraPose_Coarse_To_Fine_Surface_Encoding_for_6DoF_Object_Pose_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Su_ZebraPose_Coarse_To_Fine_Surface_Encoding_for_6DoF_Object_Pose_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Su_ZebraPose_Coarse_To_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09418)
518. ATPFL- Automatic Trajectory Prediction Model Design Under Federated Learning Framework | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ATPFL_Automatic_Trajectory_Prediction_Model_Design_Under_Federated_Learning_Framework_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ATPFL_Automatic_Trajectory_Prediction_Model_Design_Under_Federated_Learning_Framework_CVPR_2022_paper.pdf)
519. Revisiting Learnable Affines for Batch Norm in Few-Shot Transfer Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yazdanpanah_Revisiting_Learnable_Affines_for_Batch_Norm_in_Few-Shot_Transfer_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yazdanpanah_Revisiting_Learnable_Affines_for_Batch_Norm_in_Few-Shot_Transfer_Learning_CVPR_2022_paper.pdf)
520. Exact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Exact_Feature_Distribution_Matching_for_Arbitrary_Style_Transfer_and_Domain_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Exact_Feature_Distribution_Matching_for_Arbitrary_Style_Transfer_and_Domain_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Exact_Feature_Distribution_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.07740)
521. Balanced and Hierarchical Relation Learning for One-Shot Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Balanced_and_Hierarchical_Relation_Learning_for_One-Shot_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Balanced_and_Hierarchical_Relation_Learning_for_One-Shot_Object_Detection_CVPR_2022_paper.pdf)
522. Delving Deep Into the Generalization of Vision Transformers Under Distribution Shifts | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Delving_Deep_Into_the_Generalization_of_Vision_Transformers_Under_Distribution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Delving_Deep_Into_the_Generalization_of_Vision_Transformers_Under_Distribution_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2106.07617)
523. HyperDet3D- Learning a Scene-Conditioned 3D Object Detector | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_HyperDet3D_Learning_a_Scene-Conditioned_3D_Object_Detector_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_HyperDet3D_Learning_a_Scene-Conditioned_3D_Object_Detector_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_HyperDet3D_Learning_a_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.05599)
524. Motion-Aware Contrastive Video Representation Learning via Foreground-Background Merging | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Motion-Aware_Contrastive_Video_Representation_Learning_via_Foreground-Background_Merging_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Motion-Aware_Contrastive_Video_Representation_Learning_via_Foreground-Background_Merging_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ding_Motion-Aware_Contrastive_Video_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2109.15130)
525. DINE- Domain Adaptation From Single and Multiple Black-Box Predictors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_DINE_Domain_Adaptation_From_Single_and_Multiple_Black-Box_Predictors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_DINE_Domain_Adaptation_From_Single_and_Multiple_Black-Box_Predictors_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2104.01539)
526. Multi-View Mesh Reconstruction With Neural Deferred Shading | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Worchel_Multi-View_Mesh_Reconstruction_With_Neural_Deferred_Shading_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Worchel_Multi-View_Mesh_Reconstruction_With_Neural_Deferred_Shading_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Worchel_Multi-View_Mesh_Reconstruction_CVPR_2022_supplemental.pdf)
527. High-Resolution Face Swapping via Latent Semantics Disentanglement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_High-Resolution_Face_Swapping_via_Latent_Semantics_Disentanglement_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_High-Resolution_Face_Swapping_via_Latent_Semantics_Disentanglement_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_High-Resolution_Face_Swapping_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15958)
528. Deep Vanishing Point Detection- Geometric Priors Make Dataset Variations Vanish | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Deep_Vanishing_Point_Detection_Geometric_Priors_Make_Dataset_Variations_Vanish_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Deep_Vanishing_Point_Detection_Geometric_Priors_Make_Dataset_Variations_Vanish_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_Deep_Vanishing_Point_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08586)
529. Neural Compression-Based Feature Learning for Video Restoration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Neural_Compression-Based_Feature_Learning_for_Video_Restoration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Neural_Compression-Based_Feature_Learning_for_Video_Restoration_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Neural_Compression-Based_Feature_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09208)
530. Expanding Low-Density Latent Regions for Open-Set Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Han_Expanding_Low-Density_Latent_Regions_for_Open-Set_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Expanding_Low-Density_Latent_Regions_for_Open-Set_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Han_Expanding_Low-Density_Latent_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14911)
531. Exploring Dual-Task Correlation for Pose Guided Person Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Exploring_Dual-Task_Correlation_for_Pose_Guided_Person_Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Exploring_Dual-Task_Correlation_for_Pose_Guided_Person_Image_Generation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.02910)
532. Neural Rays for Occlusion-Aware Image-Based Rendering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Neural_Rays_for_Occlusion-Aware_Image-Based_Rendering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Neural_Rays_for_Occlusion-Aware_Image-Based_Rendering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Neural_Rays_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2107.13421)
533. Modeling 3D Layout for Group Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Modeling_3D_Layout_for_Group_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Modeling_3D_Layout_for_Group_Re-Identification_CVPR_2022_paper.pdf)
534. Toward Fast, Flexible, and Robust Low-Light Image Enhancement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Toward_Fast_Flexible_and_Robust_Low-Light_Image_Enhancement_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Toward_Fast_Flexible_and_Robust_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_Toward_Fast_Flexible_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.10137)
535. Highly-Efficient Incomplete Large-Scale Multi-View Clustering With Consensus Bipartite Graph | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Highly-Efficient_Incomplete_Large-Scale_Multi-View_Clustering_With_Consensus_Bipartite_Graph_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Highly-Efficient_Incomplete_Large-Scale_Multi-View_Clustering_With_Consensus_Bipartite_Graph_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Highly-Efficient_Incomplete_Large-Scale_CVPR_2022_supplemental.pdf)
536. Towards Principled Disentanglement for Domain Generalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Towards_Principled_Disentanglement_for_Domain_Generalization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Towards_Principled_Disentanglement_for_Domain_Generalization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Towards_Principled_Disentanglement_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13839)
537. Discrete Cosine Transform Network for Guided Depth Map Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Discrete_Cosine_Transform_Network_for_Guided_Depth_Map_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Discrete_Cosine_Transform_Network_for_Guided_Depth_Map_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_Discrete_Cosine_Transform_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.06977)
538. Iterative Corresponding Geometry- Fusing Region and Depth for Highly Efficient 3D Tracking of Textureless Objects | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Stoiber_Iterative_Corresponding_Geometry_Fusing_Region_and_Depth_for_Highly_Efficient_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Stoiber_Iterative_Corresponding_Geometry_Fusing_Region_and_Depth_for_Highly_Efficient_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Stoiber_Iterative_Corresponding_Geometry_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05334)
539. Multi-Instance Point Cloud Registration by Efficient Correspondence Clustering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Multi-Instance_Point_Cloud_Registration_by_Efficient_Correspondence_Clustering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Multi-Instance_Point_Cloud_Registration_by_Efficient_Correspondence_Clustering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_Multi-Instance_Point_Cloud_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2111.14582)
540. Contrastive Boundary Learning for Point Cloud Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Contrastive_Boundary_Learning_for_Point_Cloud_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Contrastive_Boundary_Learning_for_Point_Cloud_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_Contrastive_Boundary_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05272)
541. Details or Artifacts- A Locally Discriminative Learning Approach to Realistic Image Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Details_or_Artifacts_A_Locally_Discriminative_Learning_Approach_to_Realistic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Details_or_Artifacts_A_Locally_Discriminative_Learning_Approach_to_Realistic_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liang_Details_or_Artifacts_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09195)
542. Projective Manifold Gradient Layer for Deep Rotation Regression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Projective_Manifold_Gradient_Layer_for_Deep_Rotation_Regression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Projective_Manifold_Gradient_Layer_for_Deep_Rotation_Regression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Projective_Manifold_Gradient_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.11657)
543. It's Time for Artistic Correspondence in Music and Video | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Suris_Its_Time_for_Artistic_Correspondence_in_Music_and_Video_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Suris_Its_Time_for_Artistic_Correspondence_in_Music_and_Video_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Suris_Its_Time_for_CVPR_2022_supplemental.pdf)
544. Mixed Differential Privacy in Computer Vision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Golatkar_Mixed_Differential_Privacy_in_Computer_Vision_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Golatkar_Mixed_Differential_Privacy_in_Computer_Vision_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Golatkar_Mixed_Differential_Privacy_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11481)
545. HCSC- Hierarchical Contrastive Selective Coding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_HCSC_Hierarchical_Contrastive_Selective_Coding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_HCSC_Hierarchical_Contrastive_Selective_Coding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_HCSC_Hierarchical_Contrastive_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.00455)
546. KeyTr- Keypoint Transporter for 3D Reconstruction of Deformable Objects in Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Novotny_KeyTr_Keypoint_Transporter_for_3D_Reconstruction_of_Deformable_Objects_in_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Novotny_KeyTr_Keypoint_Transporter_for_3D_Reconstruction_of_Deformable_Objects_in_CVPR_2022_paper.pdf)
547. Lepard- Learning Partial Point Cloud Matching in Rigid and Deformable Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Lepard_Learning_Partial_Point_Cloud_Matching_in_Rigid_and_Deformable_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Lepard_Learning_Partial_Point_Cloud_Matching_in_Rigid_and_Deformable_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Lepard_Learning_Partial_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12591)
548. Pushing the Limits of Simple Pipelines for Few-Shot Learning- External Data and Fine-Tuning Make a Difference | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Pushing_the_Limits_of_Simple_Pipelines_for_Few-Shot_Learning_External_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Pushing_the_Limits_of_Simple_Pipelines_for_Few-Shot_Learning_External_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_Pushing_the_Limits_CVPR_2022_supplemental.pdf)
549. VISTA- Boosting 3D Object Detection via Dual Cross-VIew SpaTial Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Deng_VISTA_Boosting_3D_Object_Detection_via_Dual_Cross-VIew_SpaTial_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_VISTA_Boosting_3D_Object_Detection_via_Dual_Cross-VIew_SpaTial_Attention_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Deng_VISTA_Boosting_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09704)
550. Rethinking Deep Face Restoration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Rethinking_Deep_Face_Restoration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Rethinking_Deep_Face_Restoration_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_Rethinking_Deep_Face_CVPR_2022_supplemental.pdf)
551. A Study on the Distribution of Social Biases in Self-Supervised Learning Visual Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sirotkin_A_Study_on_the_Distribution_of_Social_Biases_in_Self-Supervised_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sirotkin_A_Study_on_the_Distribution_of_Social_Biases_in_Self-Supervised_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sirotkin_A_Study_on_CVPR_2022_supplemental.pdf)
552. On the Instability of Relative Pose Estimation and RANSAC's Role | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_On_the_Instability_of_Relative_Pose_Estimation_and_RANSACs_Role_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_On_the_Instability_of_Relative_Pose_Estimation_and_RANSACs_Role_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fan_On_the_Instability_CVPR_2022_supplemental.pdf)
553. SNUG- Self-Supervised Neural Dynamic Garments | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Santesteban_SNUG_Self-Supervised_Neural_Dynamic_Garments_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Santesteban_SNUG_Self-Supervised_Neural_Dynamic_Garments_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Santesteban_SNUG_Self-Supervised_Neural_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.02219)
554. Towards Fewer Annotations- Active Learning via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Towards_Fewer_Annotations_Active_Learning_via_Region_Impurity_and_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Towards_Fewer_Annotations_Active_Learning_via_Region_Impurity_and_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xie_Towards_Fewer_Annotations_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12940)
555. CrossPoint- Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Afham_CrossPoint_Self-Supervised_Cross-Modal_Contrastive_Learning_for_3D_Point_Cloud_Understanding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Afham_CrossPoint_Self-Supervised_Cross-Modal_Contrastive_Learning_for_3D_Point_Cloud_Understanding_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.00680)
556. Target-Relevant Knowledge Preservation for Multi-Source Domain Adaptive Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Target-Relevant_Knowledge_Preservation_for_Multi-Source_Domain_Adaptive_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Target-Relevant_Knowledge_Preservation_for_Multi-Source_Domain_Adaptive_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Target-Relevant_Knowledge_Preservation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07964)
557. Safe Self-Refinement for Transformer-Based Domain Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Safe_Self-Refinement_for_Transformer-Based_Domain_Adaptation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Safe_Self-Refinement_for_Transformer-Based_Domain_Adaptation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.07683)
558. StyleMesh- Style Transfer for Indoor 3D Scene Reconstructions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hollein_StyleMesh_Style_Transfer_for_Indoor_3D_Scene_Reconstructions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hollein_StyleMesh_Style_Transfer_for_Indoor_3D_Scene_Reconstructions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hollein_StyleMesh_Style_Transfer_CVPR_2022_supplemental.pdf)
559. Which Model To Transfer- Finding the Needle in the Growing Haystack | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Renggli_Which_Model_To_Transfer_Finding_the_Needle_in_the_Growing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Renggli_Which_Model_To_Transfer_Finding_the_Needle_in_the_Growing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Renggli_Which_Model_To_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2010.06402)
560. Class-Incremental Learning With Strong Pre-Trained Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Class-Incremental_Learning_With_Strong_Pre-Trained_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Class-Incremental_Learning_With_Strong_Pre-Trained_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Class-Incremental_Learning_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03634)
561. IRON- Inverse Rendering by Optimizing Neural SDFs and Materials From Photometric Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_IRON_Inverse_Rendering_by_Optimizing_Neural_SDFs_and_Materials_From_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_IRON_Inverse_Rendering_by_Optimizing_Neural_SDFs_and_Materials_From_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_IRON_Inverse_Rendering_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02232)
562. ObjectFolder 2.0- A Multisensory Object Dataset for Sim2Real Transfer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gao_ObjectFolder_2.0_A_Multisensory_Object_Dataset_for_Sim2Real_Transfer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_ObjectFolder_2.0_A_Multisensory_Object_Dataset_for_Sim2Real_Transfer_CVPR_2022_paper.pdf)
563. POCO- Point Convolution for Surface Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Boulch_POCO_Point_Convolution_for_Surface_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Boulch_POCO_Point_Convolution_for_Surface_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Boulch_POCO_Point_Convolution_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.01831)
564. Few-Shot Font Generation by Learning Fine-Grained Local Styles | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Few-Shot_Font_Generation_by_Learning_Fine-Grained_Local_Styles_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Few-Shot_Font_Generation_by_Learning_Fine-Grained_Local_Styles_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_Few-Shot_Font_Generation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.09965)
565. DiffPoseNet- Direct Differentiable Camera Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Parameshwara_DiffPoseNet_Direct_Differentiable_Camera_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Parameshwara_DiffPoseNet_Direct_Differentiable_Camera_Pose_Estimation_CVPR_2022_paper.pdf)
566. The Flag Median and FlagIRLS | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mankovich_The_Flag_Median_and_FlagIRLS_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mankovich_The_Flag_Median_and_FlagIRLS_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mankovich_The_Flag_Median_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.04437)
567. FENeRF- Face Editing in Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_FENeRF_Face_Editing_in_Neural_Radiance_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_FENeRF_Face_Editing_in_Neural_Radiance_Fields_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.15490)
568. Remember Intentions- Retrospective-Memory-Based Trajectory Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Remember_Intentions_Retrospective-Memory-Based_Trajectory_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Remember_Intentions_Retrospective-Memory-Based_Trajectory_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Remember_Intentions_Retrospective-Memory-Based_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11474)
569. A Framework for Learning Ante-Hoc Explainable Models via Concepts | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sarkar_A_Framework_for_Learning_Ante-Hoc_Explainable_Models_via_Concepts_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sarkar_A_Framework_for_Learning_Ante-Hoc_Explainable_Models_via_Concepts_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sarkar_A_Framework_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2108.11761)
570. Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qu_Rethinking_Architecture_Design_for_Tackling_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qu_Rethinking_Architecture_Design_for_Tackling_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Qu_Rethinking_Architecture_Design_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.06047)
571. Global Sensing and Measurements Reuse for Image Compressed Sensing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Global_Sensing_and_Measurements_Reuse_for_Image_Compressed_Sensing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Global_Sensing_and_Measurements_Reuse_for_Image_Compressed_Sensing_CVPR_2022_paper.pdf)
572. Convolutions for Spatial Interaction Modeling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Su_Convolutions_for_Spatial_Interaction_Modeling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Su_Convolutions_for_Spatial_Interaction_Modeling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Su_Convolutions_for_Spatial_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2104.07182)
573. Distinguishing Unseen From Seen for Generalized Zero-Shot Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Su_Distinguishing_Unseen_From_Seen_for_Generalized_Zero-Shot_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Su_Distinguishing_Unseen_From_Seen_for_Generalized_Zero-Shot_Learning_CVPR_2022_paper.pdf)
574. Online Continual Learning on a Contaminated Data Stream With Blurry Task Boundaries | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bang_Online_Continual_Learning_on_a_Contaminated_Data_Stream_With_Blurry_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bang_Online_Continual_Learning_on_a_Contaminated_Data_Stream_With_Blurry_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bang_Online_Continual_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15355)
575. Learning To Imagine- Diversify Memory for Incremental Learning Using Unlabeled Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Learning_To_Imagine_Diversify_Memory_for_Incremental_Learning_Using_Unlabeled_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Learning_To_Imagine_Diversify_Memory_for_Incremental_Learning_Using_Unlabeled_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_Learning_To_Imagine_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.08932)
576. Exploring Domain-Invariant Parameters for Source Free Domain Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Exploring_Domain-Invariant_Parameters_for_Source_Free_Domain_Adaptation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Exploring_Domain-Invariant_Parameters_for_Source_Free_Domain_Adaptation_CVPR_2022_paper.pdf)
577. C2AM Loss- Chasing a Better Decision Boundary for Long-Tail Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_C2AM_Loss_Chasing_a_Better_Decision_Boundary_for_Long-Tail_Object_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_C2AM_Loss_Chasing_a_Better_Decision_Boundary_for_Long-Tail_Object_CVPR_2022_paper.pdf)
578. Bi-Directional Object-Context Prioritization Learning for Saliency Ranking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tian_Bi-Directional_Object-Context_Prioritization_Learning_for_Saliency_Ranking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tian_Bi-Directional_Object-Context_Prioritization_Learning_for_Saliency_Ranking_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tian_Bi-Directional_Object-Context_Prioritization_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09416)
579. What Do Navigation Agents Learn About Their Environment- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dwivedi_What_Do_Navigation_Agents_Learn_About_Their_Environment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dwivedi_What_Do_Navigation_Agents_Learn_About_Their_Environment_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dwivedi_What_Do_Navigation_CVPR_2022_supplemental.pdf)
580. CoordGAN- Self-Supervised Dense Correspondences Emerge From GANs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mu_CoordGAN_Self-Supervised_Dense_Correspondences_Emerge_From_GANs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mu_CoordGAN_Self-Supervised_Dense_Correspondences_Emerge_From_GANs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mu_CoordGAN_Self-Supervised_Dense_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16521)
581. PSMNet- Position-Aware Stereo Merging Network for Room Layout Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_PSMNet_Position-Aware_Stereo_Merging_Network_for_Room_Layout_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_PSMNet_Position-Aware_Stereo_Merging_Network_for_Room_Layout_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_PSMNet_Position-Aware_Stereo_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15965)
582. Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-Shot Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_Attribute_Surrogates_Learning_and_Spectral_Tokens_Pooling_in_Transformers_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Attribute_Surrogates_Learning_and_Spectral_Tokens_Pooling_in_Transformers_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_Attribute_Surrogates_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09064)
583. Generalized Category Discovery | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Vaze_Generalized_Category_Discovery_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Vaze_Generalized_Category_Discovery_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Vaze_Generalized_Category_Discovery_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.02609)
584. Maximum Consensus by Weighted Influences of Monotone Boolean Functions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Maximum_Consensus_by_Weighted_Influences_of_Monotone_Boolean_Functions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Maximum_Consensus_by_Weighted_Influences_of_Monotone_Boolean_Functions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Maximum_Consensus_by_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00953)
585. TransforMatcher- Match-to-Match Attention for Semantic Correspondence | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_TransforMatcher_Match-to-Match_Attention_for_Semantic_Correspondence_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_TransforMatcher_Match-to-Match_Attention_for_Semantic_Correspondence_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_TransforMatcher_Match-to-Match_Attention_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.11634)
586. Robust Outlier Detection by De-Biasing VAE Likelihoods | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chauhan_Robust_Outlier_Detection_by_De-Biasing_VAE_Likelihoods_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chauhan_Robust_Outlier_Detection_by_De-Biasing_VAE_Likelihoods_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chauhan_Robust_Outlier_Detection_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2108.08760)
587. Point2Seq- Detecting 3D Objects As Sequences | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Point2Seq_Detecting_3D_Objects_As_Sequences_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Point2Seq_Detecting_3D_Objects_As_Sequences_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xue_Point2Seq_Detecting_3D_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.13394)
588. Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Task-Adaptive_Negative_Envision_for_Few-Shot_Open-Set_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Task-Adaptive_Negative_Envision_for_Few-Shot_Open-Set_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Task-Adaptive_Negative_Envision_CVPR_2022_supplemental.pdf)
589. MixFormer- Mixing Features Across Windows and Dimensions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_MixFormer_Mixing_Features_Across_Windows_and_Dimensions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_MixFormer_Mixing_Features_Across_Windows_and_Dimensions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_MixFormer_Mixing_Features_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02557)
590. Contextual Similarity Distillation for Asymmetric Image Retrieval | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Contextual_Similarity_Distillation_for_Asymmetric_Image_Retrieval_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Contextual_Similarity_Distillation_for_Asymmetric_Image_Retrieval_CVPR_2022_paper.pdf)
591. DASO- Distribution-Aware Semantics-Oriented Pseudo-Label for Imbalanced Semi-Supervised Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Oh_DASO_Distribution-Aware_Semantics-Oriented_Pseudo-Label_for_Imbalanced_Semi-Supervised_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Oh_DASO_Distribution-Aware_Semantics-Oriented_Pseudo-Label_for_Imbalanced_Semi-Supervised_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Oh_DASO_Distribution-Aware_Semantics-Oriented_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.05682)
592. Mobile-Former- Bridging MobileNet and Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Mobile-Former_Bridging_MobileNet_and_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Mobile-Former_Bridging_MobileNet_and_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Mobile-Former_Bridging_MobileNet_CVPR_2022_supplemental.pdf)
593. DESTR- Object Detection With Split Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_DESTR_Object_Detection_With_Split_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_DESTR_Object_Detection_With_Split_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_DESTR_Object_Detection_CVPR_2022_supplemental.pdf)
594. IterMVS- Iterative Probability Estimation for Efficient Multi-View Stereo | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_IterMVS_Iterative_Probability_Estimation_for_Efficient_Multi-View_Stereo_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_IterMVS_Iterative_Probability_Estimation_for_Efficient_Multi-View_Stereo_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_IterMVS_Iterative_Probability_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.05126)
595. FedCorr- Multi-Stage Federated Learning for Label Noise Correction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_FedCorr_Multi-Stage_Federated_Learning_for_Label_Noise_Correction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_FedCorr_Multi-Stage_Federated_Learning_for_Label_Noise_Correction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_FedCorr_Multi-Stage_Federated_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04677)
596. Source-Free Object Detection by Learning To Overlook Domain Style | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Source-Free_Object_Detection_by_Learning_To_Overlook_Domain_Style_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Source-Free_Object_Detection_by_Learning_To_Overlook_Domain_Style_CVPR_2022_paper.pdf)
597. SceneSqueezer- Learning To Compress Scene for Camera Relocalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_SceneSqueezer_Learning_To_Compress_Scene_for_Camera_Relocalization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_SceneSqueezer_Learning_To_Compress_Scene_for_Camera_Relocalization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_SceneSqueezer_Learning_To_CVPR_2022_supplemental.pdf)
598. SelfRecon- Self Reconstruction Your Digital Avatar From Monocular Video | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_SelfRecon_Self_Reconstruction_Your_Digital_Avatar_From_Monocular_Video_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_SelfRecon_Self_Reconstruction_Your_Digital_Avatar_From_Monocular_Video_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2201.12792)
599. Self-Supervised Models Are Continual Learners | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fini_Self-Supervised_Models_Are_Continual_Learners_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fini_Self-Supervised_Models_Are_Continual_Learners_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fini_Self-Supervised_Models_Are_CVPR_2022_supplemental.pdf)
600. Dreaming To Prune Image Deraining Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zou_Dreaming_To_Prune_Image_Deraining_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zou_Dreaming_To_Prune_Image_Deraining_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zou_Dreaming_To_Prune_CVPR_2022_supplemental.pdf)
601. Exploiting Explainable Metrics for Augmented SGD | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hosseini_Exploiting_Explainable_Metrics_for_Augmented_SGD_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hosseini_Exploiting_Explainable_Metrics_for_Augmented_SGD_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hosseini_Exploiting_Explainable_Metrics_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16723)
602. Improving Neural Implicit Surfaces Geometry With Patch Warping | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Darmon_Improving_Neural_Implicit_Surfaces_Geometry_With_Patch_Warping_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Darmon_Improving_Neural_Implicit_Surfaces_Geometry_With_Patch_Warping_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Darmon_Improving_Neural_Implicit_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.09648)
603. CaDeX- Learning Canonical Deformation Coordinate Space for Dynamic Surface Representation via Neural Homeomorphism | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lei_CaDeX_Learning_Canonical_Deformation_Coordinate_Space_for_Dynamic_Surface_Representation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_CaDeX_Learning_Canonical_Deformation_Coordinate_Space_for_Dynamic_Surface_Representation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lei_CaDeX_Learning_Canonical_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16529)
604. Layer-Wised Model Aggregation for Personalized Federated Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Layer-Wised_Model_Aggregation_for_Personalized_Federated_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Layer-Wised_Model_Aggregation_for_Personalized_Federated_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_Layer-Wised_Model_Aggregation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.03993)
605. A Unified Query-Based Paradigm for Point Cloud Understanding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_A_Unified_Query-Based_Paradigm_for_Point_Cloud_Understanding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_A_Unified_Query-Based_Paradigm_for_Point_Cloud_Understanding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_A_Unified_Query-Based_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01252)
606. Multi-Object Tracking Meets Moving UAV | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Multi-Object_Tracking_Meets_Moving_UAV_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Multi-Object_Tracking_Meets_Moving_UAV_CVPR_2022_paper.pdf)
607. REGTR- End-to-End Point Cloud Correspondences With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yew_REGTR_End-to-End_Point_Cloud_Correspondences_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yew_REGTR_End-to-End_Point_Cloud_Correspondences_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yew_REGTR_End-to-End_Point_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14517)
608. Neural 3D Scene Reconstruction With the Manhattan-World Assumption | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Neural_3D_Scene_Reconstruction_With_the_Manhattan-World_Assumption_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Neural_3D_Scene_Reconstruction_With_the_Manhattan-World_Assumption_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_Neural_3D_Scene_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.02836)
609. ElePose- Unsupervised 3D Human Pose Estimation by Predicting Camera Elevation and Learning Normalizing Flows on 2D Poses | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wandt_ElePose_Unsupervised_3D_Human_Pose_Estimation_by_Predicting_Camera_Elevation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wandt_ElePose_Unsupervised_3D_Human_Pose_Estimation_by_Predicting_Camera_Elevation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wandt_ElePose_Unsupervised_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.07088)
610. IDEA-Net- Dynamic 3D Point Cloud Interpolation via Deep Embedding Alignment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zeng_IDEA-Net_Dynamic_3D_Point_Cloud_Interpolation_via_Deep_Embedding_Alignment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_IDEA-Net_Dynamic_3D_Point_Cloud_Interpolation_via_Deep_Embedding_Alignment_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zeng_IDEA-Net_Dynamic_3D_CVPR_2022_supplemental.pdf)
611. UniCon- Combating Label Noise Through Uniform Selection and Contrastive Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Karim_UniCon_Combating_Label_Noise_Through_Uniform_Selection_and_Contrastive_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Karim_UniCon_Combating_Label_Noise_Through_Uniform_Selection_and_Contrastive_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Karim_UniCon_Combating_Label_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14542)
612. One-Bit Active Query With Contrastive Pairs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_One-Bit_Active_Query_With_Contrastive_Pairs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_One-Bit_Active_Query_With_Contrastive_Pairs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_One-Bit_Active_Query_CVPR_2022_supplemental.pdf)
613. Rethinking Reconstruction Autoencoder-Based Out-of-Distribution Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Rethinking_Reconstruction_Autoencoder-Based_Out-of-Distribution_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Rethinking_Reconstruction_Autoencoder-Based_Out-of-Distribution_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Rethinking_Reconstruction_Autoencoder-Based_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.02194)
614. E-CIR- Event-Enhanced Continuous Intensity Recovery | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Song_E-CIR_Event-Enhanced_Continuous_Intensity_Recovery_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Song_E-CIR_Event-Enhanced_Continuous_Intensity_Recovery_CVPR_2022_paper.pdf)
615. Towards Robust Rain Removal Against Adversarial Attacks- A Comprehensive Benchmark Analysis and Beyond | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Towards_Robust_Rain_Removal_Against_Adversarial_Attacks_A_Comprehensive_Benchmark_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Towards_Robust_Rain_Removal_Against_Adversarial_Attacks_A_Comprehensive_Benchmark_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_Towards_Robust_Rain_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.16931)
616. AziNorm- Exploiting the Radial Symmetry of Point Cloud for Azimuth-Normalized 3D Perception | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_AziNorm_Exploiting_the_Radial_Symmetry_of_Point_Cloud_for_Azimuth-Normalized_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_AziNorm_Exploiting_the_Radial_Symmetry_of_Point_Cloud_for_Azimuth-Normalized_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.13090)
617. Surface Reconstruction From Point Clouds by Learning Predictive Context Priors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Surface_Reconstruction_From_Point_Clouds_by_Learning_Predictive_Context_Priors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Surface_Reconstruction_From_Point_Clouds_by_Learning_Predictive_Context_Priors_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_Surface_Reconstruction_From_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.11015)
618. Parametric Scattering Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gauthier_Parametric_Scattering_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gauthier_Parametric_Scattering_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gauthier_Parametric_Scattering_Networks_CVPR_2022_supplemental.pdf)
619. SketchEdit- Mask-Free Local Image Manipulation With Partial Sketches | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zeng_SketchEdit_Mask-Free_Local_Image_Manipulation_With_Partial_Sketches_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_SketchEdit_Mask-Free_Local_Image_Manipulation_With_Partial_Sketches_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zeng_SketchEdit_Mask-Free_Local_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15078)
620. BatchFormer- Learning To Explore Sample Relationships for Robust Representation Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hou_BatchFormer_Learning_To_Explore_Sample_Relationships_for_Robust_Representation_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_BatchFormer_Learning_To_Explore_Sample_Relationships_for_Robust_Representation_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hou_BatchFormer_Learning_To_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01522)
621. Learning Multi-View Aggregation in the Wild for Large-Scale 3D Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Robert_Learning_Multi-View_Aggregation_in_the_Wild_for_Large-Scale_3D_Semantic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Robert_Learning_Multi-View_Aggregation_in_the_Wild_for_Large-Scale_3D_Semantic_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Robert_Learning_Multi-View_Aggregation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07548)
622. Physically Disentangled Intra- and Inter-Domain Adaptation for Varicolored Haze Removal | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Physically_Disentangled_Intra-_and_Inter-Domain_Adaptation_for_Varicolored_Haze_Removal_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Physically_Disentangled_Intra-_and_Inter-Domain_Adaptation_for_Varicolored_Haze_Removal_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Physically_Disentangled_Intra-_CVPR_2022_supplemental.pdf)
623. Representation Compensation Networks for Continual Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Representation_Compensation_Networks_for_Continual_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Representation_Compensation_Networks_for_Continual_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Representation_Compensation_Networks_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05402)
624. Learning To Solve Hard Minimal Problems | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hruby_Learning_To_Solve_Hard_Minimal_Problems_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hruby_Learning_To_Solve_Hard_Minimal_Problems_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hruby_Learning_To_Solve_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.03424)
625. Non-Generative Generalized Zero-Shot Learning via Task-Correlated Disentanglement and Controllable Samples Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Non-Generative_Generalized_Zero-Shot_Learning_via_Task-Correlated_Disentanglement_and_Controllable_Samples_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Non-Generative_Generalized_Zero-Shot_Learning_via_Task-Correlated_Disentanglement_and_Controllable_Samples_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.05335)
626. Forward Compatible Few-Shot Class-Incremental Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Forward_Compatible_Few-Shot_Class-Incremental_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Forward_Compatible_Few-Shot_Class-Incremental_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Forward_Compatible_Few-Shot_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06953)
627. Ranking Distance Calibration for Cross-Domain Few-Shot Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Ranking_Distance_Calibration_for_Cross-Domain_Few-Shot_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Ranking_Distance_Calibration_for_Cross-Domain_Few-Shot_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Ranking_Distance_Calibration_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00260)
628. Learning Pixel Trajectories With Multiscale Contrastive Random Walks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bian_Learning_Pixel_Trajectories_With_Multiscale_Contrastive_Random_Walks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bian_Learning_Pixel_Trajectories_With_Multiscale_Contrastive_Random_Walks_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2201.08379)
629. Self-Supervised Correlation Mining Network for Person Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Self-Supervised_Correlation_Mining_Network_for_Person_Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Self-Supervised_Correlation_Mining_Network_for_Person_Image_Generation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.13307)
630. Task Adaptive Parameter Sharing for Multi-Task Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wallingford_Task_Adaptive_Parameter_Sharing_for_Multi-Task_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wallingford_Task_Adaptive_Parameter_Sharing_for_Multi-Task_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wallingford_Task_Adaptive_Parameter_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16708)
631. Finding Badly Drawn Bunnies | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Finding_Badly_Drawn_Bunnies_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Finding_Badly_Drawn_Bunnies_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Finding_Badly_Drawn_CVPR_2022_supplemental.pdf)
632. Transforming Model Prediction for Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mayer_Transforming_Model_Prediction_for_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mayer_Transforming_Model_Prediction_for_Tracking_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mayer_Transforming_Model_Prediction_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11192)
633. Open-Vocabulary Instance Segmentation via Robust Cross-Modal Pseudo-Labeling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huynh_Open-Vocabulary_Instance_Segmentation_via_Robust_Cross-Modal_Pseudo-Labeling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huynh_Open-Vocabulary_Instance_Segmentation_via_Robust_Cross-Modal_Pseudo-Labeling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huynh_Open-Vocabulary_Instance_Segmentation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12698)
634. Locality-Aware Inter- and Intra-Video Reconstruction for Self-Supervised Correspondence Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Locality-Aware_Inter-_and_Intra-Video_Reconstruction_for_Self-Supervised_Correspondence_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Locality-Aware_Inter-_and_Intra-Video_Reconstruction_for_Self-Supervised_Correspondence_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Locality-Aware_Inter-_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14333)
635. MeMOT- Multi-Object Tracking With Memory | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cai_MeMOT_Multi-Object_Tracking_With_Memory_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_MeMOT_Multi-Object_Tracking_With_Memory_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16761)
636. Semi-Supervised Semantic Segmentation With Error Localization Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kwon_Semi-Supervised_Semantic_Segmentation_With_Error_Localization_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kwon_Semi-Supervised_Semantic_Segmentation_With_Error_Localization_Network_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.02078)
637. Anomaly Detection via Reverse Distillation From One-Class Embedding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Deng_Anomaly_Detection_via_Reverse_Distillation_From_One-Class_Embedding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_Anomaly_Detection_via_Reverse_Distillation_From_One-Class_Embedding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Deng_Anomaly_Detection_via_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.10703)
638. Fine-Grained Object Classification via Self-Supervised Pose Alignment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Fine-Grained_Object_Classification_via_Self-Supervised_Pose_Alignment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Fine-Grained_Object_Classification_via_Self-Supervised_Pose_Alignment_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Fine-Grained_Object_Classification_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15987)
639. Spatio-Temporal Gating-Adjacency GCN for Human Motion Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_Spatio-Temporal_Gating-Adjacency_GCN_for_Human_Motion_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Spatio-Temporal_Gating-Adjacency_GCN_for_Human_Motion_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhong_Spatio-Temporal_Gating-Adjacency_GCN_CVPR_2022_supplemental.zip)
640. Back to Reality- Weakly-Supervised 3D Object Detection With Shape-Guided Label Enhancement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Back_to_Reality_Weakly-Supervised_3D_Object_Detection_With_Shape-Guided_Label_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Back_to_Reality_Weakly-Supervised_3D_Object_Detection_With_Shape-Guided_Label_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Back_to_Reality_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05238)
641. Long-Tail Recognition via Compositional Knowledge Transfer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Parisot_Long-Tail_Recognition_via_Compositional_Knowledge_Transfer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Parisot_Long-Tail_Recognition_via_Compositional_Knowledge_Transfer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Parisot_Long-Tail_Recognition_via_CVPR_2022_supplemental.pdf)
642. Self-Taught Metric Learning Without Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Self-Taught_Metric_Learning_Without_Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Self-Taught_Metric_Learning_Without_Labels_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Self-Taught_Metric_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.01903)
643. Embracing Single Stride 3D Object Detector With Sparse Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Embracing_Single_Stride_3D_Object_Detector_With_Sparse_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Embracing_Single_Stride_3D_Object_Detector_With_Sparse_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fan_Embracing_Single_Stride_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.06375)
644. Relieving Long-Tailed Instance Segmentation via Pairwise Class Balance | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_Relieving_Long-Tailed_Instance_Segmentation_via_Pairwise_Class_Balance_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Relieving_Long-Tailed_Instance_Segmentation_via_Pairwise_Class_Balance_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_Relieving_Long-Tailed_Instance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.02784)
645. Task2Sim- Towards Effective Pre-Training and Transfer From Synthetic Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mishra_Task2Sim_Towards_Effective_Pre-Training_and_Transfer_From_Synthetic_Data_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mishra_Task2Sim_Towards_Effective_Pre-Training_and_Transfer_From_Synthetic_Data_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mishra_Task2Sim_Towards_Effective_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00054)
646. Part-Based Pseudo Label Refinement for Unsupervised Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cho_Part-Based_Pseudo_Label_Refinement_for_Unsupervised_Person_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cho_Part-Based_Pseudo_Label_Refinement_for_Unsupervised_Person_Re-Identification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cho_Part-Based_Pseudo_Label_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14675)
647. OW-DETR- Open-World Detection Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gupta_OW-DETR_Open-World_Detection_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gupta_OW-DETR_Open-World_Detection_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gupta_OW-DETR_Open-World_Detection_CVPR_2022_supplemental.pdf)
648. Correlation Verification for Image Retrieval | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Correlation_Verification_for_Image_Retrieval_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Correlation_Verification_for_Image_Retrieval_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Correlation_Verification_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01458)
649. Pastiche Master- Exemplar-Based High-Resolution Portrait Style Transfer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Pastiche_Master_Exemplar-Based_High-Resolution_Portrait_Style_Transfer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Pastiche_Master_Exemplar-Based_High-Resolution_Portrait_Style_Transfer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Pastiche_Master_Exemplar-Based_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13248)
650. Learning To Memorize Feature Hallucination for One-Shot Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Learning_To_Memorize_Feature_Hallucination_for_One-Shot_Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Learning_To_Memorize_Feature_Hallucination_for_One-Shot_Image_Generation_CVPR_2022_paper.pdf)
651. Deterministic Point Cloud Registration via Novel Transformation Decomposition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Deterministic_Point_Cloud_Registration_via_Novel_Transformation_Decomposition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Deterministic_Point_Cloud_Registration_via_Novel_Transformation_Decomposition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Deterministic_Point_Cloud_CVPR_2022_supplemental.pdf)
652. Neural Prior for Trajectory Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Neural_Prior_for_Trajectory_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Neural_Prior_for_Trajectory_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Neural_Prior_for_CVPR_2022_supplemental.pdf)
653. Rethinking Depth Estimation for Multi-View Stereo- A Unified Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Peng_Rethinking_Depth_Estimation_for_Multi-View_Stereo_A_Unified_Representation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Rethinking_Depth_Estimation_for_Multi-View_Stereo_A_Unified_Representation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Peng_Rethinking_Depth_Estimation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.01501)
654. Long-Tailed Recognition via Weight Balancing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Alshammari_Long-Tailed_Recognition_via_Weight_Balancing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Alshammari_Long-Tailed_Recognition_via_Weight_Balancing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Alshammari_Long-Tailed_Recognition_via_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.14197)
655. ShapeFormer- Transformer-Based Shape Completion via Sparse Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yan_ShapeFormer_Transformer-Based_Shape_Completion_via_Sparse_Representation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_ShapeFormer_Transformer-Based_Shape_Completion_via_Sparse_Representation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yan_ShapeFormer_Transformer-Based_Shape_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2201.10326)
656. Learning Optical Flow With Kernel Patch Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Luo_Learning_Optical_Flow_With_Kernel_Patch_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Learning_Optical_Flow_With_Kernel_Patch_Attention_CVPR_2022_paper.pdf)
657. Global-Aware Registration of Less-Overlap RGB-D Scans | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Global-Aware_Registration_of_Less-Overlap_RGB-D_Scans_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Global-Aware_Registration_of_Less-Overlap_RGB-D_Scans_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sun_Global-Aware_Registration_of_CVPR_2022_supplemental.pdf)
658. RayMVSNet- Learning Ray-Based 1D Implicit Fields for Accurate Multi-View Stereo | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xi_RayMVSNet_Learning_Ray-Based_1D_Implicit_Fields_for_Accurate_Multi-View_Stereo_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xi_RayMVSNet_Learning_Ray-Based_1D_Implicit_Fields_for_Accurate_Multi-View_Stereo_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xi_RayMVSNet_Learning_Ray-Based_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01320)
659. Neural MoCon- Neural Motion Control for Physically Plausible Human Motion Capture | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Neural_MoCon_Neural_Motion_Control_for_Physically_Plausible_Human_Motion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Neural_MoCon_Neural_Motion_Control_for_Physically_Plausible_Human_Motion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Neural_MoCon_Neural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14065)
660. Revisiting Temporal Alignment for Video Restoration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Revisiting_Temporal_Alignment_for_Video_Restoration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Revisiting_Temporal_Alignment_for_Video_Restoration_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Revisiting_Temporal_Alignment_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15288)
661. OVE6D- Object Viewpoint Encoding for Depth-Based 6D Object Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cai_OVE6D_Object_Viewpoint_Encoding_for_Depth-Based_6D_Object_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_OVE6D_Object_Viewpoint_Encoding_for_Depth-Based_6D_Object_Pose_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cai_OVE6D_Object_Viewpoint_CVPR_2022_supplemental.pdf)
662. WALT- Watch and Learn 2D Amodal Representation From Time-Lapse Imagery | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Reddy_WALT_Watch_and_Learn_2D_Amodal_Representation_From_Time-Lapse_Imagery_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Reddy_WALT_Watch_and_Learn_2D_Amodal_Representation_From_Time-Lapse_Imagery_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Reddy_WALT_Watch_and_CVPR_2022_supplemental.zip)
663. GradViT- Gradient Inversion of Vision Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hatamizadeh_GradViT_Gradient_Inversion_of_Vision_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hatamizadeh_GradViT_Gradient_Inversion_of_Vision_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hatamizadeh_GradViT_Gradient_Inversion_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.11894)
664. Joint Global and Local Hierarchical Priors for Learned Image Compression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Joint_Global_and_Local_Hierarchical_Priors_for_Learned_Image_Compression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Joint_Global_and_Local_Hierarchical_Priors_for_Learned_Image_Compression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Joint_Global_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.04487)
665. Image Segmentation Using Text and Image Prompts | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Luddecke_Image_Segmentation_Using_Text_and_Image_Prompts_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Luddecke_Image_Segmentation_Using_Text_and_Image_Prompts_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Luddecke_Image_Segmentation_Using_CVPR_2022_supplemental.pdf)
666. How Many Observations Are Enough- Knowledge Distillation for Trajectory Forecasting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Monti_How_Many_Observations_Are_Enough_Knowledge_Distillation_for_Trajectory_Forecasting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Monti_How_Many_Observations_Are_Enough_Knowledge_Distillation_for_Trajectory_Forecasting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Monti_How_Many_Observations_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04781)
667. The Two Dimensions of Worst-Case Training and Their Integrated Effect for Out-of-Domain Generalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_The_Two_Dimensions_of_Worst-Case_Training_and_Their_Integrated_Effect_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_The_Two_Dimensions_of_Worst-Case_Training_and_Their_Integrated_Effect_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_The_Two_Dimensions_CVPR_2022_supplemental.pdf)
668. Global Tracking Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Global_Tracking_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Global_Tracking_Transformers_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.13250)
669. GMFlow- Learning Optical Flow via Global Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_GMFlow_Learning_Optical_Flow_via_Global_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_GMFlow_Learning_Optical_Flow_via_Global_Matching_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_GMFlow_Learning_Optical_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13680)
670. Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_Hierarchical_Cross-Modal_Association_for_Co-Speech_Gesture_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Hierarchical_Cross-Modal_Association_for_Co-Speech_Gesture_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Learning_Hierarchical_Cross-Modal_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13161)
671. Scanline Homographies for Rolling-Shutter Plane Absolute Pose | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bai_Scanline_Homographies_for_Rolling-Shutter_Plane_Absolute_Pose_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Scanline_Homographies_for_Rolling-Shutter_Plane_Absolute_Pose_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bai_Scanline_Homographies_for_CVPR_2022_supplemental.pdf)
672. Spectral Unsupervised Domain Adaptation for Visual Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Spectral_Unsupervised_Domain_Adaptation_for_Visual_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Spectral_Unsupervised_Domain_Adaptation_for_Visual_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Spectral_Unsupervised_Domain_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.06112)
673. Recurrent Glimpse-Based Decoder for Detection With Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Recurrent_Glimpse-Based_Decoder_for_Detection_With_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Recurrent_Glimpse-Based_Decoder_for_Detection_With_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Recurrent_Glimpse-Based_Decoder_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.04632)
674. SimMIM- A Simple Framework for Masked Image Modeling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_SimMIM_A_Simple_Framework_for_Masked_Image_Modeling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_SimMIM_A_Simple_Framework_for_Masked_Image_Modeling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xie_SimMIM_A_Simple_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.09886)
675. BCOT- A Markerless High-Precision 3D Object Tracking Benchmark | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_BCOT_A_Markerless_High-Precision_3D_Object_Tracking_Benchmark_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_BCOT_A_Markerless_High-Precision_3D_Object_Tracking_Benchmark_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_BCOT_A_Markerless_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13437)
676. Omni-DETR- Omni-Supervised Object Detection With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Omni-DETR_Omni-Supervised_Object_Detection_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Omni-DETR_Omni-Supervised_Object_Detection_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Omni-DETR_Omni-Supervised_Object_CVPR_2022_supplemental.pdf)
677. Improving Adversarially Robust Few-Shot Image Classification With Generalizable Representations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Improving_Adversarially_Robust_Few-Shot_Image_Classification_With_Generalizable_Representations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Improving_Adversarially_Robust_Few-Shot_Image_Classification_With_Generalizable_Representations_CVPR_2022_paper.pdf)
678. CREAM- Weakly Supervised Object Localization via Class RE-Activation Mapping | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_CREAM_Weakly_Supervised_Object_Localization_via_Class_RE-Activation_Mapping_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_CREAM_Weakly_Supervised_Object_Localization_via_Class_RE-Activation_Mapping_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.13922)
679. APRIL- Finding the Achilles' Heel on Privacy for Vision Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lu_APRIL_Finding_the_Achilles_Heel_on_Privacy_for_Vision_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_APRIL_Finding_the_Achilles_Heel_on_Privacy_for_Vision_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lu_APRIL_Finding_the_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.14087)
680. Text Spotting Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Text_Spotting_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Text_Spotting_Transformers_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.01918)
681. Mip-NeRF 360- Unbounded Anti-Aliased Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Barron_Mip-NeRF_360_Unbounded_Anti-Aliased_Neural_Radiance_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Barron_Mip-NeRF_360_Unbounded_Anti-Aliased_Neural_Radiance_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Barron_Mip-NeRF_360_Unbounded_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12077)
682. Incorporating Semi-Supervised and Positive-Unlabeled Learning for Boosting Full Reference Image Quality Assessment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cao_Incorporating_Semi-Supervised_and_Positive-Unlabeled_Learning_for_Boosting_Full_Reference_Image_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_Incorporating_Semi-Supervised_and_Positive-Unlabeled_Learning_for_Boosting_Full_Reference_Image_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cao_Incorporating_Semi-Supervised_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.08763)
683. HINT- Hierarchical Neuron Concept Explainer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_HINT_Hierarchical_Neuron_Concept_Explainer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_HINT_Hierarchical_Neuron_Concept_Explainer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_HINT_Hierarchical_Neuron_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14196)
684. Target-Aware Dual Adversarial Learning and a Multi-Scenario Multi-Modality Benchmark To Fuse Infrared and Visible for Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Target-Aware_Dual_Adversarial_Learning_and_a_Multi-Scenario_Multi-Modality_Benchmark_To_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Target-Aware_Dual_Adversarial_Learning_and_a_Multi-Scenario_Multi-Modality_Benchmark_To_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Target-Aware_Dual_Adversarial_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16220)
685. En-Compactness- Self-Distillation Embedding & Contrastive Generation for Generalized Zero-Shot Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kong_En-Compactness_Self-Distillation_Embedding__Contrastive_Generation_for_Generalized_Zero-Shot_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_En-Compactness_Self-Distillation_Embedding__Contrastive_Generation_for_Generalized_Zero-Shot_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kong_En-Compactness_Self-Distillation_Embedding_CVPR_2022_supplemental.pdf)
686. LC-FDNet- Learned Lossless Image Compression With Frequency Decomposition Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rhee_LC-FDNet_Learned_Lossless_Image_Compression_With_Frequency_Decomposition_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rhee_LC-FDNet_Learned_Lossless_Image_Compression_With_Frequency_Decomposition_Network_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rhee_LC-FDNet_Learned_Lossless_CVPR_2022_supplemental.pdf)
687. Deep Rectangling for Image Stitching- A Learning Baseline | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nie_Deep_Rectangling_for_Image_Stitching_A_Learning_Baseline_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nie_Deep_Rectangling_for_Image_Stitching_A_Learning_Baseline_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nie_Deep_Rectangling_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03831)
688. PCL- Proxy-Based Contrastive Learning for Domain Generalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yao_PCL_Proxy-Based_Contrastive_Learning_for_Domain_Generalization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yao_PCL_Proxy-Based_Contrastive_Learning_for_Domain_Generalization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yao_PCL_Proxy-Based_Contrastive_CVPR_2022_supplemental.pdf)
689. SurfEmb- Dense and Continuous Correspondence Distributions for Object Pose Estimation With Learnt Surface Embeddings | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Haugaard_SurfEmb_Dense_and_Continuous_Correspondence_Distributions_for_Object_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Haugaard_SurfEmb_Dense_and_Continuous_Correspondence_Distributions_for_Object_Pose_Estimation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.13489)
690. Unsupervised Learning of Accurate Siamese Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shen_Unsupervised_Learning_of_Accurate_Siamese_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Unsupervised_Learning_of_Accurate_Siamese_Tracking_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shen_Unsupervised_Learning_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01475)
691. Unified Transformer Tracker for Object Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Unified_Transformer_Tracker_for_Object_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Unified_Transformer_Tracker_for_Object_Tracking_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_Unified_Transformer_Tracker_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15175)
692. Non-Parametric Depth Distribution Modelling Based Depth Inference for Multi-View Stereo | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Non-Parametric_Depth_Distribution_Modelling_Based_Depth_Inference_for_Multi-View_Stereo_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Non-Parametric_Depth_Distribution_Modelling_Based_Depth_Inference_for_Multi-View_Stereo_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Non-Parametric_Depth_Distribution_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.03783)
693. Equalized Focal Loss for Dense Long-Tailed Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Equalized_Focal_Loss_for_Dense_Long-Tailed_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Equalized_Focal_Loss_for_Dense_Long-Tailed_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Equalized_Focal_Loss_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.02593)
694. DeepDPM- Deep Clustering With an Unknown Number of Clusters | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ronen_DeepDPM_Deep_Clustering_With_an_Unknown_Number_of_Clusters_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ronen_DeepDPM_Deep_Clustering_With_an_Unknown_Number_of_Clusters_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ronen_DeepDPM_Deep_Clustering_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14309)
695. Spiking Transformers for Event-Based Single Object Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Spiking_Transformers_for_Event-Based_Single_Object_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Spiking_Transformers_for_Event-Based_Single_Object_Tracking_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Spiking_Transformers_for_CVPR_2022_supplemental.pdf)
696. Unsupervised Domain Adaptation for Nighttime Aerial Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Unsupervised_Domain_Adaptation_for_Nighttime_Aerial_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Unsupervised_Domain_Adaptation_for_Nighttime_Aerial_Tracking_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_Unsupervised_Domain_Adaptation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10541)
697. Balanced Multimodal Learning via On-the-Fly Gradient Modulation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Peng_Balanced_Multimodal_Learning_via_On-the-Fly_Gradient_Modulation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Balanced_Multimodal_Learning_via_On-the-Fly_Gradient_Modulation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Peng_Balanced_Multimodal_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15332)
698. Causality Inspired Representation Learning for Domain Generalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lv_Causality_Inspired_Representation_Learning_for_Domain_Generalization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lv_Causality_Inspired_Representation_Learning_for_Domain_Generalization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lv_Causality_Inspired_Representation_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.14237)
699. Not Just Selection, but Exploration- Online Class-Incremental Continual Learning via Dual View Consistency | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gu_Not_Just_Selection_but_Exploration_Online_Class-Incremental_Continual_Learning_via_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Not_Just_Selection_but_Exploration_Online_Class-Incremental_Continual_Learning_via_CVPR_2022_paper.pdf)
700. Block-NeRF- Scalable Large Scene Neural View Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tancik_Block-NeRF_Scalable_Large_Scene_Neural_View_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tancik_Block-NeRF_Scalable_Large_Scene_Neural_View_Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tancik_Block-NeRF_Scalable_Large_CVPR_2022_supplemental.pdf)
701. B-Cos Networks- Alignment Is All We Need for Interpretability | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bohle_B-Cos_Networks_Alignment_Is_All_We_Need_for_Interpretability_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bohle_B-Cos_Networks_Alignment_Is_All_We_Need_for_Interpretability_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bohle_B-Cos_Networks_Alignment_CVPR_2022_supplemental.pdf)
702. Burst Image Restoration and Enhancement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dudhane_Burst_Image_Restoration_and_Enhancement_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dudhane_Burst_Image_Restoration_and_Enhancement_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dudhane_Burst_Image_Restoration_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.03680)
703. What Makes Transfer Learning Work for Medical Images- Feature Reuse & Other Factors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Matsoukas_What_Makes_Transfer_Learning_Work_for_Medical_Images_Feature_Reuse_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Matsoukas_What_Makes_Transfer_Learning_Work_for_Medical_Images_Feature_Reuse_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Matsoukas_What_Makes_Transfer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01825)
704. Audio-Visual Speech Codecs- Rethinking Audio-Visual Speech Enhancement by Re-Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Audio-Visual_Speech_Codecs_Rethinking_Audio-Visual_Speech_Enhancement_by_Re-Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Audio-Visual_Speech_Codecs_Rethinking_Audio-Visual_Speech_Enhancement_by_Re-Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Audio-Visual_Speech_Codecs_CVPR_2022_supplemental.pdf)
705. Localized Adversarial Domain Generalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Localized_Adversarial_Domain_Generalization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Localized_Adversarial_Domain_Generalization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Localized_Adversarial_Domain_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.04114)
706. X-Trans2Cap- Cross-Modal Knowledge Transfer Using Transformer for 3D Dense Captioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_X-Trans2Cap_Cross-Modal_Knowledge_Transfer_Using_Transformer_for_3D_Dense_Captioning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_X-Trans2Cap_Cross-Modal_Knowledge_Transfer_Using_Transformer_for_3D_Dense_Captioning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yuan_X-Trans2Cap_Cross-Modal_Knowledge_CVPR_2022_supplemental.pdf)
707. Image-to-Lidar Self-Supervised Distillation for Autonomous Driving Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sautier_Image-to-Lidar_Self-Supervised_Distillation_for_Autonomous_Driving_Data_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sautier_Image-to-Lidar_Self-Supervised_Distillation_for_Autonomous_Driving_Data_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sautier_Image-to-Lidar_Self-Supervised_Distillation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16258)
708. Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic Filter Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Explaining_Deep_Convolutional_Neural_Networks_via_Latent_Visual-Semantic_Filter_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Explaining_Deep_Convolutional_Neural_Networks_via_Latent_Visual-Semantic_Filter_Attention_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Explaining_Deep_Convolutional_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.04601)
709. Learning To Collaborate in Decentralized Learning of Personalized Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Learning_To_Collaborate_in_Decentralized_Learning_of_Personalized_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_To_Collaborate_in_Decentralized_Learning_of_Personalized_Models_CVPR_2022_paper.pdf)
710. Ref-NeRF- Structured View-Dependent Appearance for Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Verbin_Ref-NeRF_Structured_View-Dependent_Appearance_for_Neural_Radiance_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Verbin_Ref-NeRF_Structured_View-Dependent_Appearance_for_Neural_Radiance_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Verbin_Ref-NeRF_Structured_View-Dependent_CVPR_2022_supplemental.pdf)
711. Targeted Supervised Contrastive Learning for Long-Tailed Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Targeted_Supervised_Contrastive_Learning_for_Long-Tailed_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Targeted_Supervised_Contrastive_Learning_for_Long-Tailed_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Targeted_Supervised_Contrastive_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13998)
712. Balanced Contrastive Learning for Long-Tailed Visual Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Balanced_Contrastive_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Balanced_Contrastive_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Balanced_Contrastive_Learning_CVPR_2022_supplemental.pdf)
713. Slimmable Domain Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Meng_Slimmable_Domain_Adaptation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_Slimmable_Domain_Adaptation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Meng_Slimmable_Domain_Adaptation_CVPR_2022_supplemental.pdf)
714. DIP- Deep Inverse Patchmatch for High-Resolution Optical Flow | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_DIP_Deep_Inverse_Patchmatch_for_High-Resolution_Optical_Flow_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_DIP_Deep_Inverse_Patchmatch_for_High-Resolution_Optical_Flow_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_DIP_Deep_Inverse_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00330)
715. Few-Shot Object Detection With Fully Cross-Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Han_Few-Shot_Object_Detection_With_Fully_Cross-Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Few-Shot_Object_Detection_With_Fully_Cross-Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Han_Few-Shot_Object_Detection_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15021)
716. RendNet- Unified 2D-3D Recognizer With Latent Space Rendering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_RendNet_Unified_2D3D_Recognizer_With_Latent_Space_Rendering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_RendNet_Unified_2D3D_Recognizer_With_Latent_Space_Rendering_CVPR_2022_paper.pdf)
717. iPLAN- Interactive and Procedural Layout Planning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_iPLAN_Interactive_and_Procedural_Layout_Planning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_iPLAN_Interactive_and_Procedural_Layout_Planning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_iPLAN_Interactive_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14412)
718. Whose Track Is It Anyway- Improving Robustness to Tracking Errors With Affinity-Based Trajectory Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Weng_Whose_Track_Is_It_Anyway_Improving_Robustness_to_Tracking_Errors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Weng_Whose_Track_Is_It_Anyway_Improving_Robustness_to_Tracking_Errors_CVPR_2022_paper.pdf)
719. Balanced MSE for Imbalanced Visual Regression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Balanced_MSE_for_Imbalanced_Visual_Regression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Balanced_MSE_for_Imbalanced_Visual_Regression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ren_Balanced_MSE_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16427)
720. Local Learning Matters- Rethinking Data Heterogeneity in Federated Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mendieta_Local_Learning_Matters_Rethinking_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mendieta_Local_Learning_Matters_Rethinking_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mendieta_Local_Learning_Matters_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14213)
721. Finding Good Configurations of Planar Primitives in Unorganized Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Finding_Good_Configurations_of_Planar_Primitives_in_Unorganized_Point_Clouds_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Finding_Good_Configurations_of_Planar_Primitives_in_Unorganized_Point_Clouds_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_Finding_Good_Configurations_CVPR_2022_supplemental.zip)
722. FMCNet- Feature-Level Modality Compensation for Visible-Infrared Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_FMCNet_Feature-Level_Modality_Compensation_for_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_FMCNet_Feature-Level_Modality_Compensation_for_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_FMCNet_Feature-Level_Modality_CVPR_2022_supplemental.pdf)
723. Source-Free Domain Adaptation via Distribution Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Source-Free_Domain_Adaptation_via_Distribution_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Source-Free_Domain_Adaptation_via_Distribution_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ding_Source-Free_Domain_Adaptation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.11257)
724. Transferability Estimation Using Bhattacharyya Class Separability | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pandy_Transferability_Estimation_Using_Bhattacharyya_Class_Separability_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pandy_Transferability_Estimation_Using_Bhattacharyya_Class_Separability_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Pandy_Transferability_Estimation_Using_CVPR_2022_supplemental.pdf)
725. Hierarchical Self-Supervised Representation Learning for Movie Understanding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xiao_Hierarchical_Self-Supervised_Representation_Learning_for_Movie_Understanding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xiao_Hierarchical_Self-Supervised_Representation_Learning_for_Movie_Understanding_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.03101)
726. Does Robustness on ImageNet Transfer to Downstream Tasks- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yamada_Does_Robustness_on_ImageNet_Transfer_to_Downstream_Tasks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yamada_Does_Robustness_on_ImageNet_Transfer_to_Downstream_Tasks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yamada_Does_Robustness_on_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03934)
727. Faithful Extreme Rescaling via Generative Prior Reciprocated Invertible Representations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_Faithful_Extreme_Rescaling_via_Generative_Prior_Reciprocated_Invertible_Representations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Faithful_Extreme_Rescaling_via_Generative_Prior_Reciprocated_Invertible_Representations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhong_Faithful_Extreme_Rescaling_CVPR_2022_supplemental.pdf)
728. Proto2Proto- Can You Recognize the Car, the Way I Do- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Keswani_Proto2Proto_Can_You_Recognize_the_Car_the_Way_I_Do_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Keswani_Proto2Proto_Can_You_Recognize_the_Car_the_Way_I_Do_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Keswani_Proto2Proto_Can_You_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.11830)
729. Dual Adversarial Adaptation for Cross-Device Real-World Image Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Dual_Adversarial_Adaptation_for_Cross-Device_Real-World_Image_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Dual_Adversarial_Adaptation_for_Cross-Device_Real-World_Image_Super-Resolution_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.03524)
730. FS6D- Few-Shot 6D Pose Estimation of Novel Objects | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_FS6D_Few-Shot_6D_Pose_Estimation_of_Novel_Objects_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_FS6D_Few-Shot_6D_Pose_Estimation_of_Novel_Objects_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_FS6D_Few-Shot_6D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14628)
731. Reflection and Rotation Symmetry Detection via Equivariant Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Seo_Reflection_and_Rotation_Symmetry_Detection_via_Equivariant_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Seo_Reflection_and_Rotation_Symmetry_Detection_via_Equivariant_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Seo_Reflection_and_Rotation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16787)
732. CPPF- Towards Robust Category-Level 9D Pose Estimation in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/You_CPPF_Towards_Robust_Category-Level_9D_Pose_Estimation_in_the_Wild_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/You_CPPF_Towards_Robust_Category-Level_9D_Pose_Estimation_in_the_Wild_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/You_CPPF_Towards_Robust_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03089)
733. Interactive Disentanglement- Learning Concepts by Interacting With Their Prototype Representations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Stammer_Interactive_Disentanglement_Learning_Concepts_by_Interacting_With_Their_Prototype_Representations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Stammer_Interactive_Disentanglement_Learning_Concepts_by_Interacting_With_Their_Prototype_Representations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Stammer_Interactive_Disentanglement_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02290)
734. Recall@k Surrogate Loss With Large Batches and Similarity Mixup | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Patel_Recallk_Surrogate_Loss_With_Large_Batches_and_Similarity_Mixup_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Patel_Recallk_Surrogate_Loss_With_Large_Batches_and_Similarity_Mixup_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Patel_Recallk_Surrogate_Loss_CVPR_2022_supplemental.pdf)
735. Direct Voxel Grid Optimization- Super-Fast Convergence for Radiance Fields Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Direct_Voxel_Grid_Optimization_Super-Fast_Convergence_for_Radiance_Fields_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Direct_Voxel_Grid_Optimization_Super-Fast_Convergence_for_Radiance_Fields_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sun_Direct_Voxel_Grid_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.11215)
736. Continual Test-Time Domain Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Continual_Test-Time_Domain_Adaptation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Continual_Test-Time_Domain_Adaptation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Continual_Test-Time_Domain_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13591)
737. URetinex-Net- Retinex-Based Deep Unfolding Network for Low-Light Image Enhancement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_URetinex-Net_Retinex-Based_Deep_Unfolding_Network_for_Low-Light_Image_Enhancement_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_URetinex-Net_Retinex-Based_Deep_Unfolding_Network_for_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_URetinex-Net_Retinex-Based_Deep_CVPR_2022_supplemental.pdf)
738. Towards Multi-Domain Single Image Dehazing via Test-Time Training | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Towards_Multi-Domain_Single_Image_Dehazing_via_Test-Time_Training_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Multi-Domain_Single_Image_Dehazing_via_Test-Time_Training_CVPR_2022_paper.pdf)
739. Federated Learning With Position-Aware Neurons | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Federated_Learning_With_Position-Aware_Neurons_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Federated_Learning_With_Position-Aware_Neurons_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Federated_Learning_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14666)
740. Fair Contrastive Learning for Facial Attribute Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Park_Fair_Contrastive_Learning_for_Facial_Attribute_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Fair_Contrastive_Learning_for_Facial_Attribute_Classification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Park_Fair_Contrastive_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16209)
741. MDAN- Multi-Level Dependent Attention Network for Visual Emotion Analysis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_MDAN_Multi-Level_Dependent_Attention_Network_for_Visual_Emotion_Analysis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_MDAN_Multi-Level_Dependent_Attention_Network_for_Visual_Emotion_Analysis_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.13443)
742. RGB-Depth Fusion GAN for Indoor Depth Completion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_RGB-Depth_Fusion_GAN_for_Indoor_Depth_Completion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RGB-Depth_Fusion_GAN_for_Indoor_Depth_Completion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_RGB-Depth_Fusion_GAN_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10856)
743. Human Trajectory Prediction With Momentary Observation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Human_Trajectory_Prediction_With_Momentary_Observation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Human_Trajectory_Prediction_With_Momentary_Observation_CVPR_2022_paper.pdf)
744. Generating Representative Samples for Few-Shot Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Generating_Representative_Samples_for_Few-Shot_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Generating_Representative_Samples_for_Few-Shot_Classification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Generating_Representative_Samples_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.02918)
745. ELIC- Efficient Learned Image Compression With Unevenly Grouped Space-Channel Contextual Adaptive Coding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_ELIC_Efficient_Learned_Image_Compression_With_Unevenly_Grouped_Space-Channel_Contextual_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_ELIC_Efficient_Learned_Image_Compression_With_Unevenly_Grouped_Space-Channel_Contextual_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_ELIC_Efficient_Learned_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10886)
746. Do Explanations Explain- Model Knows Best | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Khakzar_Do_Explanations_Explain_Model_Knows_Best_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Khakzar_Do_Explanations_Explain_Model_Knows_Best_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Khakzar_Do_Explanations_Explain_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.02269)
747. BasicVSR++- Improving Video Super-Resolution With Enhanced Propagation and Alignment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chan_BasicVSR_Improving_Video_Super-Resolution_With_Enhanced_Propagation_and_Alignment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_BasicVSR_Improving_Video_Super-Resolution_With_Enhanced_Propagation_and_Alignment_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chan_BasicVSR_Improving_Video_CVPR_2022_supplemental.pdf)
748. GuideFormer- Transformers for Image Guided Depth Completion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rho_GuideFormer_Transformers_for_Image_Guided_Depth_Completion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rho_GuideFormer_Transformers_for_Image_Guided_Depth_Completion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rho_GuideFormer_Transformers_for_CVPR_2022_supplemental.pdf)
749. Region-Aware Face Swapping | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Region-Aware_Face_Swapping_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Region-Aware_Face_Swapping_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.04564)
750. CamLiFlow- Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_CamLiFlow_Bidirectional_Camera-LiDAR_Fusion_for_Joint_Optical_Flow_and_Scene_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_CamLiFlow_Bidirectional_Camera-LiDAR_Fusion_for_Joint_Optical_Flow_and_Scene_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_CamLiFlow_Bidirectional_Camera-LiDAR_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.10502)
751. BNV-Fusion- Dense 3D Reconstruction Using Bi-Level Neural Volume Fusion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_BNV-Fusion_Dense_3D_Reconstruction_Using_Bi-Level_Neural_Volume_Fusion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_BNV-Fusion_Dense_3D_Reconstruction_Using_Bi-Level_Neural_Volume_Fusion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_BNV-Fusion_Dense_3D_CVPR_2022_supplemental.pdf)
752. Reflash Dropout in Image Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kong_Reflash_Dropout_in_Image_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_Reflash_Dropout_in_Image_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kong_Reflash_Dropout_in_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.12089)
753. WildNet- Learning Domain Generalized Semantic Segmentation From the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_WildNet_Learning_Domain_Generalized_Semantic_Segmentation_From_the_Wild_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_WildNet_Learning_Domain_Generalized_Semantic_Segmentation_From_the_Wild_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_WildNet_Learning_Domain_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01446)
754. Auditing Privacy Defenses in Federated Learning via Generative Gradient Leakage | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Auditing_Privacy_Defenses_in_Federated_Learning_via_Generative_Gradient_Leakage_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Auditing_Privacy_Defenses_in_Federated_Learning_via_Generative_Gradient_Leakage_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Auditing_Privacy_Defenses_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15696)
755. Task Discrepancy Maximization for Fine-Grained Few-Shot Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Task_Discrepancy_Maximization_for_Fine-Grained_Few-Shot_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Task_Discrepancy_Maximization_for_Fine-Grained_Few-Shot_Classification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Task_Discrepancy_Maximization_CVPR_2022_supplemental.pdf)
756. FedDC- Federated Learning With Non-IID Data via Local Drift Decoupling and Correction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gao_FedDC_Federated_Learning_With_Non-IID_Data_via_Local_Drift_Decoupling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_FedDC_Federated_Learning_With_Non-IID_Data_via_Local_Drift_Decoupling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gao_FedDC_Federated_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11751)
757. Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hou_Point-to-Voxel_Knowledge_Distillation_for_LiDAR_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_Point-to-Voxel_Knowledge_Distillation_for_LiDAR_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hou_Point-to-Voxel_Knowledge_Distillation_CVPR_2022_supplemental.pdf)
758. Leveling Down in Computer Vision- Pareto Inefficiencies in Fair Deep Classifiers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zietlow_Leveling_Down_in_Computer_Vision_Pareto_Inefficiencies_in_Fair_Deep_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zietlow_Leveling_Down_in_Computer_Vision_Pareto_Inefficiencies_in_Fair_Deep_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zietlow_Leveling_Down_in_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04913)
759. Adiabatic Quantum Computing for Multi Object Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zaech_Adiabatic_Quantum_Computing_for_Multi_Object_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zaech_Adiabatic_Quantum_Computing_for_Multi_Object_Tracking_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zaech_Adiabatic_Quantum_Computing_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2202.08837)
760. Represent, Compare, and Learn- A Similarity-Aware Framework for Class-Agnostic Counting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_Represent_Compare_and_Learn_A_Similarity-Aware_Framework_for_Class-Agnostic_Counting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Represent_Compare_and_Learn_A_Similarity-Aware_Framework_for_Class-Agnostic_Counting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shi_Represent_Compare_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08354)
761. Critical Regularizations for Neural Surface Reconstruction in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Critical_Regularizations_for_Neural_Surface_Reconstruction_in_the_Wild_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Critical_Regularizations_for_Neural_Surface_Reconstruction_in_the_Wild_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Critical_Regularizations_for_CVPR_2022_supplemental.zip)
762. EASE- Unsupervised Discriminant Subspace Learning for Transductive Few-Shot Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_EASE_Unsupervised_Discriminant_Subspace_Learning_for_Transductive_Few-Shot_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_EASE_Unsupervised_Discriminant_Subspace_Learning_for_Transductive_Few-Shot_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_EASE_Unsupervised_Discriminant_CVPR_2022_supplemental.pdf)
763. UCC- Uncertainty Guided Cross-Head Co-Training for Semi-Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_UCC_Uncertainty_Guided_Cross-Head_Co-Training_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_UCC_Uncertainty_Guided_Cross-Head_Co-Training_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.10334)
764. HVH- Learning a Hybrid Neural Volumetric Representation for Dynamic Hair Performance Capture | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_HVH_Learning_a_Hybrid_Neural_Volumetric_Representation_for_Dynamic_Hair_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_HVH_Learning_a_Hybrid_Neural_Volumetric_Representation_for_Dynamic_Hair_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_HVH_Learning_a_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.06904)
765. Learning Based Multi-Modality Image and Video Compression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Learning_Based_Multi-Modality_Image_and_Video_Compression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Learning_Based_Multi-Modality_Image_and_Video_Compression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lu_Learning_Based_Multi-Modality_CVPR_2022_supplemental.pdf)
766. Ditto- Building Digital Twins of Articulated Objects From Interaction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Ditto_Building_Digital_Twins_of_Articulated_Objects_From_Interaction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Ditto_Building_Digital_Twins_of_Articulated_Objects_From_Interaction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jiang_Ditto_Building_Digital_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.08227)
767. Transformer Based Line Segment Classifier With Image Context for Real-Time Vanishing Point Detection in Manhattan World | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tong_Transformer_Based_Line_Segment_Classifier_With_Image_Context_for_Real-Time_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tong_Transformer_Based_Line_Segment_Classifier_With_Image_Context_for_Real-Time_CVPR_2022_paper.pdf)
768. Self-Sustaining Representation Expansion for Non-Exemplar Class-Incremental Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Self-Sustaining_Representation_Expansion_for_Non-Exemplar_Class-Incremental_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Self-Sustaining_Representation_Expansion_for_Non-Exemplar_Class-Incremental_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Self-Sustaining_Representation_Expansion_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06359)
769. Cross-Domain Correlation Distillation for Unsupervised Domain Adaptation in Nighttime Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gao_Cross-Domain_Correlation_Distillation_for_Unsupervised_Domain_Adaptation_in_Nighttime_Semantic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Cross-Domain_Correlation_Distillation_for_Unsupervised_Domain_Adaptation_in_Nighttime_Semantic_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gao_Cross-Domain_Correlation_Distillation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.00858)
770. More Than Words- In-the-Wild Visually-Driven Prosody for Text-to-Speech | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hassid_More_Than_Words_In-the-Wild_Visually-Driven_Prosody_for_Text-to-Speech_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hassid_More_Than_Words_In-the-Wild_Visually-Driven_Prosody_for_Text-to-Speech_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hassid_More_Than_Words_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.10139)
771. Cross-Modal Perceptionist- Can Face Geometry Be Gleaned From Voices- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Cross-Modal_Perceptionist_Can_Face_Geometry_Be_Gleaned_From_Voices_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Cross-Modal_Perceptionist_Can_Face_Geometry_Be_Gleaned_From_Voices_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Cross-Modal_Perceptionist_Can_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09824)
772. On Generalizing Beyond Domains in Cross-Domain Continual Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Simon_On_Generalizing_Beyond_Domains_in_Cross-Domain_Continual_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Simon_On_Generalizing_Beyond_Domains_in_Cross-Domain_Continual_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Simon_On_Generalizing_Beyond_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03970)
773. A Closer Look at Few-Shot Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_A_Closer_Look_at_Few-Shot_Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_A_Closer_Look_at_Few-Shot_Image_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_A_Closer_Look_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.03805)
774. Unsupervised Domain Generalization by Learning a Bridge Across Domains | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Harary_Unsupervised_Domain_Generalization_by_Learning_a_Bridge_Across_Domains_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Harary_Unsupervised_Domain_Generalization_by_Learning_a_Bridge_Across_Domains_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Harary_Unsupervised_Domain_Generalization_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02300)
775. Learning Trajectory-Aware Transformer for Video Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_Trajectory-Aware_Transformer_for_Video_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Trajectory-Aware_Transformer_for_Video_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Learning_Trajectory-Aware_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04216)
776. Graph Sampling Based Deep Metric Learning for Generalizable Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liao_Graph_Sampling_Based_Deep_Metric_Learning_for_Generalizable_Person_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Graph_Sampling_Based_Deep_Metric_Learning_for_Generalizable_Person_Re-Identification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liao_Graph_Sampling_Based_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.01546)
777. Undoing the Damage of Label Shift for Cross-Domain Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Undoing_the_Damage_of_Label_Shift_for_Cross-Domain_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Undoing_the_Damage_of_Label_Shift_for_Cross-Domain_Semantic_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.05546)
778. GPV-Pose- Category-Level Object Pose Estimation via Geometry-Guided Point-Wise Voting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Di_GPV-Pose_Category-Level_Object_Pose_Estimation_via_Geometry-Guided_Point-Wise_Voting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Di_GPV-Pose_Category-Level_Object_Pose_Estimation_via_Geometry-Guided_Point-Wise_Voting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Di_GPV-Pose_Category-Level_Object_CVPR_2022_supplemental.pdf)
779. Trustworthy Long-Tailed Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Trustworthy_Long-Tailed_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Trustworthy_Long-Tailed_Classification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Trustworthy_Long-Tailed_Classification_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.09030)
780. Mix and Localize- Localizing Sound Sources in Mixtures | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Mix_and_Localize_Localizing_Sound_Sources_in_Mixtures_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Mix_and_Localize_Localizing_Sound_Sources_in_Mixtures_CVPR_2022_paper.pdf)
781. SphericGAN- Semi-Supervised Hyper-Spherical Generative Adversarial Networks for Fine-Grained Image Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_SphericGAN_Semi-Supervised_Hyper-Spherical_Generative_Adversarial_Networks_for_Fine-Grained_Image_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_SphericGAN_Semi-Supervised_Hyper-Spherical_Generative_Adversarial_Networks_for_Fine-Grained_Image_Synthesis_CVPR_2022_paper.pdf)
782. Image Dehazing Transformer With Transmission-Aware 3D Position Embedding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Image_Dehazing_Transformer_With_Transmission-Aware_3D_Position_Embedding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Image_Dehazing_Transformer_With_Transmission-Aware_3D_Position_Embedding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_Image_Dehazing_Transformer_CVPR_2022_supplemental.pdf)
783. Deformable ProtoPNet- An Interpretable Image Classifier Using Deformable Prototypes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Donnelly_Deformable_ProtoPNet_An_Interpretable_Image_Classifier_Using_Deformable_Prototypes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Donnelly_Deformable_ProtoPNet_An_Interpretable_Image_Classifier_Using_Deformable_Prototypes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Donnelly_Deformable_ProtoPNet_An_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15000)
784. Context-Aware Sequence Alignment Using 4D Skeletal Augmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kwon_Context-Aware_Sequence_Alignment_Using_4D_Skeletal_Augmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kwon_Context-Aware_Sequence_Alignment_Using_4D_Skeletal_Augmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kwon_Context-Aware_Sequence_Alignment_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.12223)
785. Motion-Modulated Temporal Fragment Alignment Network for Few-Shot Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Motion-Modulated_Temporal_Fragment_Alignment_Network_for_Few-Shot_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Motion-Modulated_Temporal_Fragment_Alignment_Network_for_Few-Shot_Action_Recognition_CVPR_2022_paper.pdf)
786. Focal Sparse Convolutional Networks for 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Focal_Sparse_Convolutional_Networks_for_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Focal_Sparse_Convolutional_Networks_for_3D_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Focal_Sparse_Convolutional_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.12463)
787. Nested Collaborative Learning for Long-Tailed Visual Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Nested_Collaborative_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Nested_Collaborative_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Nested_Collaborative_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15359)
788. Restormer- Efficient Transformer for High-Resolution Image Restoration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zamir_Restormer_Efficient_Transformer_for_High-Resolution_Image_Restoration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zamir_Restormer_Efficient_Transformer_for_High-Resolution_Image_Restoration_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zamir_Restormer_Efficient_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.09881)
789. Learning Distinctive Margin Toward Active Domain Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Learning_Distinctive_Margin_Toward_Active_Domain_Adaptation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Learning_Distinctive_Margin_Toward_Active_Domain_Adaptation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xie_Learning_Distinctive_Margin_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05738)
790. Neural Inertial Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Herath_Neural_Inertial_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Herath_Neural_Inertial_Localization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Herath_Neural_Inertial_Localization_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15851)
791. Finding Fallen Objects via Asynchronous Audio-Visual Integration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gan_Finding_Fallen_Objects_via_Asynchronous_Audio-Visual_Integration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gan_Finding_Fallen_Objects_via_Asynchronous_Audio-Visual_Integration_CVPR_2022_paper.pdf)
792. Semi-Supervised Object Detection via Multi-Instance Alignment With Global Class Prototypes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Semi-Supervised_Object_Detection_via_Multi-Instance_Alignment_With_Global_Class_Prototypes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Semi-Supervised_Object_Detection_via_Multi-Instance_Alignment_With_Global_Class_Prototypes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Semi-Supervised_Object_Detection_CVPR_2022_supplemental.pdf)
793. VGSE- Visually-Grounded Semantic Embeddings for Zero-Shot Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_VGSE_Visually-Grounded_Semantic_Embeddings_for_Zero-Shot_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_VGSE_Visually-Grounded_Semantic_Embeddings_for_Zero-Shot_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_VGSE_Visually-Grounded_Semantic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10444)
794. Catching Both Gray and Black Swans- Open-Set Supervised Anomaly Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Catching_Both_Gray_and_Black_Swans_Open-Set_Supervised_Anomaly_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Catching_Both_Gray_and_Black_Swans_Open-Set_Supervised_Anomaly_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ding_Catching_Both_Gray_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14506)
795. Multimodal Colored Point Cloud to Image Alignment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rotstein_Multimodal_Colored_Point_Cloud_to_Image_Alignment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rotstein_Multimodal_Colored_Point_Cloud_to_Image_Alignment_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rotstein_Multimodal_Colored_Point_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.03249)
796. MotionAug- Augmentation With Physical Correction for Human Motion Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Maeda_MotionAug_Augmentation_With_Physical_Correction_for_Human_Motion_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Maeda_MotionAug_Augmentation_With_Physical_Correction_for_Human_Motion_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Maeda_MotionAug_Augmentation_With_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.09116)
797. Unsupervised Deraining- Where Contrastive Learning Meets Self-Similarity | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Unsupervised_Deraining_Where_Contrastive_Learning_Meets_Self-Similarity_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Unsupervised_Deraining_Where_Contrastive_Learning_Meets_Self-Similarity_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_Unsupervised_Deraining_Where_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11509)
798. Simple Multi-Dataset Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Simple_Multi-Dataset_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Simple_Multi-Dataset_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Simple_Multi-Dataset_Detection_CVPR_2022_supplemental.pdf)
799. Sketch3T- Test-Time Training for Zero-Shot SBIR | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sain_Sketch3T_Test-Time_Training_for_Zero-Shot_SBIR_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sain_Sketch3T_Test-Time_Training_for_Zero-Shot_SBIR_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sain_Sketch3T_Test-Time_Training_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14691)
800. Towards Discriminative Representation- Multi-View Trajectory Contrastive Learning for Online Multi-Object Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Towards_Discriminative_Representation_Multi-View_Trajectory_Contrastive_Learning_for_Online_Multi-Object_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Towards_Discriminative_Representation_Multi-View_Trajectory_Contrastive_Learning_for_Online_Multi-Object_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.14208)
801. Audio-Visual Generalised Zero-Shot Learning With Cross-Modal Attention and Language | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mercea_Audio-Visual_Generalised_Zero-Shot_Learning_With_Cross-Modal_Attention_and_Language_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mercea_Audio-Visual_Generalised_Zero-Shot_Learning_With_Cross-Modal_Attention_and_Language_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mercea_Audio-Visual_Generalised_Zero-Shot_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03598)
802. AdaMixer- A Fast-Converging Query-Based Object Detector | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gao_AdaMixer_A_Fast-Converging_Query-Based_Object_Detector_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_AdaMixer_A_Fast-Converging_Query-Based_Object_Detector_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gao_AdaMixer_A_Fast-Converging_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.16507)
803. Deep Unlearning via Randomized Conditionally Independent Hessians | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mehta_Deep_Unlearning_via_Randomized_Conditionally_Independent_Hessians_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mehta_Deep_Unlearning_via_Randomized_Conditionally_Independent_Hessians_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mehta_Deep_Unlearning_via_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.07655)
804. Patch-Level Representation Learning for Self-Supervised Vision Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yun_Patch-Level_Representation_Learning_for_Self-Supervised_Vision_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yun_Patch-Level_Representation_Learning_for_Self-Supervised_Vision_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yun_Patch-Level_Representation_Learning_CVPR_2022_supplemental.pdf)
805. Sylph- A Hypernetwork Framework for Incremental Few-Shot Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yin_Sylph_A_Hypernetwork_Framework_for_Incremental_Few-Shot_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_Sylph_A_Hypernetwork_Framework_for_Incremental_Few-Shot_Object_Detection_CVPR_2022_paper.pdf)
806. What To Look at and Where- Semantic and Spatial Refined Transformer for Detecting Human-Object Interactions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Iftekhar_What_To_Look_at_and_Where_Semantic_and_Spatial_Refined_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Iftekhar_What_To_Look_at_and_Where_Semantic_and_Spatial_Refined_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Iftekhar_What_To_Look_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00746)
807. Stereo Magnification With Multi-Layer Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Khakhulin_Stereo_Magnification_With_Multi-Layer_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Khakhulin_Stereo_Magnification_With_Multi-Layer_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Khakhulin_Stereo_Magnification_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.05023)
808. LMGP- Lifted Multicut Meets Geometry Projections for Multi-Camera Multi-Object Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_LMGP_Lifted_Multicut_Meets_Geometry_Projections_for_Multi-Camera_Multi-Object_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_LMGP_Lifted_Multicut_Meets_Geometry_Projections_for_Multi-Camera_Multi-Object_Tracking_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nguyen_LMGP_Lifted_Multicut_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.11892)
809. Stereo Depth From Events Cameras- Concentrate and Focus on the Future | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nam_Stereo_Depth_From_Events_Cameras_Concentrate_and_Focus_on_the_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nam_Stereo_Depth_From_Events_Cameras_Concentrate_and_Focus_on_the_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nam_Stereo_Depth_From_CVPR_2022_supplemental.pdf)
810. A Probabilistic Graphical Model Based on Neural-Symbolic Reasoning for Visual Relationship Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_A_Probabilistic_Graphical_Model_Based_on_Neural-Symbolic_Reasoning_for_Visual_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_A_Probabilistic_Graphical_Model_Based_on_Neural-Symbolic_Reasoning_for_Visual_CVPR_2022_paper.pdf)
811. Knowledge Distillation As Efficient Pre-Training- Faster Convergence, Higher Data-Efficiency, and Better Transferability | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_Knowledge_Distillation_As_Efficient_Pre-Training_Faster_Convergence_Higher_Data-Efficiency_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Knowledge_Distillation_As_Efficient_Pre-Training_Faster_Convergence_Higher_Data-Efficiency_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_Knowledge_Distillation_As_CVPR_2022_supplemental.pdf)
812. Integrative Few-Shot Learning for Classification and Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kang_Integrative_Few-Shot_Learning_for_Classification_and_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Integrative_Few-Shot_Learning_for_Classification_and_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kang_Integrative_Few-Shot_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15712)
813. Learning Fair Classifiers With Partially Annotated Group Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jung_Learning_Fair_Classifiers_With_Partially_Annotated_Group_Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jung_Learning_Fair_Classifiers_With_Partially_Annotated_Group_Labels_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jung_Learning_Fair_Classifiers_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14581)
814. Constrained Few-Shot Class-Incremental Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hersche_Constrained_Few-Shot_Class-Incremental_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hersche_Constrained_Few-Shot_Class-Incremental_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hersche_Constrained_Few-Shot_Class-Incremental_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16588)
815. Self-Supervised Material and Texture Representation Learning for Remote Sensing Tasks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Akiva_Self-Supervised_Material_and_Texture_Representation_Learning_for_Remote_Sensing_Tasks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Akiva_Self-Supervised_Material_and_Texture_Representation_Learning_for_Remote_Sensing_Tasks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Akiva_Self-Supervised_Material_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01715)
816. Think Twice Before Detecting GAN-Generated Fake Images From Their Spectral Domain Imprints | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Think_Twice_Before_Detecting_GAN-Generated_Fake_Images_From_Their_Spectral_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Think_Twice_Before_Detecting_GAN-Generated_Fake_Images_From_Their_Spectral_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_Think_Twice_Before_CVPR_2022_supplemental.pdf)
817. RSCFed- Random Sampling Consensus Federated Semi-Supervised Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_RSCFed_Random_Sampling_Consensus_Federated_Semi-Supervised_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_RSCFed_Random_Sampling_Consensus_Federated_Semi-Supervised_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liang_RSCFed_Random_Sampling_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13993)
818. TransMVSNet- Global Context-Aware Multi-View Stereo Network With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_TransMVSNet_Global_Context-Aware_Multi-View_Stereo_Network_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_TransMVSNet_Global_Context-Aware_Multi-View_Stereo_Network_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ding_TransMVSNet_Global_Context-Aware_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14600)
819. iFS-RCNN- An Incremental Few-Shot Instance Segmenter | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_iFS-RCNN_An_Incremental_Few-Shot_Instance_Segmenter_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_iFS-RCNN_An_Incremental_Few-Shot_Instance_Segmenter_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nguyen_iFS-RCNN_An_Incremental_CVPR_2022_supplemental.pdf)
820. DPGEN- Differentially Private Generative Energy-Guided Network for Natural Image Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_DPGEN_Differentially_Private_Generative_Energy-Guided_Network_for_Natural_Image_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_DPGEN_Differentially_Private_Generative_Energy-Guided_Network_for_Natural_Image_Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_DPGEN_Differentially_Private_CVPR_2022_supplemental.pdf)
821. The Majority Can Help the Minority- Context-Rich Minority Oversampling for Long-Tailed Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Park_The_Majority_Can_Help_the_Minority_Context-Rich_Minority_Oversampling_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_The_Majority_Can_Help_the_Minority_Context-Rich_Minority_Oversampling_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Park_The_Majority_Can_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00412)
822. IntentVizor- Towards Generic Query Guided Interactive Video Summarization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_IntentVizor_Towards_Generic_Query_Guided_Interactive_Video_Summarization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_IntentVizor_Towards_Generic_Query_Guided_Interactive_Video_Summarization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_IntentVizor_Towards_Generic_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2109.14834)
823. Scene Representation Transformer- Geometry-Free Novel View Synthesis Through Set-Latent Scene Representations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sajjadi_Scene_Representation_Transformer_Geometry-Free_Novel_View_Synthesis_Through_Set-Latent_Scene_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sajjadi_Scene_Representation_Transformer_Geometry-Free_Novel_View_Synthesis_Through_Set-Latent_Scene_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sajjadi_Scene_Representation_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13152)
824. Bootstrapping ViTs- Towards Liberating Vision Transformers From Pre-Training | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Bootstrapping_ViTs_Towards_Liberating_Vision_Transformers_From_Pre-Training_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Bootstrapping_ViTs_Towards_Liberating_Vision_Transformers_From_Pre-Training_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Bootstrapping_ViTs_Towards_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.03552)
825. Styleformer- Transformer Based Generative Adversarial Networks With Style Vector | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Park_Styleformer_Transformer_Based_Generative_Adversarial_Networks_With_Style_Vector_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Styleformer_Transformer_Based_Generative_Adversarial_Networks_With_Style_Vector_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Park_Styleformer_Transformer_Based_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.07023)
826. Light Field Neural Rendering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Suhail_Light_Field_Neural_Rendering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Suhail_Light_Field_Neural_Rendering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Suhail_Light_Field_Neural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.09687)
827. Augmented Geometric Distillation for Data-Free Incremental Person ReID | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Augmented_Geometric_Distillation_for_Data-Free_Incremental_Person_ReID_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Augmented_Geometric_Distillation_for_Data-Free_Incremental_Person_ReID_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lu_Augmented_Geometric_Distillation_CVPR_2022_supplemental.pdf)
828. Style Neophile- Constantly Seeking Novel Styles for Domain Generalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kang_Style_Neophile_Constantly_Seeking_Novel_Styles_for_Domain_Generalization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Style_Neophile_Constantly_Seeking_Novel_Styles_for_Domain_Generalization_CVPR_2022_paper.pdf)
829. RIO- Rotation-Equivariance Supervised Learning of Robust Inertial Odometry | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cao_RIO_Rotation-Equivariance_Supervised_Learning_of_Robust_Inertial_Odometry_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_RIO_Rotation-Equivariance_Supervised_Learning_of_Robust_Inertial_Odometry_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cao_RIO_Rotation-Equivariance_Supervised_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.11676)
830. Adaptive Trajectory Prediction via Transferable GNN | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Adaptive_Trajectory_Prediction_via_Transferable_GNN_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Adaptive_Trajectory_Prediction_via_Transferable_GNN_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Adaptive_Trajectory_Prediction_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05046)
831. Deformation and Correspondence Aware Unsupervised Synthetic-to-Real Scene Flow Estimation for Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jin_Deformation_and_Correspondence_Aware_Unsupervised_Synthetic-to-Real_Scene_Flow_Estimation_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Deformation_and_Correspondence_Aware_Unsupervised_Synthetic-to-Real_Scene_Flow_Estimation_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jin_Deformation_and_Correspondence_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16895)
832. Learn From Others and Be Yourself in Heterogeneous Federated Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Learn_From_Others_and_Be_Yourself_in_Heterogeneous_Federated_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Learn_From_Others_and_Be_Yourself_in_Heterogeneous_Federated_Learning_CVPR_2022_paper.pdf)
833. Semantic-Aware Auto-Encoders for Self-Supervised Representation Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Semantic-Aware_Auto-Encoders_for_Self-Supervised_Representation_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Semantic-Aware_Auto-Encoders_for_Self-Supervised_Representation_Learning_CVPR_2022_paper.pdf)
834. Consistent Explanations by Contrastive Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pillai_Consistent_Explanations_by_Contrastive_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pillai_Consistent_Explanations_by_Contrastive_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Pillai_Consistent_Explanations_by_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2110.00527)
835. Text2Pos- Text-to-Point-Cloud Cross-Modal Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kolmet_Text2Pos_Text-to-Point-Cloud_Cross-Modal_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kolmet_Text2Pos_Text-to-Point-Cloud_Cross-Modal_Localization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kolmet_Text2Pos_Text-to-Point-Cloud_Cross-Modal_CVPR_2022_supplemental.pdf)
836. Salient-to-Broad Transition for Video Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bai_Salient-to-Broad_Transition_for_Video_Person_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Salient-to-Broad_Transition_for_Video_Person_Re-Identification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bai_Salient-to-Broad_Transition_for_CVPR_2022_supplemental.pdf)
837. Progressively Generating Better Initial Guesses Towards Next Stages for High-Quality Human Motion Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Progressively_Generating_Better_Initial_Guesses_Towards_Next_Stages_for_High-Quality_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Progressively_Generating_Better_Initial_Guesses_Towards_Next_Stages_for_High-Quality_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_Progressively_Generating_Better_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16051)
838. M2I- From Factored Marginal Trajectory Prediction to Interactive Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_M2I_From_Factored_Marginal_Trajectory_Prediction_to_Interactive_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_M2I_From_Factored_Marginal_Trajectory_Prediction_to_Interactive_Prediction_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2202.11884)
839. Domain Adaptation on Point Clouds via Geometry-Aware Implicits | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shen_Domain_Adaptation_on_Point_Clouds_via_Geometry-Aware_Implicits_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Domain_Adaptation_on_Point_Clouds_via_Geometry-Aware_Implicits_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shen_Domain_Adaptation_on_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.09343)
840. NeuralHOFusion- Neural Volumetric Rendering Under Human-Object Interactions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_NeuralHOFusion_Neural_Volumetric_Rendering_Under_Human-Object_Interactions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_NeuralHOFusion_Neural_Volumetric_Rendering_Under_Human-Object_Interactions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jiang_NeuralHOFusion_Neural_Volumetric_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.12825)
841. Cross-Domain Few-Shot Learning With Task-Specific Adapters | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Cross-Domain_Few-Shot_Learning_With_Task-Specific_Adapters_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Cross-Domain_Few-Shot_Learning_With_Task-Specific_Adapters_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Cross-Domain_Few-Shot_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2107.00358)
842. MAXIM- Multi-Axis MLP for Image Processing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tu_MAXIM_Multi-Axis_MLP_for_Image_Processing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tu_MAXIM_Multi-Axis_MLP_for_Image_Processing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tu_MAXIM_Multi-Axis_MLP_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.02973)
843. Towards Better Understanding Attribution Methods | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rao_Towards_Better_Understanding_Attribution_Methods_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rao_Towards_Better_Understanding_Attribution_Methods_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rao_Towards_Better_Understanding_CVPR_2022_supplemental.pdf)
844. PSTR- End-to-End One-Step Person Search With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cao_PSTR_End-to-End_One-Step_Person_Search_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_PSTR_End-to-End_One-Step_Person_Search_With_Transformers_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.03340)
845. NFormer- Robust Person Re-Identification With Neighbor Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_NFormer_Robust_Person_Re-Identification_With_Neighbor_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_NFormer_Robust_Person_Re-Identification_With_Neighbor_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_NFormer_Robust_Person_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.09331)
846. Unseen Classes at a Later Time- No Problem | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kuchibhotla_Unseen_Classes_at_a_Later_Time_No_Problem_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kuchibhotla_Unseen_Classes_at_a_Later_Time_No_Problem_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kuchibhotla_Unseen_Classes_at_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16517)
847. Learning the Degradation Distribution for Blind Image Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Luo_Learning_the_Degradation_Distribution_for_Blind_Image_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Learning_the_Degradation_Distribution_for_Blind_Image_Super-Resolution_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.04962)
848. Retrieval Augmented Classification for Long-Tail Visual Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Long_Retrieval_Augmented_Classification_for_Long-Tail_Visual_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Long_Retrieval_Augmented_Classification_for_Long-Tail_Visual_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Long_Retrieval_Augmented_Classification_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.11233)
849. NLX-GPT- A Model for Natural Language Explanations in Vision and Vision-Language Tasks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sammani_NLX-GPT_A_Model_for_Natural_Language_Explanations_in_Vision_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sammani_NLX-GPT_A_Model_for_Natural_Language_Explanations_in_Vision_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sammani_NLX-GPT_A_Model_CVPR_2022_supplemental.pdf)
850. WarpingGAN- Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_WarpingGAN_Warping_Multiple_Uniform_Priors_for_Adversarial_3D_Point_Cloud_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_WarpingGAN_Warping_Multiple_Uniform_Priors_for_Adversarial_3D_Point_Cloud_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_WarpingGAN_Warping_Multiple_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12917)
851. Forward Propagation, Backward Regression, and Pose Association for Hand Tracking in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Forward_Propagation_Backward_Regression_and_Pose_Association_for_Hand_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Forward_Propagation_Backward_Regression_and_Pose_Association_for_Hand_Tracking_CVPR_2022_paper.pdf)
852. ES6D- A Computation Efficient and Symmetry-Aware 6D Pose Regression Framework | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mo_ES6D_A_Computation_Efficient_and_Symmetry-Aware_6D_Pose_Regression_Framework_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mo_ES6D_A_Computation_Efficient_and_Symmetry-Aware_6D_Pose_Regression_Framework_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mo_ES6D_A_Computation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01080)
853. OoD-Bench- Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_OoD-Bench_Quantifying_and_Understanding_Two_Dimensions_of_Out-of-Distribution_Generalization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_OoD-Bench_Quantifying_and_Understanding_Two_Dimensions_of_Out-of-Distribution_Generalization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_OoD-Bench_Quantifying_and_CVPR_2022_supplemental.pdf)
854. OnePose- One-Shot Object Pose Estimation Without CAD Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_OnePose_One-Shot_Object_Pose_Estimation_Without_CAD_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_OnePose_One-Shot_Object_Pose_Estimation_Without_CAD_Models_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.12257)
855. Federated Class-Incremental Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Federated_Class-Incremental_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Federated_Class-Incremental_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_Federated_Class-Incremental_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11473)
856. Extracting Triangular 3D Models, Materials, and Lighting From Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Munkberg_Extracting_Triangular_3D_Models_Materials_and_Lighting_From_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Munkberg_Extracting_Triangular_3D_Models_Materials_and_Lighting_From_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Munkberg_Extracting_Triangular_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12503)
857. Parameter-Free Online Test-Time Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Boudiaf_Parameter-Free_Online_Test-Time_Adaptation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Boudiaf_Parameter-Free_Online_Test-Time_Adaptation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Boudiaf_Parameter-Free_Online_Test-Time_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.05718)
858. SIGMA- Semantic-Complete Graph Matching for Domain Adaptive Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_SIGMA_Semantic-Complete_Graph_Matching_for_Domain_Adaptive_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_SIGMA_Semantic-Complete_Graph_Matching_for_Domain_Adaptive_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_SIGMA_Semantic-Complete_Graph_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06398)
859. Global Convergence of MAML and Theory-Inspired Neural Architecture Search for Few-Shot Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Global_Convergence_of_MAML_and_Theory-Inspired_Neural_Architecture_Search_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Global_Convergence_of_MAML_and_Theory-Inspired_Neural_Architecture_Search_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Global_Convergence_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09137)
860. No Pain, Big Gain- Classify Dynamic Point Cloud Sequences With Static Models by Fitting Feature-Level Space-Time Surfaces | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_No_Pain_Big_Gain_Classify_Dynamic_Point_Cloud_Sequences_With_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_No_Pain_Big_Gain_Classify_Dynamic_Point_Cloud_Sequences_With_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhong_No_Pain_Big_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11113)
861. HiVT- Hierarchical Vector Transformer for Multi-Agent Motion Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_HiVT_Hierarchical_Vector_Transformer_for_Multi-Agent_Motion_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_HiVT_Hierarchical_Vector_Transformer_for_Multi-Agent_Motion_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_HiVT_Hierarchical_Vector_CVPR_2022_supplemental.pdf)
862. Correlation-Aware Deep Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Correlation-Aware_Deep_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Correlation-Aware_Deep_Tracking_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xie_Correlation-Aware_Deep_Tracking_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01666)
863. Implicit Sample Extension for Unsupervised Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Implicit_Sample_Extension_for_Unsupervised_Person_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Implicit_Sample_Extension_for_Unsupervised_Person_Re-Identification_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.06892)
864. Energy-Based Latent Aligner for Incremental Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Joseph_Energy-Based_Latent_Aligner_for_Incremental_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Joseph_Energy-Based_Latent_Aligner_for_Incremental_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Joseph_Energy-Based_Latent_Aligner_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.14952)
865. GanOrCon- Are Generative Models Useful for Few-Shot Segmentation- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Saha_GanOrCon_Are_Generative_Models_Useful_for_Few-Shot_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Saha_GanOrCon_Are_Generative_Models_Useful_for_Few-Shot_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Saha_GanOrCon_Are_Generative_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00854)
866. Reading To Listen at the Cocktail Party- Multi-Modal Speech Separation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rahimi_Reading_To_Listen_at_the_Cocktail_Party_Multi-Modal_Speech_Separation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rahimi_Reading_To_Listen_at_the_Cocktail_Party_Multi-Modal_Speech_Separation_CVPR_2022_paper.pdf)
867. Group R-CNN for Weakly Semi-Supervised Object Detection With Points | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Group_R-CNN_for_Weakly_Semi-Supervised_Object_Detection_With_Points_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Group_R-CNN_for_Weakly_Semi-Supervised_Object_Detection_With_Points_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Group_R-CNN_for_CVPR_2022_supplemental.pdf)
868. Weakly-Supervised Action Transition Learning for Stochastic Human Motion Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mao_Weakly-Supervised_Action_Transition_Learning_for_Stochastic_Human_Motion_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mao_Weakly-Supervised_Action_Transition_Learning_for_Stochastic_Human_Motion_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mao_Weakly-Supervised_Action_Transition_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2205.15608)
869. Coarse-To-Fine Deep Video Coding With Hyperprior-Guided Mode Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Coarse-To-Fine_Deep_Video_Coding_With_Hyperprior-Guided_Mode_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Coarse-To-Fine_Deep_Video_Coding_With_Hyperprior-Guided_Mode_Prediction_CVPR_2022_paper.pdf)
870. SAR-Net- Shape Alignment and Recovery Network for Category-Level 6D Object Pose and Size Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_SAR-Net_Shape_Alignment_and_Recovery_Network_for_Category-Level_6D_Object_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SAR-Net_Shape_Alignment_and_Recovery_Network_for_Category-Level_6D_Object_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_SAR-Net_Shape_Alignment_CVPR_2022_supplemental.zip)
871. Mutual Quantization for Cross-Modal Search With Noisy Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Mutual_Quantization_for_Cross-Modal_Search_With_Noisy_Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Mutual_Quantization_for_Cross-Modal_Search_With_Noisy_Labels_CVPR_2022_paper.pdf)
872. SphereSR- 360deg Image Super-Resolution With Arbitrary Projection via Continuous Spherical Image Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yoon_SphereSR_360deg_Image_Super-Resolution_With_Arbitrary_Projection_via_Continuous_Spherical_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yoon_SphereSR_360deg_Image_Super-Resolution_With_Arbitrary_Projection_via_Continuous_Spherical_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yoon_SphereSR_360deg_Image_CVPR_2022_supplemental.pdf)
873. Cross Domain Object Detection by Target-Perceived Dual Branch Distillation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_Cross_Domain_Object_Detection_by_Target-Perceived_Dual_Branch_Distillation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Cross_Domain_Object_Detection_by_Target-Perceived_Dual_Branch_Distillation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_Cross_Domain_Object_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.01291)
874. Overcoming Catastrophic Forgetting in Incremental Object Detection via Elastic Response Distillation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Overcoming_Catastrophic_Forgetting_in_Incremental_Object_Detection_via_Elastic_Response_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Overcoming_Catastrophic_Forgetting_in_Incremental_Object_Detection_via_Elastic_Response_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.02136)
875. GroupNet- Multiscale Hypergraph Neural Networks for Trajectory Prediction With Relational Reasoning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_GroupNet_Multiscale_Hypergraph_Neural_Networks_for_Trajectory_Prediction_With_Relational_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_GroupNet_Multiscale_Hypergraph_Neural_Networks_for_Trajectory_Prediction_With_Relational_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_GroupNet_Multiscale_Hypergraph_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.08770)
876. Unbiased Subclass Regularization for Semi-Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guan_Unbiased_Subclass_Regularization_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Unbiased_Subclass_Regularization_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.10026)
877. Coupled Iterative Refinement for 6D Multi-Object Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lipson_Coupled_Iterative_Refinement_for_6D_Multi-Object_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lipson_Coupled_Iterative_Refinement_for_6D_Multi-Object_Pose_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lipson_Coupled_Iterative_Refinement_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.12516)
878. Weakly Paired Associative Learning for Sound and Image Representations via Bimodal Associative Memory | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Weakly_Paired_Associative_Learning_for_Sound_and_Image_Representations_via_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Weakly_Paired_Associative_Learning_for_Sound_and_Image_Representations_via_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Weakly_Paired_Associative_CVPR_2022_supplemental.pdf)
879. PCA-Based Knowledge Distillation Towards Lightweight and Content-Style Balanced Photorealistic Style Transfer Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chiu_PCA-Based_Knowledge_Distillation_Towards_Lightweight_and_Content-Style_Balanced_Photorealistic_Style_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chiu_PCA-Based_Knowledge_Distillation_Towards_Lightweight_and_Content-Style_Balanced_Photorealistic_Style_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chiu_PCA-Based_Knowledge_Distillation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13452)
880. Transformer Tracking With Cyclic Shifting Window Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Song_Transformer_Tracking_With_Cyclic_Shifting_Window_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Song_Transformer_Tracking_With_Cyclic_Shifting_Window_Attention_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Song_Transformer_Tracking_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.03806)
881. ProposalCLIP- Unsupervised Open-Category Object Proposal Generation via Exploiting CLIP Cues | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_ProposalCLIP_Unsupervised_Open-Category_Object_Proposal_Generation_via_Exploiting_CLIP_Cues_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_ProposalCLIP_Unsupervised_Open-Category_Object_Proposal_Generation_via_Exploiting_CLIP_Cues_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2201.06696)
882. Towards Understanding Adversarial Robustness of Optical Flow Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Schrodi_Towards_Understanding_Adversarial_Robustness_of_Optical_Flow_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Schrodi_Towards_Understanding_Adversarial_Robustness_of_Optical_Flow_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Schrodi_Towards_Understanding_Adversarial_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2103.16255)
883. Unsupervised Representation Learning for Binary Networks by Joint Classifier Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Unsupervised_Representation_Learning_for_Binary_Networks_by_Joint_Classifier_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Unsupervised_Representation_Learning_for_Binary_Networks_by_Joint_Classifier_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Unsupervised_Representation_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.08851)
884. Investigating Tradeoffs in Real-World Video Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chan_Investigating_Tradeoffs_in_Real-World_Video_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Investigating_Tradeoffs_in_Real-World_Video_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chan_Investigating_Tradeoffs_in_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12704)
885. Differentiable Stereopsis- Meshes From Multiple Views Using Differentiable Rendering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Goel_Differentiable_Stereopsis_Meshes_From_Multiple_Views_Using_Differentiable_Rendering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Goel_Differentiable_Stereopsis_Meshes_From_Multiple_Views_Using_Differentiable_Rendering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Goel_Differentiable_Stereopsis_Meshes_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.05472)
886. Global Tracking via Ensemble of Local Trackers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Global_Tracking_via_Ensemble_of_Local_Trackers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Global_Tracking_via_Ensemble_of_Local_Trackers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Global_Tracking_via_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16092)
887. MPC- Multi-View Probabilistic Clustering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_MPC_Multi-View_Probabilistic_Clustering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_MPC_Multi-View_Probabilistic_Clustering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_MPC_Multi-View_Probabilistic_CVPR_2022_supplemental.pdf)
888. MSDN- Mutually Semantic Distillation Network for Zero-Shot Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_MSDN_Mutually_Semantic_Distillation_Network_for_Zero-Shot_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_MSDN_Mutually_Semantic_Distillation_Network_for_Zero-Shot_Learning_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.03137)
889. MS2DG-Net- Progressive Correspondence Learning via Multiple Sparse Semantics Dynamic Graph | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dai_MS2DG-Net_Progressive_Correspondence_Learning_via_Multiple_Sparse_Semantics_Dynamic_Graph_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_MS2DG-Net_Progressive_Correspondence_Learning_via_Multiple_Sparse_Semantics_Dynamic_Graph_CVPR_2022_paper.pdf)
890. Sparse Fuse Dense- Towards High Quality 3D Detection With Depth Completion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Sparse_Fuse_Dense_Towards_High_Quality_3D_Detection_With_Depth_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Sparse_Fuse_Dense_Towards_High_Quality_3D_Detection_With_Depth_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Sparse_Fuse_Dense_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09780)
891. PNP- Robust Learning From Noisy Labels by Probabilistic Noise Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_PNP_Robust_Learning_From_Noisy_Labels_by_Probabilistic_Noise_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_PNP_Robust_Learning_From_Noisy_Labels_by_Probabilistic_Noise_Prediction_CVPR_2022_paper.pdf)
892. Estimating Structural Disparities for Face Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ardeshir_Estimating_Structural_Disparities_for_Face_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ardeshir_Estimating_Structural_Disparities_for_Face_Models_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.06562)
893. Revisiting the Transferability of Supervised Pretraining- An MLP Perspective | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Revisiting_the_Transferability_of_Supervised_Pretraining_An_MLP_Perspective_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Revisiting_the_Transferability_of_Supervised_Pretraining_An_MLP_Perspective_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Revisiting_the_Transferability_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00496)
894. Plenoxels- Radiance Fields Without Neural Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fridovich-Keil_Plenoxels_Radiance_Fields_Without_Neural_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fridovich-Keil_Plenoxels_Radiance_Fields_Without_Neural_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fridovich-Keil_Plenoxels_Radiance_Fields_CVPR_2022_supplemental.pdf)
895. SimT- Handling Open-Set Noise for Domain Adaptive Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_SimT_Handling_Open-Set_Noise_for_Domain_Adaptive_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_SimT_Handling_Open-Set_Noise_for_Domain_Adaptive_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_SimT_Handling_Open-Set_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15202)
896. PLAD- Learning To Infer Shape Programs With Pseudo-Labels and Approximate Distributions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jones_PLAD_Learning_To_Infer_Shape_Programs_With_Pseudo-Labels_and_Approximate_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jones_PLAD_Learning_To_Infer_Shape_Programs_With_Pseudo-Labels_and_Approximate_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jones_PLAD_Learning_To_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2011.13045)
897. PTTR- Relational 3D Point Cloud Object Tracking With Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_PTTR_Relational_3D_Point_Cloud_Object_Tracking_With_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_PTTR_Relational_3D_Point_Cloud_Object_Tracking_With_Transformer_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.02857)
898. Industrial Style Transfer With Large-Scale Geometric Warping and Content Preservation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Industrial_Style_Transfer_With_Large-Scale_Geometric_Warping_and_Content_Preservation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Industrial_Style_Transfer_With_Large-Scale_Geometric_Warping_and_Content_Preservation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Industrial_Style_Transfer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12835)
899. Modeling Image Composition for Complex Scene Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Modeling_Image_Composition_for_Complex_Scene_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Modeling_Image_Composition_for_Complex_Scene_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Modeling_Image_Composition_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2206.00923)
900. SS3D- Sparsely-Supervised 3D Object Detection From Point Cloud | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_SS3D_Sparsely-Supervised_3D_Object_Detection_From_Point_Cloud_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_SS3D_Sparsely-Supervised_3D_Object_Detection_From_Point_Cloud_CVPR_2022_paper.pdf)
901. Remember the Difference- Cross-Domain Few-Shot Semantic Segmentation via Meta-Memory Transfer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Remember_the_Difference_Cross-Domain_Few-Shot_Semantic_Segmentation_via_Meta-Memory_Transfer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Remember_the_Difference_Cross-Domain_Few-Shot_Semantic_Segmentation_via_Meta-Memory_Transfer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Remember_the_Difference_CVPR_2022_supplemental.pdf)
902. Templates for 3D Object Pose Estimation Revisited- Generalization to New Objects and Robustness to Occlusions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_Templates_for_3D_Object_Pose_Estimation_Revisited_Generalization_to_New_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_Templates_for_3D_Object_Pose_Estimation_Revisited_Generalization_to_New_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nguyen_Templates_for_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.17234)
903. Non-Isotropy Regularization for Proxy-Based Deep Metric Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Roth_Non-Isotropy_Regularization_for_Proxy-Based_Deep_Metric_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Roth_Non-Isotropy_Regularization_for_Proxy-Based_Deep_Metric_Learning_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.08547)
904. Learning a Structured Latent Space for Unsupervised Point Cloud Completion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cai_Learning_a_Structured_Latent_Space_for_Unsupervised_Point_Cloud_Completion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Learning_a_Structured_Latent_Space_for_Unsupervised_Point_Cloud_Completion_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.15580)
905. Few-Shot Learning With Noisy Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Few-Shot_Learning_With_Noisy_Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Few-Shot_Learning_With_Noisy_Labels_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liang_Few-Shot_Learning_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.05494)
906. Interactive Image Synthesis With Panoptic Layout Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Interactive_Image_Synthesis_With_Panoptic_Layout_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Interactive_Image_Synthesis_With_Panoptic_Layout_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Interactive_Image_Synthesis_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02104)
907. PlanarRecon- Real-Time 3D Plane Detection and Reconstruction From Posed Monocular Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_PlanarRecon_Real-Time_3D_Plane_Detection_and_Reconstruction_From_Posed_Monocular_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_PlanarRecon_Real-Time_3D_Plane_Detection_and_Reconstruction_From_Posed_Monocular_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xie_PlanarRecon_Real-Time_3D_CVPR_2022_supplemental.pdf)
908. Motron- Multimodal Probabilistic Human Motion Forecasting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Salzmann_Motron_Multimodal_Probabilistic_Human_Motion_Forecasting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Salzmann_Motron_Multimodal_Probabilistic_Human_Motion_Forecasting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Salzmann_Motron_Multimodal_Probabilistic_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.04132)
909. Cycle-Consistent Counterfactuals by Latent Transformations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Khorram_Cycle-Consistent_Counterfactuals_by_Latent_Transformations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Khorram_Cycle-Consistent_Counterfactuals_by_Latent_Transformations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Khorram_Cycle-Consistent_Counterfactuals_by_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15064)
910. ADeLA- Automatic Dense Labeling With Attention for Viewpoint Shift in Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_ADeLA_Automatic_Dense_Labeling_With_Attention_for_Viewpoint_Shift_in_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_ADeLA_Automatic_Dense_Labeling_With_Attention_for_Viewpoint_Shift_in_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ren_ADeLA_Automatic_Dense_CVPR_2022_supplemental.pdf)
911. Blind Face Restoration via Integrating Face Shape and Generative Priors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Blind_Face_Restoration_via_Integrating_Face_Shape_and_Generative_Priors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Blind_Face_Restoration_via_Integrating_Face_Shape_and_Generative_Priors_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Blind_Face_Restoration_CVPR_2022_supplemental.pdf)
912. RCP- Recurrent Closest Point for Point Cloud | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gu_RCP_Recurrent_Closest_Point_for_Point_Cloud_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_RCP_Recurrent_Closest_Point_for_Point_Cloud_CVPR_2022_paper.pdf)
913. A Dual Weighting Label Assignment Scheme for Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_A_Dual_Weighting_Label_Assignment_Scheme_for_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_A_Dual_Weighting_Label_Assignment_Scheme_for_Object_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.09730)
914. FAM- Visual Explanations for the Feature Representations From Deep Convolutional Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_FAM_Visual_Explanations_for_the_Feature_Representations_From_Deep_Convolutional_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_FAM_Visual_Explanations_for_the_Feature_Representations_From_Deep_Convolutional_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_FAM_Visual_Explanations_CVPR_2022_supplemental.pdf)
915. Hyperbolic Vision Transformers- Combining Improvements in Metric Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ermolov_Hyperbolic_Vision_Transformers_Combining_Improvements_in_Metric_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ermolov_Hyperbolic_Vision_Transformers_Combining_Improvements_in_Metric_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ermolov_Hyperbolic_Vision_Transformers_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10833)
916. Attributable Visual Similarity Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Attributable_Visual_Similarity_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Attributable_Visual_Similarity_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Attributable_Visual_Similarity_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14932)
917. DyTox- Transformers for Continual Learning With DYnamic TOken eXpansion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Douillard_DyTox_Transformers_for_Continual_Learning_With_DYnamic_TOken_eXpansion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Douillard_DyTox_Transformers_for_Continual_Learning_With_DYnamic_TOken_eXpansion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Douillard_DyTox_Transformers_for_CVPR_2022_supplemental.pdf)
918. Semantic-Aligned Fusion Transformer for One-Shot Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Semantic-Aligned_Fusion_Transformer_for_One-Shot_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Semantic-Aligned_Fusion_Transformer_for_One-Shot_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_Semantic-Aligned_Fusion_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09093)
919. Beyond Supervised vs. Unsupervised- Representative Benchmarking and Analysis of Image Representation Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gwilliam_Beyond_Supervised_vs._Unsupervised_Representative_Benchmarking_and_Analysis_of_Image_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gwilliam_Beyond_Supervised_vs._Unsupervised_Representative_Benchmarking_and_Analysis_of_Image_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gwilliam_Beyond_Supervised_vs._CVPR_2022_supplemental.pdf)
920. Discrete Time Convolution for Fast Event-Based Stereo | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Discrete_Time_Convolution_for_Fast_Event-Based_Stereo_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Discrete_Time_Convolution_for_Fast_Event-Based_Stereo_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Discrete_Time_Convolution_CVPR_2022_supplemental.pdf)
921. Improving Visual Grounding With Visual-Linguistic Verification and Iterative Reasoning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Improving_Visual_Grounding_With_Visual-Linguistic_Verification_and_Iterative_Reasoning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Improving_Visual_Grounding_With_Visual-Linguistic_Verification_and_Iterative_Reasoning_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.00272)
922. Learning Robust Image-Based Rendering on Sparse Scene Geometry via Depth Completion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Learning_Robust_Image-Based_Rendering_on_Sparse_Scene_Geometry_via_Depth_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Learning_Robust_Image-Based_Rendering_on_Sparse_Scene_Geometry_via_Depth_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sun_Learning_Robust_Image-Based_CVPR_2022_supplemental.pdf)
923. Self-Supervised Object Detection From Audio-Visual Correspondence | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Afouras_Self-Supervised_Object_Detection_From_Audio-Visual_Correspondence_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Afouras_Self-Supervised_Object_Detection_From_Audio-Visual_Correspondence_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2104.06401)
924. Super-Fibonacci Spirals- Fast, Low-Discrepancy Sampling of SO(3) | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Alexa_Super-Fibonacci_Spirals_Fast_Low-Discrepancy_Sampling_of_SO3_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Alexa_Super-Fibonacci_Spirals_Fast_Low-Discrepancy_Sampling_of_SO3_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Alexa_Super-Fibonacci_Spirals_Fast_CVPR_2022_supplemental.pdf)
925. TrackFormer- Multi-Object Tracking With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Meinhardt_TrackFormer_Multi-Object_Tracking_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Meinhardt_TrackFormer_Multi-Object_Tracking_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Meinhardt_TrackFormer_Multi-Object_Tracking_CVPR_2022_supplemental.pdf)
926. Learning To Learn and Remember Super Long Multi-Domain Task Sequence | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Learning_To_Learn_and_Remember_Super_Long_Multi-Domain_Task_Sequence_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learning_To_Learn_and_Remember_Super_Long_Multi-Domain_Task_Sequence_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Learning_To_Learn_CVPR_2022_supplemental.zip)
927. Domain-Agnostic Prior for Transfer Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huo_Domain-Agnostic_Prior_for_Transfer_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huo_Domain-Agnostic_Prior_for_Transfer_Semantic_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.02684)
928. Dynamic Kernel Selection for Improved Generalization and Memory Efficiency in Meta-Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chavan_Dynamic_Kernel_Selection_for_Improved_Generalization_and_Memory_Efficiency_in_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chavan_Dynamic_Kernel_Selection_for_Improved_Generalization_and_Memory_Efficiency_in_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chavan_Dynamic_Kernel_Selection_CVPR_2022_supplemental.pdf)
929. Differentially Private Federated Learning With Local Regularization and Sparsification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Differentially_Private_Federated_Learning_With_Local_Regularization_and_Sparsification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Differentially_Private_Federated_Learning_With_Local_Regularization_and_Sparsification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cheng_Differentially_Private_Federated_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03106)
930. Learning Semantic Associations for Mirror Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guan_Learning_Semantic_Associations_for_Mirror_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Learning_Semantic_Associations_for_Mirror_Detection_CVPR_2022_paper.pdf)
931. Reconstructing Surfaces for Sparse Point Clouds With On-Surface Priors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Reconstructing_Surfaces_for_Sparse_Point_Clouds_With_On-Surface_Priors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Reconstructing_Surfaces_for_Sparse_Point_Clouds_With_On-Surface_Priors_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_Reconstructing_Surfaces_for_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.10603)
932. Contrastive Conditional Neural Processes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Contrastive_Conditional_Neural_Processes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Contrastive_Conditional_Neural_Processes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_Contrastive_Conditional_Neural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03978)
933. Robust Equivariant Imaging- A Fully Unsupervised Framework for Learning To Image From Noisy and Partial Measurements | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Robust_Equivariant_Imaging_A_Fully_Unsupervised_Framework_for_Learning_To_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Robust_Equivariant_Imaging_A_Fully_Unsupervised_Framework_for_Learning_To_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Robust_Equivariant_Imaging_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2111.12855)
934. Self-Supervised Global-Local Structure Modeling for Point Cloud Domain Adaptation With Reliable Voted Pseudo Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Self-Supervised_Global-Local_Structure_Modeling_for_Point_Cloud_Domain_Adaptation_With_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Self-Supervised_Global-Local_Structure_Modeling_for_Point_Cloud_Domain_Adaptation_With_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fan_Self-Supervised_Global-Local_Structure_CVPR_2022_supplemental.pdf)
935. Input-Level Inductive Biases for 3D Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yifan_Input-Level_Inductive_Biases_for_3D_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yifan_Input-Level_Inductive_Biases_for_3D_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yifan_Input-Level_Inductive_Biases_CVPR_2022_supplemental.pdf)
936. Real-Time Object Detection for Streaming Perception | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Real-Time_Object_Detection_for_Streaming_Perception_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Real-Time_Object_Detection_for_Streaming_Perception_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.12338)
937. Equivariance Allows Handling Multiple Nuisance Variables When Analyzing Pooled Neuroimaging Datasets | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lokhande_Equivariance_Allows_Handling_Multiple_Nuisance_Variables_When_Analyzing_Pooled_Neuroimaging_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lokhande_Equivariance_Allows_Handling_Multiple_Nuisance_Variables_When_Analyzing_Pooled_Neuroimaging_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lokhande_Equivariance_Allows_Handling_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.15234)
938. Bi-Level Alignment for Cross-Domain Crowd Counting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gong_Bi-Level_Alignment_for_Cross-Domain_Crowd_Counting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_Bi-Level_Alignment_for_Cross-Domain_Crowd_Counting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gong_Bi-Level_Alignment_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.05844)
939. Efficient Multi-View Stereo by Iterative Dynamic Cost Volume | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Efficient_Multi-View_Stereo_by_Iterative_Dynamic_Cost_Volume_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Efficient_Multi-View_Stereo_by_Iterative_Dynamic_Cost_Volume_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Efficient_Multi-View_Stereo_CVPR_2022_supplemental.pdf)
940. Learning To Generate Line Drawings That Convey Geometry and Semantics | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chan_Learning_To_Generate_Line_Drawings_That_Convey_Geometry_and_Semantics_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Learning_To_Generate_Line_Drawings_That_Convey_Geometry_and_Semantics_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.12691)
941. TransEditor- Transformer-Based Dual-Space GAN for Highly Controllable Facial Editing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_TransEditor_Transformer-Based_Dual-Space_GAN_for_Highly_Controllable_Facial_Editing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_TransEditor_Transformer-Based_Dual-Space_GAN_for_Highly_Controllable_Facial_Editing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_TransEditor_Transformer-Based_Dual-Space_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.17266)
942. Neural Volumetric Object Selection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Neural_Volumetric_Object_Selection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Neural_Volumetric_Object_Selection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.14929)
943. PointCLIP- Point Cloud Understanding by CLIP | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_PointCLIP_Point_Cloud_Understanding_by_CLIP_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_PointCLIP_Point_Cloud_Understanding_by_CLIP_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_PointCLIP_Point_Cloud_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02413)
944. NeRFusion- Fusing Radiance Fields for Large-Scale Scene Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_NeRFusion_Fusing_Radiance_Fields_for_Large-Scale_Scene_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_NeRFusion_Fusing_Radiance_Fields_for_Large-Scale_Scene_Reconstruction_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.11283)
945. Reusing the Task-Specific Classifier as a Discriminator- Discriminator-Free Adversarial Domain Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Reusing_the_Task-Specific_Classifier_as_a_Discriminator_Discriminator-Free_Adversarial_Domain_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Reusing_the_Task-Specific_Classifier_as_a_Discriminator_Discriminator-Free_Adversarial_Domain_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Reusing_the_Task-Specific_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03838)
946. Bijective Mapping Network for Shadow Removal | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Bijective_Mapping_Network_for_Shadow_Removal_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Bijective_Mapping_Network_for_Shadow_Removal_CVPR_2022_paper.pdf)
947. Causal Transportability for Visual Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mao_Causal_Transportability_for_Visual_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mao_Causal_Transportability_for_Visual_Recognition_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.12363)
948. Local Attention Pyramid for Scene Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shim_Local_Attention_Pyramid_for_Scene_Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shim_Local_Attention_Pyramid_for_Scene_Image_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shim_Local_Attention_Pyramid_CVPR_2022_supplemental.pdf)
949. Multi-Objective Diverse Human Motion Prediction With Knowledge Distillation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Multi-Objective_Diverse_Human_Motion_Prediction_With_Knowledge_Distillation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Multi-Objective_Diverse_Human_Motion_Prediction_With_Knowledge_Distillation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_Multi-Objective_Diverse_Human_CVPR_2022_supplemental.pdf)
950. GridShift- A Faster Mode-Seeking Algorithm for Image Segmentation and Object Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kumar_GridShift_A_Faster_Mode-Seeking_Algorithm_for_Image_Segmentation_and_Object_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kumar_GridShift_A_Faster_Mode-Seeking_Algorithm_for_Image_Segmentation_and_Object_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kumar_GridShift_A_Faster_CVPR_2022_supplemental.pdf)
951. Robust Region Feature Synthesizer for Zero-Shot Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Robust_Region_Feature_Synthesizer_for_Zero-Shot_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Robust_Region_Feature_Synthesizer_for_Zero-Shot_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Robust_Region_Feature_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.00103)
952. HSC4D- Human-Centered 4D Scene Capture in Large-Scale Indoor-Outdoor Space Using Wearable IMUs and LiDAR | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dai_HSC4D_Human-Centered_4D_Scene_Capture_in_Large-Scale_Indoor-Outdoor_Space_Using_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_HSC4D_Human-Centered_4D_Scene_Capture_in_Large-Scale_Indoor-Outdoor_Space_Using_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dai_HSC4D_Human-Centered_4D_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.09215)
953. M3L- Language-Based Video Editing via Multi-Modal Multi-Level Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fu_M3L_Language-Based_Video_Editing_via_Multi-Modal_Multi-Level_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_M3L_Language-Based_Video_Editing_via_Multi-Modal_Multi-Level_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fu_M3L_Language-Based_Video_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.01122)
954. It's All in the Teacher- Zero-Shot Quantization Brought Closer to the Teacher | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Choi_Its_All_in_the_Teacher_Zero-Shot_Quantization_Brought_Closer_to_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Choi_Its_All_in_the_Teacher_Zero-Shot_Quantization_Brought_Closer_to_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Choi_Its_All_in_CVPR_2022_supplemental.zip)
955. A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_A_Text_Attention_Network_for_Spatial_Deformation_Robust_Scene_Text_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_A_Text_Attention_Network_for_Spatial_Deformation_Robust_Scene_Text_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_A_Text_Attention_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09388)
956. OSOP- A Multi-Stage One Shot Object Pose Estimation Framework | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shugurov_OSOP_A_Multi-Stage_One_Shot_Object_Pose_Estimation_Framework_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shugurov_OSOP_A_Multi-Stage_One_Shot_Object_Pose_Estimation_Framework_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shugurov_OSOP_A_Multi-Stage_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15533)
957. BodyGAN- General-Purpose Controllable Neural Human Body Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_BodyGAN_General-Purpose_Controllable_Neural_Human_Body_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_BodyGAN_General-Purpose_Controllable_Neural_Human_Body_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_BodyGAN_General-Purpose_Controllable_CVPR_2022_supplemental.pdf)
958. Robust Fine-Tuning of Zero-Shot Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wortsman_Robust_Fine-Tuning_of_Zero-Shot_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wortsman_Robust_Fine-Tuning_of_Zero-Shot_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wortsman_Robust_Fine-Tuning_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2109.01903)
959. Multi-Granularity Alignment Domain Adaptation for Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Multi-Granularity_Alignment_Domain_Adaptation_for_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Multi-Granularity_Alignment_Domain_Adaptation_for_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Multi-Granularity_Alignment_Domain_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16897)
960. Robust Federated Learning With Noisy and Heterogeneous Clients | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fang_Robust_Federated_Learning_With_Noisy_and_Heterogeneous_Clients_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_Robust_Federated_Learning_With_Noisy_and_Heterogeneous_Clients_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fang_Robust_Federated_Learning_CVPR_2022_supplemental.pdf)
961. Enabling Equivariance for Arbitrary Lie Groups | [link](https://openaccess.thecvf.com/content/CVPR2022/html/MacDonald_Enabling_Equivariance_for_Arbitrary_Lie_Groups_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/MacDonald_Enabling_Equivariance_for_Arbitrary_Lie_Groups_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/MacDonald_Enabling_Equivariance_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.08251)
962. Unbiased Teacher v2- Semi-Supervised Object Detection for Anchor-Free and Anchor-Based Detectors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Unbiased_Teacher_v2_Semi-Supervised_Object_Detection_for_Anchor-Free_and_Anchor-Based_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Unbiased_Teacher_v2_Semi-Supervised_Object_Detection_for_Anchor-Free_and_Anchor-Based_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Unbiased_Teacher_v2_CVPR_2022_supplemental.pdf)
963. Volumetric Bundle Adjustment for Online Photorealistic Scene Capture | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Clark_Volumetric_Bundle_Adjustment_for_Online_Photorealistic_Scene_Capture_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Clark_Volumetric_Bundle_Adjustment_for_Online_Photorealistic_Scene_Capture_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Clark_Volumetric_Bundle_Adjustment_CVPR_2022_supplemental.pdf)
964. RegNeRF- Regularizing Neural Radiance Fields for View Synthesis From Sparse Inputs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Niemeyer_RegNeRF_Regularizing_Neural_Radiance_Fields_for_View_Synthesis_From_Sparse_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Niemeyer_RegNeRF_Regularizing_Neural_Radiance_Fields_for_View_Synthesis_From_Sparse_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.00724)
965. Ranking-Based Siamese Visual Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Ranking-Based_Siamese_Visual_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Ranking-Based_Siamese_Visual_Tracking_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.11761)
966. SEEG- Semantic Energized Co-Speech Gesture Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_SEEG_Semantic_Energized_Co-Speech_Gesture_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_SEEG_Semantic_Energized_Co-Speech_Gesture_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liang_SEEG_Semantic_Energized_CVPR_2022_supplemental.pdf)
967. Compound Domain Generalization via Meta-Knowledge Encoding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Compound_Domain_Generalization_via_Meta-Knowledge_Encoding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Compound_Domain_Generalization_via_Meta-Knowledge_Encoding_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.13006)
968. Hyperspherical Consistency Regularization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tan_Hyperspherical_Consistency_Regularization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tan_Hyperspherical_Consistency_Regularization_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2206.00845)
969. Probabilistic Warp Consistency for Weakly-Supervised Semantic Correspondences | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Truong_Probabilistic_Warp_Consistency_for_Weakly-Supervised_Semantic_Correspondences_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Truong_Probabilistic_Warp_Consistency_for_Weakly-Supervised_Semantic_Correspondences_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Truong_Probabilistic_Warp_Consistency_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04279)
970. Inertia-Guided Flow Completion and Style Fusion for Video Inpainting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Inertia-Guided_Flow_Completion_and_Style_Fusion_for_Video_Inpainting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Inertia-Guided_Flow_Completion_and_Style_Fusion_for_Video_Inpainting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Inertia-Guided_Flow_Completion_CVPR_2022_supplemental.pdf)
971. Long-Tailed Visual Recognition via Gaussian Clouded Logit Adjustment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Long-Tailed_Visual_Recognition_via_Gaussian_Clouded_Logit_Adjustment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Long-Tailed_Visual_Recognition_via_Gaussian_Clouded_Logit_Adjustment_CVPR_2022_paper.pdf)
972. Point Density-Aware Voxels for LiDAR 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Point_Density-Aware_Voxels_for_LiDAR_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Point_Density-Aware_Voxels_for_LiDAR_3D_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_Point_Density-Aware_Voxels_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05662)
973. A Simple Episodic Linear Probe Improves Visual Recognition in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_A_Simple_Episodic_Linear_Probe_Improves_Visual_Recognition_in_the_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_A_Simple_Episodic_Linear_Probe_Improves_Visual_Recognition_in_the_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liang_A_Simple_Episodic_CVPR_2022_supplemental.pdf)
974. Matching Feature Sets for Few-Shot Image Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Afrasiyabi_Matching_Feature_Sets_for_Few-Shot_Image_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Afrasiyabi_Matching_Feature_Sets_for_Few-Shot_Image_Classification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Afrasiyabi_Matching_Feature_Sets_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00949)
975. Deep Spectral Methods- A Surprisingly Strong Baseline for Unsupervised Semantic Segmentation and Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Melas-Kyriazi_Deep_Spectral_Methods_A_Surprisingly_Strong_Baseline_for_Unsupervised_Semantic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Melas-Kyriazi_Deep_Spectral_Methods_A_Surprisingly_Strong_Baseline_for_Unsupervised_Semantic_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Melas-Kyriazi_Deep_Spectral_Methods_CVPR_2022_supplemental.pdf)
976. XMP-Font- Self-Supervised Cross-Modality Pre-Training for Few-Shot Font Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_XMP-Font_Self-Supervised_Cross-Modality_Pre-Training_for_Few-Shot_Font_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_XMP-Font_Self-Supervised_Cross-Modality_Pre-Training_for_Few-Shot_Font_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_XMP-Font_Self-Supervised_Cross-Modality_CVPR_2022_supplemental.pdf)
977. Gradient-SDF- A Semi-Implicit Surface Representation for 3D Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sommer_Gradient-SDF_A_Semi-Implicit_Surface_Representation_for_3D_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sommer_Gradient-SDF_A_Semi-Implicit_Surface_Representation_for_3D_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sommer_Gradient-SDF_A_Semi-Implicit_CVPR_2022_supplemental.pdf)
978. Localization Distillation for Dense Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Localization_Distillation_for_Dense_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Localization_Distillation_for_Dense_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_Localization_Distillation_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2102.12252)
979. Beyond 3D Siamese Tracking- A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Beyond_3D_Siamese_Tracking_A_Motion-Centric_Paradigm_for_3D_Single_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Beyond_3D_Siamese_Tracking_A_Motion-Centric_Paradigm_for_3D_Single_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_Beyond_3D_Siamese_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01730)
980. Non-Probability Sampling Network for Stochastic Human Trajectory Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bae_Non-Probability_Sampling_Network_for_Stochastic_Human_Trajectory_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bae_Non-Probability_Sampling_Network_for_Stochastic_Human_Trajectory_Prediction_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.13471)
981. ResSFL- A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_ResSFL_A_Resistance_Transfer_Framework_for_Defending_Model_Inversion_Attack_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_ResSFL_A_Resistance_Transfer_Framework_for_Defending_Model_Inversion_Attack_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_ResSFL_A_Resistance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.04007)
982. Learning of Global Objective for Network Flow in Multi-Object Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Learning_of_Global_Objective_for_Network_Flow_in_Multi-Object_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_of_Global_Objective_for_Network_Flow_in_Multi-Object_Tracking_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16210)
983. RAMA- A Rapid Multicut Algorithm on GPU | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Abbas_RAMA_A_Rapid_Multicut_Algorithm_on_GPU_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Abbas_RAMA_A_Rapid_Multicut_Algorithm_on_GPU_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Abbas_RAMA_A_Rapid_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2109.01838)
984. DC-SSL- Addressing Mismatched Class Distribution in Semi-Supervised Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_DC-SSL_Addressing_Mismatched_Class_Distribution_in_Semi-Supervised_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_DC-SSL_Addressing_Mismatched_Class_Distribution_in_Semi-Supervised_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_DC-SSL_Addressing_Mismatched_CVPR_2022_supplemental.pdf)
985. Transferability Metrics for Selecting Source Model Ensembles | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Agostinelli_Transferability_Metrics_for_Selecting_Source_Model_Ensembles_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Agostinelli_Transferability_Metrics_for_Selecting_Source_Model_Ensembles_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Agostinelli_Transferability_Metrics_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13011)
986. DAFormer- Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hoyer_DAFormer_Improving_Network_Architectures_and_Training_Strategies_for_Domain-Adaptive_Semantic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hoyer_DAFormer_Improving_Network_Architectures_and_Training_Strategies_for_Domain-Adaptive_Semantic_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hoyer_DAFormer_Improving_Network_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14887)
987. Joint Distribution Matters- Deep Brownian Distance Covariance for Few-Shot Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Joint_Distribution_Matters_Deep_Brownian_Distance_Covariance_for_Few-Shot_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Joint_Distribution_Matters_Deep_Brownian_Distance_Covariance_for_Few-Shot_Classification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xie_Joint_Distribution_Matters_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04567)
988. MetaPose- Fast 3D Pose From Multiple Views Without 3D Supervision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Usman_MetaPose_Fast_3D_Pose_From_Multiple_Views_Without_3D_Supervision_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Usman_MetaPose_Fast_3D_Pose_From_Multiple_Views_Without_3D_Supervision_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Usman_MetaPose_Fast_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2108.04869)
989. The Devil Is in the Pose- Ambiguity-Free 3D Rotation-Invariant Learning via Pose-Aware Convolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_The_Devil_Is_in_the_Pose_Ambiguity-Free_3D_Rotation-Invariant_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_The_Devil_Is_in_the_Pose_Ambiguity-Free_3D_Rotation-Invariant_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_The_Devil_Is_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.15210)
990. Visible-Thermal UAV Tracking- A Large-Scale Benchmark and New Baseline | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Visible-Thermal_UAV_Tracking_A_Large-Scale_Benchmark_and_New_Baseline_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Visible-Thermal_UAV_Tracking_A_Large-Scale_Benchmark_and_New_Baseline_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Visible-Thermal_UAV_Tracking_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04120)
991. Neural RGB-D Surface Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Azinovic_Neural_RGB-D_Surface_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Azinovic_Neural_RGB-D_Surface_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Azinovic_Neural_RGB-D_Surface_CVPR_2022_supplemental.pdf)
992. Cross-Domain Adaptive Teacher for Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Cross-Domain_Adaptive_Teacher_for_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Cross-Domain_Adaptive_Teacher_for_Object_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.13216)
993. Exposure Normalization and Compensation for Multiple-Exposure Correction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Exposure_Normalization_and_Compensation_for_Multiple-Exposure_Correction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Exposure_Normalization_and_Compensation_for_Multiple-Exposure_Correction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Exposure_Normalization_and_CVPR_2022_supplemental.pdf)
994. Leveraging Adversarial Examples To Quantify Membership Information Leakage | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Del_Grosso_Leveraging_Adversarial_Examples_To_Quantify_Membership_Information_Leakage_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Del_Grosso_Leveraging_Adversarial_Examples_To_Quantify_Membership_Information_Leakage_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Del_Grosso_Leveraging_Adversarial_Examples_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09566)
995. Point-NeRF- Point-Based Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Point-NeRF_Point-Based_Neural_Radiance_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Point-NeRF_Point-Based_Neural_Radiance_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Point-NeRF_Point-Based_Neural_CVPR_2022_supplemental.pdf)
996. FedCor- Correlation-Based Active Client Selection Strategy for Heterogeneous Federated Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_FedCor_Correlation-Based_Active_Client_Selection_Strategy_for_Heterogeneous_Federated_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_FedCor_Correlation-Based_Active_Client_Selection_Strategy_for_Heterogeneous_Federated_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_FedCor_Correlation-Based_Active_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2103.13822)
997. HumanNeRF- Efficiently Generated Human Radiance Field From Sparse Inputs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_HumanNeRF_Efficiently_Generated_Human_Radiance_Field_From_Sparse_Inputs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_HumanNeRF_Efficiently_Generated_Human_Radiance_Field_From_Sparse_Inputs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_HumanNeRF_Efficiently_Generated_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02789)
998. Cascade Transformers for End-to-End Person Search | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Cascade_Transformers_for_End-to-End_Person_Search_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Cascade_Transformers_for_End-to-End_Person_Search_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.09642)
999. LSVC- A Learning-Based Stereo Video Compression Framework | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_LSVC_A_Learning-Based_Stereo_Video_Compression_Framework_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_LSVC_A_Learning-Based_Stereo_Video_Compression_Framework_CVPR_2022_paper.pdf)
1000. InsetGAN for Full-Body Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fruhstuck_InsetGAN_for_Full-Body_Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fruhstuck_InsetGAN_for_Full-Body_Image_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fruhstuck_InsetGAN_for_Full-Body_CVPR_2022_supplemental.pdf)
1001. Event-Aided Direct Sparse Odometry | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hidalgo-Carrio_Event-Aided_Direct_Sparse_Odometry_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hidalgo-Carrio_Event-Aided_Direct_Sparse_Odometry_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hidalgo-Carrio_Event-Aided_Direct_Sparse_CVPR_2022_supplemental.pdf)
1002. MPViT- Multi-Path Vision Transformer for Dense Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_MPViT_Multi-Path_Vision_Transformer_for_Dense_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_MPViT_Multi-Path_Vision_Transformer_for_Dense_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_MPViT_Multi-Path_Vision_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.11010)
1003. Neural 3D Video Synthesis From Multi-View Video | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Neural_3D_Video_Synthesis_From_Multi-View_Video_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Neural_3D_Video_Synthesis_From_Multi-View_Video_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Neural_3D_Video_CVPR_2022_supplemental.pdf)
1004. Learning What Not To Segment- A New Perspective on Few-Shot Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lang_Learning_What_Not_To_Segment_A_New_Perspective_on_Few-Shot_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lang_Learning_What_Not_To_Segment_A_New_Perspective_on_Few-Shot_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lang_Learning_What_Not_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.07615)
1005. Robust Invertible Image Steganography | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Robust_Invertible_Image_Steganography_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Robust_Invertible_Image_Steganography_CVPR_2022_paper.pdf)
1006. Entropy-Based Active Learning for Object Detection With Progressive Diversity Constraint | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Entropy-Based_Active_Learning_for_Object_Detection_With_Progressive_Diversity_Constraint_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Entropy-Based_Active_Learning_for_Object_Detection_With_Progressive_Diversity_Constraint_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Entropy-Based_Active_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07965)
1007. Egocentric Deep Multi-Channel Audio-Visual Active Speaker Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Egocentric_Deep_Multi-Channel_Audio-Visual_Active_Speaker_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Egocentric_Deep_Multi-Channel_Audio-Visual_Active_Speaker_Localization_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2201.01928)
1008. Structure-Aware Flow Generation for Human Body Reshaping | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Structure-Aware_Flow_Generation_for_Human_Body_Reshaping_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Structure-Aware_Flow_Generation_for_Human_Body_Reshaping_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ren_Structure-Aware_Flow_Generation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04670)
1009. Practical Learned Lossless JPEG Recompression With Multi-Level Cross-Channel Entropy Model in the DCT Domain | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Practical_Learned_Lossless_JPEG_Recompression_With_Multi-Level_Cross-Channel_Entropy_Model_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Practical_Learned_Lossless_JPEG_Recompression_With_Multi-Level_Cross-Channel_Entropy_Model_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_Practical_Learned_Lossless_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16357)
1010. Leveraging Equivariant Features for Absolute Pose Regression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Musallam_Leveraging_Equivariant_Features_for_Absolute_Pose_Regression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Musallam_Leveraging_Equivariant_Features_for_Absolute_Pose_Regression_CVPR_2022_paper.pdf)
1011. Deep Visual Geo-Localization Benchmark | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Berton_Deep_Visual_Geo-Localization_Benchmark_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Berton_Deep_Visual_Geo-Localization_Benchmark_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Berton_Deep_Visual_Geo-Localization_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03444)
1012. Leveraging Self-Supervision for Cross-Domain Crowd Counting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Leveraging_Self-Supervision_for_Cross-Domain_Crowd_Counting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Leveraging_Self-Supervision_for_Cross-Domain_Crowd_Counting_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2103.16291)
1013. PlaneMVS- 3D Plane Reconstruction From Multi-View Stereo | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_PlaneMVS_3D_Plane_Reconstruction_From_Multi-View_Stereo_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_PlaneMVS_3D_Plane_Reconstruction_From_Multi-View_Stereo_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_PlaneMVS_3D_Plane_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12082)
1014. MVS2D- Efficient Multi-View Stereo via Attention-Driven 2D Convolutions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_MVS2D_Efficient_Multi-View_Stereo_via_Attention-Driven_2D_Convolutions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_MVS2D_Efficient_Multi-View_Stereo_via_Attention-Driven_2D_Convolutions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_MVS2D_Efficient_Multi-View_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.13325)
1015. Fine-Tuning Global Model via Data-Free Knowledge Distillation for Non-IID Federated Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Fine-Tuning_Global_Model_via_Data-Free_Knowledge_Distillation_for_Non-IID_Federated_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Fine-Tuning_Global_Model_via_Data-Free_Knowledge_Distillation_for_Non-IID_Federated_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Fine-Tuning_Global_Model_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09249)
1016. Deep 3D-to-2D Watermarking- Embedding Messages in 3D Meshes and Extracting Them From 2D Renderings | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yoo_Deep_3D-to-2D_Watermarking_Embedding_Messages_in_3D_Meshes_and_Extracting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yoo_Deep_3D-to-2D_Watermarking_Embedding_Messages_in_3D_Meshes_and_Extracting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yoo_Deep_3D-to-2D_Watermarking_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2104.13450)
1017. AirObject- A Temporally Evolving Graph Embedding for Object Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Keetha_AirObject_A_Temporally_Evolving_Graph_Embedding_for_Object_Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Keetha_AirObject_A_Temporally_Evolving_Graph_Embedding_for_Object_Identification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Keetha_AirObject_A_Temporally_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2111.15150)
1018. Protecting Celebrities From DeepFake With Identity Consistency Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Protecting_Celebrities_From_DeepFake_With_Identity_Consistency_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Protecting_Celebrities_From_DeepFake_With_Identity_Consistency_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_Protecting_Celebrities_From_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01318)
1019. KG-SP- Knowledge Guided Simple Primitives for Open World Compositional Zero-Shot Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Karthik_KG-SP_Knowledge_Guided_Simple_Primitives_for_Open_World_Compositional_Zero-Shot_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Karthik_KG-SP_Knowledge_Guided_Simple_Primitives_for_Open_World_Compositional_Zero-Shot_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Karthik_KG-SP_Knowledge_Guided_CVPR_2022_supplemental.pdf)
1020. CD2-pFed- Cyclic Distillation-Guided Channel Decoupling for Model Personalization in Federated Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shen_CD2-pFed_Cyclic_Distillation-Guided_Channel_Decoupling_for_Model_Personalization_in_Federated_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_CD2-pFed_Cyclic_Distillation-Guided_Channel_Decoupling_for_Model_Personalization_in_Federated_CVPR_2022_paper.pdf)
1021. Style-ERD- Responsive and Coherent Online Motion Style Transfer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tao_Style-ERD_Responsive_and_Coherent_Online_Motion_Style_Transfer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Style-ERD_Responsive_and_Coherent_Online_Motion_Style_Transfer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tao_Style-ERD_Responsive_and_CVPR_2022_supplemental.pdf)
1022. Stratified Transformer for 3D Point Cloud Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lai_Stratified_Transformer_for_3D_Point_Cloud_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lai_Stratified_Transformer_for_3D_Point_Cloud_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lai_Stratified_Transformer_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14508)
1023. Task Decoupled Framework for Reference-Based Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Task_Decoupled_Framework_for_Reference-Based_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Task_Decoupled_Framework_for_Reference-Based_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Task_Decoupled_Framework_CVPR_2022_supplemental.pdf)
1024. Temporal Complementarity-Guided Reinforcement Learning for Image-to-Video Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Temporal_Complementarity-Guided_Reinforcement_Learning_for_Image-to-Video_Person_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Temporal_Complementarity-Guided_Reinforcement_Learning_for_Image-to-Video_Person_Re-Identification_CVPR_2022_paper.pdf)
1025. Fairness-Aware Adversarial Perturbation Towards Bias Mitigation for Deployed Deep Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Fairness-Aware_Adversarial_Perturbation_Towards_Bias_Mitigation_for_Deployed_Deep_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Fairness-Aware_Adversarial_Perturbation_Towards_Bias_Mitigation_for_Deployed_Deep_Models_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.01584)
1026. Stochastic Backpropagation- A Memory Efficient Strategy for Training Video Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Stochastic_Backpropagation_A_Memory_Efficient_Strategy_for_Training_Video_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Stochastic_Backpropagation_A_Memory_Efficient_Strategy_for_Training_Video_Models_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16755)
1027. Commonality in Natural Images Rescues GANs- Pretraining GANs With Generic and Privacy-Free Synthetic Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Baek_Commonality_in_Natural_Images_Rescues_GANs_Pretraining_GANs_With_Generic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Baek_Commonality_in_Natural_Images_Rescues_GANs_Pretraining_GANs_With_Generic_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Baek_Commonality_in_Natural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04950)
1028. GASP, a Generalized Framework for Agglomerative Clustering of Signed Graphs and Its Application to Instance Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bailoni_GASP_a_Generalized_Framework_for_Agglomerative_Clustering_of_Signed_Graphs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bailoni_GASP_a_Generalized_Framework_for_Agglomerative_Clustering_of_Signed_Graphs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bailoni_GASP_a_Generalized_CVPR_2022_supplemental.pdf)
1029. RIM-Net- Recursive Implicit Fields for Unsupervised Learning of Hierarchical Shape Structures | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Niu_RIM-Net_Recursive_Implicit_Fields_for_Unsupervised_Learning_of_Hierarchical_Shape_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Niu_RIM-Net_Recursive_Implicit_Fields_for_Unsupervised_Learning_of_Hierarchical_Shape_CVPR_2022_paper.pdf)
1030. Learning To Affiliate- Mutual Centralized Learning for Few-Shot Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_To_Affiliate_Mutual_Centralized_Learning_for_Few-Shot_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_To_Affiliate_Mutual_Centralized_Learning_for_Few-Shot_Classification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Learning_To_Affiliate_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.05517)
1031. CAPRI-Net- Learning Compact CAD Shapes With Adaptive Primitive Assembly | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_CAPRI-Net_Learning_Compact_CAD_Shapes_With_Adaptive_Primitive_Assembly_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_CAPRI-Net_Learning_Compact_CAD_Shapes_With_Adaptive_Primitive_Assembly_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_CAPRI-Net_Learning_Compact_CVPR_2022_supplemental.pdf)
1032. Bridging the Gap Between Classification and Localization for Weakly Supervised Object Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Bridging_the_Gap_Between_Classification_and_Localization_for_Weakly_Supervised_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Bridging_the_Gap_Between_Classification_and_Localization_for_Weakly_Supervised_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Bridging_the_Gap_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00220)
1033. NICE-SLAM- Neural Implicit Scalable Encoding for SLAM | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_NICE-SLAM_Neural_Implicit_Scalable_Encoding_for_SLAM_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_NICE-SLAM_Neural_Implicit_Scalable_Encoding_for_SLAM_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_NICE-SLAM_Neural_Implicit_CVPR_2022_supplemental.pdf)
1034. Cross-Modal Map Learning for Vision and Language Navigation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Georgakis_Cross-Modal_Map_Learning_for_Vision_and_Language_Navigation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Georgakis_Cross-Modal_Map_Learning_for_Vision_and_Language_Navigation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Georgakis_Cross-Modal_Map_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05137)
1035. Incremental Transformer Structure Enhanced Image Inpainting With Masking Positional Encoding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Incremental_Transformer_Structure_Enhanced_Image_Inpainting_With_Masking_Positional_Encoding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Incremental_Transformer_Structure_Enhanced_Image_Inpainting_With_Masking_Positional_Encoding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_Incremental_Transformer_Structure_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.00867)
1036. CRIS- CLIP-Driven Referring Image Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_CRIS_CLIP-Driven_Referring_Image_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_CRIS_CLIP-Driven_Referring_Image_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.15174)
1037. Infrared Invisible Clothing- Hiding From Infrared Detectors at Multiple Angles in Real World | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Infrared_Invisible_Clothing_Hiding_From_Infrared_Detectors_at_Multiple_Angles_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Infrared_Invisible_Clothing_Hiding_From_Infrared_Detectors_at_Multiple_Angles_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Infrared_Invisible_Clothing_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2205.05909)
1038. Distribution-Aware Single-Stage Models for Multi-Person 3D Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Distribution-Aware_Single-Stage_Models_for_Multi-Person_3D_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Distribution-Aware_Single-Stage_Models_for_Multi-Person_3D_Pose_Estimation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.07697)
1039. Searching the Deployable Convolution Neural Networks for GPUs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Searching_the_Deployable_Convolution_Neural_Networks_for_GPUs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Searching_the_Deployable_Convolution_Neural_Networks_for_GPUs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Searching_the_Deployable_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.00841)
1040. DeepFake Disrupter- The Detector of DeepFake Is My Friend | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_DeepFake_Disrupter_The_Detector_of_DeepFake_Is_My_Friend_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_DeepFake_Disrupter_The_Detector_of_DeepFake_Is_My_Friend_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_DeepFake_Disrupter_The_CVPR_2022_supplemental.pdf)
1041. Long-Short Temporal Contrastive Learning of Video Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Long-Short_Temporal_Contrastive_Learning_of_Video_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Long-Short_Temporal_Contrastive_Learning_of_Video_Transformers_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2106.09212)
1042. Drop the GAN- In Defense of Patches Nearest Neighbors As Single Image Generative Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Granot_Drop_the_GAN_In_Defense_of_Patches_Nearest_Neighbors_As_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Granot_Drop_the_GAN_In_Defense_of_Patches_Nearest_Neighbors_As_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2103.15545)
1043. SIOD- Single Instance Annotated per Category per Image for Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_SIOD_Single_Instance_Annotated_per_Category_per_Image_for_Object_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_SIOD_Single_Instance_Annotated_per_Category_per_Image_for_Object_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_SIOD_Single_Instance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15353)
1044. Online Learning of Reusable Abstract Models for Object Goal Navigation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Campari_Online_Learning_of_Reusable_Abstract_Models_for_Object_Goal_Navigation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Campari_Online_Learning_of_Reusable_Abstract_Models_for_Object_Goal_Navigation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.02583)
1045. SimMatch- Semi-Supervised Learning With Similarity Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_SimMatch_Semi-Supervised_Learning_With_Similarity_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_SimMatch_Semi-Supervised_Learning_With_Similarity_Matching_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.06915)
1046. OrphicX- A Causality-Inspired Latent Variable Model for Interpreting Graph Neural Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_OrphicX_A_Causality-Inspired_Latent_Variable_Model_for_Interpreting_Graph_Neural_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_OrphicX_A_Causality-Inspired_Latent_Variable_Model_for_Interpreting_Graph_Neural_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_OrphicX_A_Causality-Inspired_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15209)
1047. EfficientNeRF  Efficient Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_EfficientNeRF__Efficient_Neural_Radiance_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_EfficientNeRF__Efficient_Neural_Radiance_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_EfficientNeRF__Efficient_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2206.00878)
1048. Quantifying Societal Bias Amplification in Image Captioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hirota_Quantifying_Societal_Bias_Amplification_in_Image_Captioning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hirota_Quantifying_Societal_Bias_Amplification_in_Image_Captioning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hirota_Quantifying_Societal_Bias_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15395)
1049. StyleSwin- Transformer-Based GAN for High-Resolution Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_StyleSwin_Transformer-Based_GAN_for_High-Resolution_Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_StyleSwin_Transformer-Based_GAN_for_High-Resolution_Image_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_StyleSwin_Transformer-Based_GAN_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.10762)
1050. Reinforced Structured State-Evolution for Vision-Language Navigation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Reinforced_Structured_State-Evolution_for_Vision-Language_Navigation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Reinforced_Structured_State-Evolution_for_Vision-Language_Navigation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.09280)
1051. E2V-SDE- From Asynchronous Events to Fast and Continuous Video Reconstruction via Neural Stochastic Differential Equations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_E2V-SDE_From_Asynchronous_Events_to_Fast_and_Continuous_Video_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_E2V-SDE_From_Asynchronous_Events_to_Fast_and_Continuous_Video_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_E2V-SDE_From_Asynchronous_CVPR_2022_supplemental.pdf)
1052. CoSSL- Co-Learning of Representation and Classifier for Imbalanced Semi-Supervised Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_CoSSL_Co-Learning_of_Representation_and_Classifier_for_Imbalanced_Semi-Supervised_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_CoSSL_Co-Learning_of_Representation_and_Classifier_for_Imbalanced_Semi-Supervised_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fan_CoSSL_Co-Learning_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.04564)
1053. Discovering Objects That Can Move | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bao_Discovering_Objects_That_Can_Move_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_Discovering_Objects_That_Can_Move_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bao_Discovering_Objects_That_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10159)
1054. Self-Supervised Learning of Object Parts for Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ziegler_Self-Supervised_Learning_of_Object_Parts_for_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ziegler_Self-Supervised_Learning_of_Object_Parts_for_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ziegler_Self-Supervised_Learning_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.13101)
1055. Swin Transformer V2- Scaling Up Capacity and Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Swin_Transformer_V2_Scaling_Up_Capacity_and_Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Swin_Transformer_V2_Scaling_Up_Capacity_and_Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Swin_Transformer_V2_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.09883)
1056. DEFEAT- Deep Hidden Feature Backdoor Attacks by Imperceptible Perturbation and Latent Representation Constraints | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_DEFEAT_Deep_Hidden_Feature_Backdoor_Attacks_by_Imperceptible_Perturbation_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_DEFEAT_Deep_Hidden_Feature_Backdoor_Attacks_by_Imperceptible_Perturbation_and_CVPR_2022_paper.pdf)
1057. Learning To Refactor Action and Co-Occurrence Features for Temporal Action Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xia_Learning_To_Refactor_Action_and_Co-Occurrence_Features_for_Temporal_Action_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Learning_To_Refactor_Action_and_Co-Occurrence_Features_for_Temporal_Action_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xia_Learning_To_Refactor_CVPR_2022_supplemental.pdf)
1058. DN-DETR- Accelerate DETR Training by Introducing Query DeNoising | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_DN-DETR_Accelerate_DETR_Training_by_Introducing_Query_DeNoising_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_DN-DETR_Accelerate_DETR_Training_by_Introducing_Query_DeNoising_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_DN-DETR_Accelerate_DETR_CVPR_2022_supplemental.pdf)
1059. RAGO- Recurrent Graph Optimizer for Multiple Rotation Averaging | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_RAGO_Recurrent_Graph_Optimizer_for_Multiple_Rotation_Averaging_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_RAGO_Recurrent_Graph_Optimizer_for_Multiple_Rotation_Averaging_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_RAGO_Recurrent_Graph_CVPR_2022_supplemental.pdf)
1060. Arch-Graph- Acyclic Architecture Relation Predictor for Task-Transferable Neural Architecture Search | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Arch-Graph_Acyclic_Architecture_Relation_Predictor_for_Task-Transferable_Neural_Architecture_Search_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Arch-Graph_Acyclic_Architecture_Relation_Predictor_for_Task-Transferable_Neural_Architecture_Search_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Arch-Graph_Acyclic_Architecture_CVPR_2022_supplemental.pdf)
1061. On Aliased Resizing and Surprising Subtleties in GAN Evaluation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Parmar_On_Aliased_Resizing_and_Surprising_Subtleties_in_GAN_Evaluation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Parmar_On_Aliased_Resizing_and_Surprising_Subtleties_in_GAN_Evaluation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2104.11222)
1062. Virtual Elastic Objects | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Virtual_Elastic_Objects_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Virtual_Elastic_Objects_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Virtual_Elastic_Objects_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.04623)
1063. DiSparse- Disentangled Sparsification for Multitask Model Compression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_DiSparse_Disentangled_Sparsification_for_Multitask_Model_Compression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_DiSparse_Disentangled_Sparsification_for_Multitask_Model_Compression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sun_DiSparse_Disentangled_Sparsification_CVPR_2022_supplemental.pdf)
1064. Towards Efficient and Scalable Sharpness-Aware Minimization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Towards_Efficient_and_Scalable_Sharpness-Aware_Minimization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Efficient_and_Scalable_Sharpness-Aware_Minimization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Towards_Efficient_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02714)
1065. Few-Shot Head Swapping in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shu_Few-Shot_Head_Swapping_in_the_Wild_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shu_Few-Shot_Head_Swapping_in_the_Wild_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shu_Few-Shot_Head_Swapping_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.13100)
1066. ICON- Implicit Clothed Humans Obtained From Normals | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xiu_ICON_Implicit_Clothed_Humans_Obtained_From_Normals_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xiu_ICON_Implicit_Clothed_Humans_Obtained_From_Normals_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xiu_ICON_Implicit_Clothed_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.09127)
1067. Shape From Polarization for Complex Scenes in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lei_Shape_From_Polarization_for_Complex_Scenes_in_the_Wild_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_Shape_From_Polarization_for_Complex_Scenes_in_the_Wild_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.11377)
1068. Glass Segmentation Using Intensity and Spectral Polarization Cues | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mei_Glass_Segmentation_Using_Intensity_and_Spectral_Polarization_Cues_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mei_Glass_Segmentation_Using_Intensity_and_Spectral_Polarization_Cues_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mei_Glass_Segmentation_Using_CVPR_2022_supplemental.pdf)
1069. Few Shot Generative Model Adaption via Relaxed Spatial Structural Alignment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xiao_Few_Shot_Generative_Model_Adaption_via_Relaxed_Spatial_Structural_Alignment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xiao_Few_Shot_Generative_Model_Adaption_via_Relaxed_Spatial_Structural_Alignment_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.04121)
1070. Pyramid Grafting Network for One-Stage High Resolution Saliency Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Pyramid_Grafting_Network_for_One-Stage_High_Resolution_Saliency_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Pyramid_Grafting_Network_for_One-Stage_High_Resolution_Saliency_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xie_Pyramid_Grafting_Network_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.05041)
1071. Enhancing Adversarial Training With Second-Order Statistics of Weights | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jin_Enhancing_Adversarial_Training_With_Second-Order_Statistics_of_Weights_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Enhancing_Adversarial_Training_With_Second-Order_Statistics_of_Weights_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jin_Enhancing_Adversarial_Training_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06020)
1072. Dual Temperature Helps Contrastive Learning Without Many Negative Samples- Towards Understanding and Simplifying MoCo | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Dual_Temperature_Helps_Contrastive_Learning_Without_Many_Negative_Samples_Towards_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Dual_Temperature_Helps_Contrastive_Learning_Without_Many_Negative_Samples_Towards_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Dual_Temperature_Helps_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.17248)
1073. UniCoRN- A Unified Conditional Image Repainting Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_UniCoRN_A_Unified_Conditional_Image_Repainting_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_UniCoRN_A_Unified_Conditional_Image_Repainting_Network_CVPR_2022_paper.pdf)
1074. Forecasting Characteristic 3D Poses of Human Actions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Diller_Forecasting_Characteristic_3D_Poses_of_Human_Actions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Diller_Forecasting_Characteristic_3D_Poses_of_Human_Actions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Diller_Forecasting_Characteristic_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2011.15079)
1075. Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ristea_Self-Supervised_Predictive_Convolutional_Attentive_Block_for_Anomaly_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ristea_Self-Supervised_Predictive_Convolutional_Attentive_Block_for_Anomaly_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ristea_Self-Supervised_Predictive_Convolutional_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.09099)
1076. Robust Structured Declarative Classifiers for 3D Point Clouds- Defending Adversarial Attacks With Implicit Gradients | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Robust_Structured_Declarative_Classifiers_for_3D_Point_Clouds_Defending_Adversarial_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Robust_Structured_Declarative_Classifiers_for_3D_Point_Clouds_Defending_Adversarial_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.15245)
1077. Improving the Transferability of Targeted Adversarial Examples Through Object-Based Diverse Input | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Byun_Improving_the_Transferability_of_Targeted_Adversarial_Examples_Through_Object-Based_Diverse_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Byun_Improving_the_Transferability_of_Targeted_Adversarial_Examples_Through_Object-Based_Diverse_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Byun_Improving_the_Transferability_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09123)
1078. Splicing ViT Features for Semantic Appearance Transfer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tumanyan_Splicing_ViT_Features_for_Semantic_Appearance_Transfer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tumanyan_Splicing_ViT_Features_for_Semantic_Appearance_Transfer_CVPR_2022_paper.pdf)
1079. Putting People in Their Place- Monocular Regression of 3D People in Depth | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Putting_People_in_Their_Place_Monocular_Regression_of_3D_People_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Putting_People_in_Their_Place_Monocular_Regression_of_3D_People_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sun_Putting_People_in_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.08274)
1080. Neural Texture Extraction and Distribution for Controllable Person Image Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Neural_Texture_Extraction_and_Distribution_for_Controllable_Person_Image_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Neural_Texture_Extraction_and_Distribution_for_Controllable_Person_Image_Synthesis_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.06160)
1081. Dual-Path Image Inpainting With Auxiliary GAN Inversion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Dual-Path_Image_Inpainting_With_Auxiliary_GAN_Inversion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Dual-Path_Image_Inpainting_With_Auxiliary_GAN_Inversion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Dual-Path_Image_Inpainting_CVPR_2022_supplemental.pdf)
1082. Generative Flows With Invertible Attentions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sukthanker_Generative_Flows_With_Invertible_Attentions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sukthanker_Generative_Flows_With_Invertible_Attentions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sukthanker_Generative_Flows_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.03959)
1083. Estimating Fine-Grained Noise Model via Contrastive Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zou_Estimating_Fine-Grained_Noise_Model_via_Contrastive_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zou_Estimating_Fine-Grained_Noise_Model_via_Contrastive_Learning_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.01716)
1084. Shifting More Attention to Visual Backbone- Query-Modulated Refinement Networks for End-to-End Visual Grounding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Shifting_More_Attention_to_Visual_Backbone_Query-Modulated_Refinement_Networks_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Shifting_More_Attention_to_Visual_Backbone_Query-Modulated_Refinement_Networks_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_Shifting_More_Attention_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15442)
1085. DO-GAN- A Double Oracle Framework for Generative Adversarial Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Aung_DO-GAN_A_Double_Oracle_Framework_for_Generative_Adversarial_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Aung_DO-GAN_A_Double_Oracle_Framework_for_Generative_Adversarial_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Aung_DO-GAN_A_Double_CVPR_2022_supplemental.pdf)
1086. Contextualized Spatio-Temporal Contrastive Learning With Self-Supervision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_Contextualized_Spatio-Temporal_Contrastive_Learning_With_Self-Supervision_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Contextualized_Spatio-Temporal_Contrastive_Learning_With_Self-Supervision_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yuan_Contextualized_Spatio-Temporal_Contrastive_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.05181)
1087. APES- Articulated Part Extraction From Sprite Sheets | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_APES_Articulated_Part_Extraction_From_Sprite_Sheets_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_APES_Articulated_Part_Extraction_From_Sprite_Sheets_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_APES_Articulated_Part_CVPR_2022_supplemental.pdf)
1088. Uni6D- A Unified CNN Framework Without Projection Breakdown for 6D Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Uni6D_A_Unified_CNN_Framework_Without_Projection_Breakdown_for_6D_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Uni6D_A_Unified_CNN_Framework_Without_Projection_Breakdown_for_6D_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jiang_Uni6D_A_Unified_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14531)
1089. SPAMs- Structured Implicit Parametric Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Palafox_SPAMs_Structured_Implicit_Parametric_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Palafox_SPAMs_Structured_Implicit_Parametric_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Palafox_SPAMs_Structured_Implicit_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.08141)
1090. DETReg- Unsupervised Pretraining With Region Priors for Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bar_DETReg_Unsupervised_Pretraining_With_Region_Priors_for_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bar_DETReg_Unsupervised_Pretraining_With_Region_Priors_for_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bar_DETReg_Unsupervised_Pretraining_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.04550)
1091. Practical Evaluation of Adversarial Robustness via Adaptive Auto Attack | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Practical_Evaluation_of_Adversarial_Robustness_via_Adaptive_Auto_Attack_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Practical_Evaluation_of_Adversarial_Robustness_via_Adaptive_Auto_Attack_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Practical_Evaluation_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05154)
1092. Salvage of Supervision in Weakly Supervised Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sui_Salvage_of_Supervision_in_Weakly_Supervised_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sui_Salvage_of_Supervision_in_Weakly_Supervised_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sui_Salvage_of_Supervision_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.04073)
1093. Cross-View Transformers for Real-Time Map-View Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Cross-View_Transformers_for_Real-Time_Map-View_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Cross-View_Transformers_for_Real-Time_Map-View_Semantic_Segmentation_CVPR_2022_paper.pdf)
1094. Controllable Dynamic Multi-Task Architectures | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Raychaudhuri_Controllable_Dynamic_Multi-Task_Architectures_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Raychaudhuri_Controllable_Dynamic_Multi-Task_Architectures_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Raychaudhuri_Controllable_Dynamic_Multi-Task_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14949)
1095. Fire Together Wire Together- A Dynamic Pruning Approach With Self-Supervised Mask Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Elkerdawy_Fire_Together_Wire_Together_A_Dynamic_Pruning_Approach_With_Self-Supervised_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Elkerdawy_Fire_Together_Wire_Together_A_Dynamic_Pruning_Approach_With_Self-Supervised_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Elkerdawy_Fire_Together_Wire_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.08232)
1096. Multi-Source Uncertainty Mining for Deep Unsupervised Saliency Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Multi-Source_Uncertainty_Mining_for_Deep_Unsupervised_Saliency_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Multi-Source_Uncertainty_Mining_for_Deep_Unsupervised_Saliency_Detection_CVPR_2022_paper.pdf)
1097. Wavelet Knowledge Distillation- Towards Efficient Image-to-Image Translation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Wavelet_Knowledge_Distillation_Towards_Efficient_Image-to-Image_Translation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Wavelet_Knowledge_Distillation_Towards_Efficient_Image-to-Image_Translation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.06321)
1098. Improving Adversarial Transferability via Neuron Attribution-Based Attacks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Improving_Adversarial_Transferability_via_Neuron_Attribution-Based_Attacks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Improving_Adversarial_Transferability_via_Neuron_Attribution-Based_Attacks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Improving_Adversarial_Transferability_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00008)
1099. Better Trigger Inversion Optimization in Backdoor Scanning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tao_Better_Trigger_Inversion_Optimization_in_Backdoor_Scanning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Better_Trigger_Inversion_Optimization_in_Backdoor_Scanning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tao_Better_Trigger_Inversion_CVPR_2022_supplemental.pdf)
1100. Distribution Consistent Neural Architecture Search | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pan_Distribution_Consistent_Neural_Architecture_Search_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Distribution_Consistent_Neural_Architecture_Search_CVPR_2022_paper.pdf)
1101. FreeSOLO- Learning To Segment Objects Without Annotations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_FreeSOLO_Learning_To_Segment_Objects_Without_Annotations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_FreeSOLO_Learning_To_Segment_Objects_Without_Annotations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_FreeSOLO_Learning_To_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.12181)
1102. Enhancing Adversarial Robustness for Deep Metric Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Enhancing_Adversarial_Robustness_for_Deep_Metric_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Enhancing_Adversarial_Robustness_for_Deep_Metric_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Enhancing_Adversarial_Robustness_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01439)
1103. Multi-Scale High-Resolution Vision Transformer for Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gu_Multi-Scale_High-Resolution_Vision_Transformer_for_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Multi-Scale_High-Resolution_Vision_Transformer_for_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gu_Multi-Scale_High-Resolution_Vision_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.01236)
1104. Lite-MDETR- A Lightweight Multi-Modal Detector | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lou_Lite-MDETR_A_Lightweight_Multi-Modal_Detector_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lou_Lite-MDETR_A_Lightweight_Multi-Modal_Detector_CVPR_2022_paper.pdf)
1105. Look for the Change- Learning Object States and State-Modifying Actions From Untrimmed Web Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Soucek_Look_for_the_Change_Learning_Object_States_and_State-Modifying_Actions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Soucek_Look_for_the_Change_Learning_Object_States_and_State-Modifying_Actions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Soucek_Look_for_the_CVPR_2022_supplemental.pdf)
1106. Divide and Conquer- Compositional Experts for Generalized Novel Class Discovery | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Divide_and_Conquer_Compositional_Experts_for_Generalized_Novel_Class_Discovery_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Divide_and_Conquer_Compositional_Experts_for_Generalized_Novel_Class_Discovery_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Divide_and_Conquer_CVPR_2022_supplemental.pdf)
1107. Programmatic Concept Learning for Human Motion Description and Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kulal_Programmatic_Concept_Learning_for_Human_Motion_Description_and_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kulal_Programmatic_Concept_Learning_for_Human_Motion_Description_and_Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kulal_Programmatic_Concept_Learning_CVPR_2022_supplemental.pdf)
1108. Interpretable Part-Whole Hierarchies and Conceptual-Semantic Relationships in Neural Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Garau_Interpretable_Part-Whole_Hierarchies_and_Conceptual-Semantic_Relationships_in_Neural_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Garau_Interpretable_Part-Whole_Hierarchies_and_Conceptual-Semantic_Relationships_in_Neural_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Garau_Interpretable_Part-Whole_Hierarchies_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03282)
1109. Less Is More- Generating Grounded Navigation Instructions From Landmarks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Less_Is_More_Generating_Grounded_Navigation_Instructions_From_Landmarks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Less_Is_More_Generating_Grounded_Navigation_Instructions_From_Landmarks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Less_Is_More_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12872)
1110. CycleMix- A Holistic Strategy for Medical Image Segmentation From Scribble Supervision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_CycleMix_A_Holistic_Strategy_for_Medical_Image_Segmentation_From_Scribble_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_CycleMix_A_Holistic_Strategy_for_Medical_Image_Segmentation_From_Scribble_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_CycleMix_A_Holistic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01475)
1111. Image Based Reconstruction of Liquids From 2D Surface Detections | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Richter_Image_Based_Reconstruction_of_Liquids_From_2D_Surface_Detections_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Richter_Image_Based_Reconstruction_of_Liquids_From_2D_Surface_Detections_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Richter_Image_Based_Reconstruction_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2111.11491)
1112. Contextual Outpainting With Object-Level Contrastive Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Contextual_Outpainting_With_Object-Level_Contrastive_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Contextual_Outpainting_With_Object-Level_Contrastive_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Contextual_Outpainting_With_CVPR_2022_supplemental.pdf)
1113. Depth-Guided Sparse Structure-From-Motion for Movies and TV Shows | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Depth-Guided_Sparse_Structure-From-Motion_for_Movies_and_TV_Shows_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Depth-Guided_Sparse_Structure-From-Motion_for_Movies_and_TV_Shows_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Depth-Guided_Sparse_Structure-From-Motion_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.02509)
1114. When Does Contrastive Visual Representation Learning Work- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cole_When_Does_Contrastive_Visual_Representation_Learning_Work_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cole_When_Does_Contrastive_Visual_Representation_Learning_Work_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2105.05837)
1115. One Step at a Time- Long-Horizon Vision-and-Language Navigation With Milestones | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Song_One_Step_at_a_Time_Long-Horizon_Vision-and-Language_Navigation_With_Milestones_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Song_One_Step_at_a_Time_Long-Horizon_Vision-and-Language_Navigation_With_Milestones_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2202.07028)
1116. Scene Consistency Representation Learning for Video Scene Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Scene_Consistency_Representation_Learning_for_Video_Scene_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Scene_Consistency_Representation_Learning_for_Video_Scene_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Scene_Consistency_Representation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.05487)
1117. Two Coupled Rejection Metrics Can Tell Adversarial Examples Apart | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pang_Two_Coupled_Rejection_Metrics_Can_Tell_Adversarial_Examples_Apart_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pang_Two_Coupled_Rejection_Metrics_Can_Tell_Adversarial_Examples_Apart_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Pang_Two_Coupled_Rejection_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2105.14785)
1118. How Well Do Sparse ImageNet Models Transfer- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Iofinova_How_Well_Do_Sparse_ImageNet_Models_Transfer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Iofinova_How_Well_Do_Sparse_ImageNet_Models_Transfer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Iofinova_How_Well_Do_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13445)
1119. REX- Reasoning-Aware and Grounded Explanation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_REX_Reasoning-Aware_and_Grounded_Explanation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_REX_Reasoning-Aware_and_Grounded_Explanation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_REX_Reasoning-Aware_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06107)
1120. Dynamic Dual-Output Diffusion Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Benny_Dynamic_Dual-Output_Diffusion_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Benny_Dynamic_Dual-Output_Diffusion_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Benny_Dynamic_Dual-Output_Diffusion_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04304)
1121. JoinABLe- Learning Bottom-Up Assembly of Parametric CAD Joints | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Willis_JoinABLe_Learning_Bottom-Up_Assembly_of_Parametric_CAD_Joints_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Willis_JoinABLe_Learning_Bottom-Up_Assembly_of_Parametric_CAD_Joints_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Willis_JoinABLe_Learning_Bottom-Up_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12772)
1122. AEGNN- Asynchronous Event-Based Graph Neural Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Schaefer_AEGNN_Asynchronous_Event-Based_Graph_Neural_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Schaefer_AEGNN_Asynchronous_Event-Based_Graph_Neural_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Schaefer_AEGNN_Asynchronous_Event-Based_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.17149)
1123. Polarity Sampling- Quality and Diversity Control of Pre-Trained Generative Networks via Singular Values | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Humayun_Polarity_Sampling_Quality_and_Diversity_Control_of_Pre-Trained_Generative_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Humayun_Polarity_Sampling_Quality_and_Diversity_Control_of_Pre-Trained_Generative_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Humayun_Polarity_Sampling_Quality_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01993)
1124. Style-Structure Disentangled Features and Normalizing Flows for Diverse Icon Colorization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Style-Structure_Disentangled_Features_and_Normalizing_Flows_for_Diverse_Icon_Colorization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Style-Structure_Disentangled_Features_and_Normalizing_Flows_for_Diverse_Icon_Colorization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Style-Structure_Disentangled_Features_CVPR_2022_supplemental.zip)
1125. MAT- Mask-Aware Transformer for Large Hole Image Inpainting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_MAT_Mask-Aware_Transformer_for_Large_Hole_Image_Inpainting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_MAT_Mask-Aware_Transformer_for_Large_Hole_Image_Inpainting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_MAT_Mask-Aware_Transformer_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.15270)
1126. Uncertainty-Aware Deep Multi-View Photometric Stereo | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kaya_Uncertainty-Aware_Deep_Multi-View_Photometric_Stereo_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kaya_Uncertainty-Aware_Deep_Multi-View_Photometric_Stereo_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kaya_Uncertainty-Aware_Deep_Multi-View_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2202.13071)
1127. Unleashing Potential of Unsupervised Pre-Training With Intra-Identity Regularization for Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Unleashing_Potential_of_Unsupervised_Pre-Training_With_Intra-Identity_Regularization_for_Person_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Unleashing_Potential_of_Unsupervised_Pre-Training_With_Intra-Identity_Regularization_for_Person_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Unleashing_Potential_of_CVPR_2022_supplemental.pdf)
1128. MSG-Transformer- Exchanging Local Spatial Information by Manipulating Messenger Tokens | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fang_MSG-Transformer_Exchanging_Local_Spatial_Information_by_Manipulating_Messenger_Tokens_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_MSG-Transformer_Exchanging_Local_Spatial_Information_by_Manipulating_Messenger_Tokens_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fang_MSG-Transformer_Exchanging_Local_CVPR_2022_supplemental.pdf)
1129. Contrastive Dual Gating- Learning Sparse Features With Contrastive Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Meng_Contrastive_Dual_Gating_Learning_Sparse_Features_With_Contrastive_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_Contrastive_Dual_Gating_Learning_Sparse_Features_With_Contrastive_Learning_CVPR_2022_paper.pdf)
1130. Universal Photometric Stereo Network Using Global Lighting Contexts | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ikehata_Universal_Photometric_Stereo_Network_Using_Global_Lighting_Contexts_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ikehata_Universal_Photometric_Stereo_Network_Using_Global_Lighting_Contexts_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ikehata_Universal_Photometric_Stereo_CVPR_2022_supplemental.pdf)
1131. Ray3D- Ray-Based 3D Human Pose Estimation for Monocular Absolute 3D Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhan_Ray3D_Ray-Based_3D_Human_Pose_Estimation_for_Monocular_Absolute_3D_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhan_Ray3D_Ray-Based_3D_Human_Pose_Estimation_for_Monocular_Absolute_3D_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhan_Ray3D_Ray-Based_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11471)
1132. ASM-Loc- Action-Aware Segment Modeling for Weakly-Supervised Temporal Action Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_ASM-Loc_Action-Aware_Segment_Modeling_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_ASM-Loc_Action-Aware_Segment_Modeling_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_ASM-Loc_Action-Aware_Segment_CVPR_2022_supplemental.pdf)
1133. Scaling Up Your Kernels to 31x31- Revisiting Large Kernel Design in CNNs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Scaling_Up_Your_Kernels_to_31x31_Revisiting_Large_Kernel_Design_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Scaling_Up_Your_Kernels_to_31x31_Revisiting_Large_Kernel_Design_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ding_Scaling_Up_Your_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06717)
1134. End-to-End Multi-Person Pose Estimation With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_End-to-End_Multi-Person_Pose_Estimation_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_End-to-End_Multi-Person_Pose_Estimation_With_Transformers_CVPR_2022_paper.pdf)
1135. Revisiting AP Loss for Dense Object Detection- Adaptive Ranking Pair Selection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Revisiting_AP_Loss_for_Dense_Object_Detection_Adaptive_Ranking_Pair_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Revisiting_AP_Loss_for_Dense_Object_Detection_Adaptive_Ranking_Pair_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Revisiting_AP_Loss_CVPR_2022_supplemental.pdf)
1136. 3DeformRS- Certifying Spatial Deformations on Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/S._3DeformRS_Certifying_Spatial_Deformations_on_Point_Clouds_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/S._3DeformRS_Certifying_Spatial_Deformations_on_Point_Clouds_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/S._3DeformRS_Certifying_Spatial_CVPR_2022_supplemental.pdf)
1137. QueryDet- Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_QueryDet_Cascaded_Sparse_Query_for_Accelerating_High-Resolution_Small_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_QueryDet_Cascaded_Sparse_Query_for_Accelerating_High-Resolution_Small_Object_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2103.09136)
1138. BEHAVE- Dataset and Method for Tracking Human Object Interactions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bhatnagar_BEHAVE_Dataset_and_Method_for_Tracking_Human_Object_Interactions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bhatnagar_BEHAVE_Dataset_and_Method_for_Tracking_Human_Object_Interactions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bhatnagar_BEHAVE_Dataset_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.06950)
1139. Estimating Egocentric 3D Human Pose in the Wild With External Weak Supervision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Estimating_Egocentric_3D_Human_Pose_in_the_Wild_With_External_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Estimating_Egocentric_3D_Human_Pose_in_the_Wild_With_External_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Estimating_Egocentric_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.07929)
1140. Performance-Aware Mutual Knowledge Distillation for Improving Neural Architecture Search | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Performance-Aware_Mutual_Knowledge_Distillation_for_Improving_Neural_Architecture_Search_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Performance-Aware_Mutual_Knowledge_Distillation_for_Improving_Neural_Architecture_Search_CVPR_2022_paper.pdf)
1141. HyperInverter- Improving StyleGAN Inversion via Hypernetwork | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dinh_HyperInverter_Improving_StyleGAN_Inversion_via_Hypernetwork_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dinh_HyperInverter_Improving_StyleGAN_Inversion_via_Hypernetwork_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dinh_HyperInverter_Improving_StyleGAN_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00719)
1142. Dataset Distillation by Matching Training Trajectories | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cazenavette_Dataset_Distillation_by_Matching_Training_Trajectories_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cazenavette_Dataset_Distillation_by_Matching_Training_Trajectories_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.11932)
1143. Global Context With Discrete Diffusion in Vector Quantised Modelling for Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Global_Context_With_Discrete_Diffusion_in_Vector_Quantised_Modelling_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Global_Context_With_Discrete_Diffusion_in_Vector_Quantised_Modelling_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_Global_Context_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01799)
1144. Symmetry and Uncertainty-Aware Object SLAM for 6DoF Object Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Merrill_Symmetry_and_Uncertainty-Aware_Object_SLAM_for_6DoF_Object_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Merrill_Symmetry_and_Uncertainty-Aware_Object_SLAM_for_6DoF_Object_Pose_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Merrill_Symmetry_and_Uncertainty-Aware_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.01823)
1145. Towards Multimodal Depth Estimation From Light Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Leistner_Towards_Multimodal_Depth_Estimation_From_Light_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Leistner_Towards_Multimodal_Depth_Estimation_From_Light_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Leistner_Towards_Multimodal_Depth_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16542)
1146. Learning To Recognize Procedural Activities With Distant Supervision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Learning_To_Recognize_Procedural_Activities_With_Distant_Supervision_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Learning_To_Recognize_Procedural_Activities_With_Distant_Supervision_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_Learning_To_Recognize_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.10990)
1147. Weakly Supervised Rotation-Invariant Aerial Object Detection Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Weakly_Supervised_Rotation-Invariant_Aerial_Object_Detection_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Weakly_Supervised_Rotation-Invariant_Aerial_Object_Detection_Network_CVPR_2022_paper.pdf)
1148. Modeling Motion With Multi-Modal Features for Text-Based Video Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Modeling_Motion_With_Multi-Modal_Features_for_Text-Based_Video_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Modeling_Motion_With_Multi-Modal_Features_for_Text-Based_Video_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_Modeling_Motion_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02547)
1149. Deformable Video Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Deformable_Video_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Deformable_Video_Transformer_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16795)
1150. Fast, Accurate and Memory-Efficient Partial Permutation Synchronization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Fast_Accurate_and_Memory-Efficient_Partial_Permutation_Synchronization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Fast_Accurate_and_Memory-Efficient_Partial_Permutation_Synchronization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Fast_Accurate_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16505)
1151. ScaleNet- A Shallow Architecture for Scale Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Barroso-Laguna_ScaleNet_A_Shallow_Architecture_for_Scale_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Barroso-Laguna_ScaleNet_A_Shallow_Architecture_for_Scale_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Barroso-Laguna_ScaleNet_A_Shallow_CVPR_2022_supplemental.pdf)
1152. Bounded Adversarial Attack on Deep Content Features | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Bounded_Adversarial_Attack_on_Deep_Content_Features_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Bounded_Adversarial_Attack_on_Deep_Content_Features_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Bounded_Adversarial_Attack_CVPR_2022_supplemental.pdf)
1153. CAD- Co-Adapting Discriminative Features for Improved Few-Shot Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chikontwe_CAD_Co-Adapting_Discriminative_Features_for_Improved_Few-Shot_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chikontwe_CAD_Co-Adapting_Discriminative_Features_for_Improved_Few-Shot_Classification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chikontwe_CAD_Co-Adapting_Discriminative_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.13465)
1154. Fingerprinting Deep Neural Networks Globally via Universal Adversarial Perturbations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Peng_Fingerprinting_Deep_Neural_Networks_Globally_via_Universal_Adversarial_Perturbations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Fingerprinting_Deep_Neural_Networks_Globally_via_Universal_Adversarial_Perturbations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Peng_Fingerprinting_Deep_Neural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.08602)
1155. ManiTrans- Entity-Level Text-Guided Image Manipulation via Token-Wise Semantic Alignment and Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ManiTrans_Entity-Level_Text-Guided_Image_Manipulation_via_Token-Wise_Semantic_Alignment_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ManiTrans_Entity-Level_Text-Guided_Image_Manipulation_via_Token-Wise_Semantic_Alignment_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_ManiTrans_Entity-Level_Text-Guided_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04428)
1156. Robust Image Forgery Detection Over Online Social Network Shared Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Robust_Image_Forgery_Detection_Over_Online_Social_Network_Shared_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Robust_Image_Forgery_Detection_Over_Online_Social_Network_Shared_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Robust_Image_Forgery_CVPR_2022_supplemental.pdf)
1157. Text2Mesh- Text-Driven Neural Stylization for Meshes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Michel_Text2Mesh_Text-Driven_Neural_Stylization_for_Meshes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Michel_Text2Mesh_Text-Driven_Neural_Stylization_for_Meshes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Michel_Text2Mesh_Text-Driven_Neural_CVPR_2022_supplemental.pdf)
1158. FWD- Real-Time Novel View Synthesis With Forward Warping and Depth | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cao_FWD_Real-Time_Novel_View_Synthesis_With_Forward_Warping_and_Depth_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_FWD_Real-Time_Novel_View_Synthesis_With_Forward_Warping_and_Depth_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cao_FWD_Real-Time_Novel_CVPR_2022_supplemental.pdf)
1159. C-CAM- Causal CAM for Weakly Supervised Semantic Segmentation on Medical Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_C-CAM_Causal_CAM_for_Weakly_Supervised_Semantic_Segmentation_on_Medical_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_C-CAM_Causal_CAM_for_Weakly_Supervised_Semantic_Segmentation_on_Medical_CVPR_2022_paper.pdf)
1160. Leveraging Real Talking Faces via Self-Supervision for Robust Forgery Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Haliassos_Leveraging_Real_Talking_Faces_via_Self-Supervision_for_Robust_Forgery_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Haliassos_Leveraging_Real_Talking_Faces_via_Self-Supervision_for_Robust_Forgery_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Haliassos_Leveraging_Real_Talking_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.07131)
1161. BaLeNAS- Differentiable Architecture Search via the Bayesian Learning Rule | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_BaLeNAS_Differentiable_Architecture_Search_via_the_Bayesian_Learning_Rule_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_BaLeNAS_Differentiable_Architecture_Search_via_the_Bayesian_Learning_Rule_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_BaLeNAS_Differentiable_Architecture_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13204)
1162. Weakly Supervised Object Localization As Domain Adaption | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Weakly_Supervised_Object_Localization_As_Domain_Adaption_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Weakly_Supervised_Object_Localization_As_Domain_Adaption_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Weakly_Supervised_Object_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01714)
1163. Dynamic Prototype Convolution Network for Few-Shot Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Dynamic_Prototype_Convolution_Network_for_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Dynamic_Prototype_Convolution_Network_for_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Dynamic_Prototype_Convolution_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.10638)
1164. Mr.BiQ- Post-Training Non-Uniform Quantization Based on Minimizing the Reconstruction Error | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jeon_Mr.BiQ_Post-Training_Non-Uniform_Quantization_Based_on_Minimizing_the_Reconstruction_Error_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jeon_Mr.BiQ_Post-Training_Non-Uniform_Quantization_Based_on_Minimizing_the_Reconstruction_Error_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jeon_Mr.BiQ_Post-Training_Non-Uniform_CVPR_2022_supplemental.pdf)
1165. MatteFormer- Transformer-Based Image Matting via Prior-Tokens | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Park_MatteFormer_Transformer-Based_Image_Matting_via_Prior-Tokens_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_MatteFormer_Transformer-Based_Image_Matting_via_Prior-Tokens_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Park_MatteFormer_Transformer-Based_Image_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15662)
1166. ESCNet- Gaze Target Detection With the Understanding of 3D Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bao_ESCNet_Gaze_Target_Detection_With_the_Understanding_of_3D_Scenes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_ESCNet_Gaze_Target_Detection_With_the_Understanding_of_3D_Scenes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bao_ESCNet_Gaze_Target_CVPR_2022_supplemental.pdf)
1167. Point2Cyl- Reverse Engineering 3D Objects From Point Clouds to Extrusion Cylinders | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Uy_Point2Cyl_Reverse_Engineering_3D_Objects_From_Point_Clouds_to_Extrusion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Uy_Point2Cyl_Reverse_Engineering_3D_Objects_From_Point_Clouds_to_Extrusion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Uy_Point2Cyl_Reverse_Engineering_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.09329)
1168. MHFormer- Multi-Hypothesis Transformer for 3D Human Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_MHFormer_Multi-Hypothesis_Transformer_for_3D_Human_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_MHFormer_Multi-Hypothesis_Transformer_for_3D_Human_Pose_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_MHFormer_Multi-Hypothesis_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12707)
1169. Surface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Surface-Aligned_Neural_Radiance_Fields_for_Controllable_3D_Human_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Surface-Aligned_Neural_Radiance_Fields_for_Controllable_3D_Human_Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Surface-Aligned_Neural_Radiance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.01683)
1170. Unsupervised Vision-Language Parsing- Seamlessly Bridging Visual Scene Graphs With Language Structures via Dependency Relationships | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lou_Unsupervised_Vision-Language_Parsing_Seamlessly_Bridging_Visual_Scene_Graphs_With_Language_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lou_Unsupervised_Vision-Language_Parsing_Seamlessly_Bridging_Visual_Scene_Graphs_With_Language_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.14260)
1171. Query and Attention Augmentation for Knowledge-Based Explainable Reasoning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Query_and_Attention_Augmentation_for_Knowledge-Based_Explainable_Reasoning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Query_and_Attention_Augmentation_for_Knowledge-Based_Explainable_Reasoning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Query_and_Attention_CVPR_2022_supplemental.pdf)
1172. Interactron- Embodied Adaptive Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kotar_Interactron_Embodied_Adaptive_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kotar_Interactron_Embodied_Adaptive_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kotar_Interactron_Embodied_Adaptive_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.00660)
1173. MeMViT- Memory-Augmented Multiscale Vision Transformer for Efficient Long-Term Video Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_MeMViT_Memory-Augmented_Multiscale_Vision_Transformer_for_Efficient_Long-Term_Video_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_MeMViT_Memory-Augmented_Multiscale_Vision_Transformer_for_Efficient_Long-Term_Video_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_MeMViT_Memory-Augmented_Multiscale_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.08383)
1174. Multidimensional Belief Quantification for Label-Efficient Meta-Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pandey_Multidimensional_Belief_Quantification_for_Label-Efficient_Meta-Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pandey_Multidimensional_Belief_Quantification_for_Label-Efficient_Meta-Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Pandey_Multidimensional_Belief_Quantification_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12768)
1175. HODEC- Towards Efficient High-Order DEcomposed Convolutional Neural Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yin_HODEC_Towards_Efficient_High-Order_DEcomposed_Convolutional_Neural_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_HODEC_Towards_Efficient_High-Order_DEcomposed_Convolutional_Neural_Networks_CVPR_2022_paper.pdf)
1176. Bridging the Gap Between Learning in Discrete and Continuous Environments for Vision-and-Language Navigation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Bridging_the_Gap_Between_Learning_in_Discrete_and_Continuous_Environments_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Bridging_the_Gap_Between_Learning_in_Discrete_and_Continuous_Environments_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hong_Bridging_the_Gap_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02764)
1177. Learning Deep Implicit Functions for 3D Shapes With Dynamic Code Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Learning_Deep_Implicit_Functions_for_3D_Shapes_With_Dynamic_Code_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_Deep_Implicit_Functions_for_3D_Shapes_With_Dynamic_Code_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Learning_Deep_Implicit_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14048)
1178. Reversible Vision Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mangalam_Reversible_Vision_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mangalam_Reversible_Vision_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mangalam_Reversible_Vision_Transformers_CVPR_2022_supplemental.pdf)
1179. Protecting Facial Privacy- Generating Adversarial Identity Masks via Style-Robust Makeup Transfer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Protecting_Facial_Privacy_Generating_Adversarial_Identity_Masks_via_Style-Robust_Makeup_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Protecting_Facial_Privacy_Generating_Adversarial_Identity_Masks_via_Style-Robust_Makeup_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_Protecting_Facial_Privacy_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03121)
1180. Temporal Feature Alignment and Mutual Information Maximization for Video-Based Human Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Temporal_Feature_Alignment_and_Mutual_Information_Maximization_for_Video-Based_Human_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Temporal_Feature_Alignment_and_Mutual_Information_Maximization_for_Video-Based_Human_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.15227)
1181. Spatially-Adaptive Multilayer Selection for GAN Inversion and Editing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Parmar_Spatially-Adaptive_Multilayer_Selection_for_GAN_Inversion_and_Editing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Parmar_Spatially-Adaptive_Multilayer_Selection_for_GAN_Inversion_and_Editing_CVPR_2022_paper.pdf)
1182. Self-Supervised Transformers for Unsupervised Object Discovery Using Normalized Cut | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Self-Supervised_Transformers_for_Unsupervised_Object_Discovery_Using_Normalized_Cut_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Self-Supervised_Transformers_for_Unsupervised_Object_Discovery_Using_Normalized_Cut_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Self-Supervised_Transformers_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.11539)
1183. Towards Robust Adaptive Object Detection Under Noisy Annotations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Towards_Robust_Adaptive_Object_Detection_Under_Noisy_Annotations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Robust_Adaptive_Object_Detection_Under_Noisy_Annotations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Towards_Robust_Adaptive_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02620)
1184. Open-Vocabulary One-Stage Detection With Hierarchical Visual-Language Knowledge Distillation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Open-Vocabulary_One-Stage_Detection_With_Hierarchical_Visual-Language_Knowledge_Distillation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Open-Vocabulary_One-Stage_Detection_With_Hierarchical_Visual-Language_Knowledge_Distillation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_Open-Vocabulary_One-Stage_Detection_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10593)
1185. COAP- Compositional Articulated Occupancy of People | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mihajlovic_COAP_Compositional_Articulated_Occupancy_of_People_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mihajlovic_COAP_Compositional_Articulated_Occupancy_of_People_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mihajlovic_COAP_Compositional_Articulated_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.06184)
1186. Counterfactual Cycle-Consistent Learning for Instruction Following and Generation in Vision-Language Navigation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Counterfactual_Cycle-Consistent_Learning_for_Instruction_Following_and_Generation_in_Vision-Language_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Counterfactual_Cycle-Consistent_Learning_for_Instruction_Following_and_Generation_in_Vision-Language_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16586)
1187. Motion-Adjustable Neural Implicit Video Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mai_Motion-Adjustable_Neural_Implicit_Video_Representation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mai_Motion-Adjustable_Neural_Implicit_Video_Representation_CVPR_2022_paper.pdf)
1188. The Norm Must Go On- Dynamic Unsupervised Domain Adaptation by Normalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mirza_The_Norm_Must_Go_On_Dynamic_Unsupervised_Domain_Adaptation_by_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mirza_The_Norm_Must_Go_On_Dynamic_Unsupervised_Domain_Adaptation_by_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mirza_The_Norm_Must_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00463)
1189. Learning To Prompt for Open-Vocabulary Object Detection With Vision-Language Model | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Du_Learning_To_Prompt_for_Open-Vocabulary_Object_Detection_With_Vision-Language_Model_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Learning_To_Prompt_for_Open-Vocabulary_Object_Detection_With_Vision-Language_Model_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Du_Learning_To_Prompt_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14940)
1190. General Incremental Learning With Domain-Aware Categorical Representations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_General_Incremental_Learning_With_Domain-Aware_Categorical_Representations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_General_Incremental_Learning_With_Domain-Aware_Categorical_Representations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xie_General_Incremental_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04078)
1191. ActiveZero- Mixed Domain Learning for Active Stereovision With Zero Annotation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_ActiveZero_Mixed_Domain_Learning_for_Active_Stereovision_With_Zero_Annotation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_ActiveZero_Mixed_Domain_Learning_for_Active_Stereovision_With_Zero_Annotation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_ActiveZero_Mixed_Domain_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02772)
1192. DearKD- Data-Efficient Early Knowledge Distillation for Vision Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_DearKD_Data-Efficient_Early_Knowledge_Distillation_for_Vision_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_DearKD_Data-Efficient_Early_Knowledge_Distillation_for_Vision_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_DearKD_Data-Efficient_Early_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.12997)
1193. ContrastMask- Contrastive Learning To Segment Every Thing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ContrastMask_Contrastive_Learning_To_Segment_Every_Thing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ContrastMask_Contrastive_Learning_To_Segment_Every_Thing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_ContrastMask_Contrastive_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09775)
1194. Rep-Net- Efficient On-Device Learning via Feature Reprogramming | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Rep-Net_Efficient_On-Device_Learning_via_Feature_Reprogramming_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Rep-Net_Efficient_On-Device_Learning_via_Feature_Reprogramming_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Rep-Net_Efficient_On-Device_CVPR_2022_supplemental.pdf)
1195. Implicit Motion Handling for Video Camouflaged Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Implicit_Motion_Handling_for_Video_Camouflaged_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Implicit_Motion_Handling_for_Video_Camouflaged_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cheng_Implicit_Motion_Handling_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.07363)
1196. Learning With Twin Noisy Labels for Visible-Infrared Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Learning_With_Twin_Noisy_Labels_for_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Learning_With_Twin_Noisy_Labels_for_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Learning_With_Twin_CVPR_2022_supplemental.pdf)
1197. MetaFormer Is Actually What You Need for Vision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_MetaFormer_Is_Actually_What_You_Need_for_Vision_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_MetaFormer_Is_Actually_What_You_Need_for_Vision_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_MetaFormer_Is_Actually_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.11418)
1198. Knowledge Distillation via the Target-Aware Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Knowledge_Distillation_via_the_Target-Aware_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Knowledge_Distillation_via_the_Target-Aware_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_Knowledge_Distillation_via_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.10793)
1199. Recurring the Transformer for Video Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Recurring_the_Transformer_for_Video_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Recurring_the_Transformer_for_Video_Action_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Recurring_the_Transformer_CVPR_2022_supplemental.pdf)
1200. Subspace Adversarial Training | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Subspace_Adversarial_Training_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Subspace_Adversarial_Training_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Subspace_Adversarial_Training_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12229)
1201. Background Activation Suppression for Weakly Supervised Object Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Background_Activation_Suppression_for_Weakly_Supervised_Object_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Background_Activation_Suppression_for_Weakly_Supervised_Object_Localization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Background_Activation_Suppression_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00580)
1202. Motion-From-Blur- 3D Shape and Motion Estimation of Motion-Blurred Objects in Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rozumnyi_Motion-From-Blur_3D_Shape_and_Motion_Estimation_of_Motion-Blurred_Objects_in_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rozumnyi_Motion-From-Blur_3D_Shape_and_Motion_Estimation_of_Motion-Blurred_Objects_in_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rozumnyi_Motion-From-Blur_3D_Shape_CVPR_2022_supplemental.zip)
1203. Hallucinated Neural Radiance Fields in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Hallucinated_Neural_Radiance_Fields_in_the_Wild_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Hallucinated_Neural_Radiance_Fields_in_the_Wild_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Hallucinated_Neural_Radiance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15246)
1204. Backdoor Attacks on Self-Supervised Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Saha_Backdoor_Attacks_on_Self-Supervised_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Saha_Backdoor_Attacks_on_Self-Supervised_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Saha_Backdoor_Attacks_on_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2105.10123)
1205. Multimodal Token Fusion for Vision Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Multimodal_Token_Fusion_for_Vision_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Multimodal_Token_Fusion_for_Vision_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Multimodal_Token_Fusion_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.08721)
1206. FLAVA- A Foundational Language and Vision Alignment Model | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Singh_FLAVA_A_Foundational_Language_and_Vision_Alignment_Model_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_FLAVA_A_Foundational_Language_and_Vision_Alignment_Model_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Singh_FLAVA_A_Foundational_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.04482)
1207. OCSampler- Compressing Videos to One Clip With Single-Step Sampling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_OCSampler_Compressing_Videos_to_One_Clip_With_Single-Step_Sampling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_OCSampler_Compressing_Videos_to_One_Clip_With_Single-Step_Sampling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_OCSampler_Compressing_Videos_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.04388)
1208. Grounded Language-Image Pre-Training | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.03857)
1209. PatchFormer- An Efficient Point Transformer With Patch Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_PatchFormer_An_Efficient_Point_Transformer_With_Patch_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_PatchFormer_An_Efficient_Point_Transformer_With_Patch_Attention_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.00207)
1210. Label Matching Semi-Supervised Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Label_Matching_Semi-Supervised_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Label_Matching_Semi-Supervised_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Label_Matching_Semi-Supervised_CVPR_2022_supplemental.pdf)
1211. An MIL-Derived Transformer for Weakly Supervised Point Cloud Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_An_MIL-Derived_Transformer_for_Weakly_Supervised_Point_Cloud_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_An_MIL-Derived_Transformer_for_Weakly_Supervised_Point_Cloud_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_An_MIL-Derived_Transformer_CVPR_2022_supplemental.pdf)
1212. Fast Light-Weight Near-Field Photometric Stereo | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lichy_Fast_Light-Weight_Near-Field_Photometric_Stereo_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lichy_Fast_Light-Weight_Near-Field_Photometric_Stereo_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lichy_Fast_Light-Weight_Near-Field_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16515)
1213. Uniform Subdivision of Omnidirectional Camera Space for Efficient Spherical Stereo Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kang_Uniform_Subdivision_of_Omnidirectional_Camera_Space_for_Efficient_Spherical_Stereo_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Uniform_Subdivision_of_Omnidirectional_Camera_Space_for_Efficient_Spherical_Stereo_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kang_Uniform_Subdivision_of_CVPR_2022_supplemental.pdf)
1214. High-Resolution Image Synthesis With Latent Diffusion Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rombach_High-Resolution_Image_Synthesis_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.10752)
1215. Transferable Sparse Adversarial Attack | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_Transferable_Sparse_Adversarial_Attack_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Transferable_Sparse_Adversarial_Attack_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2105.14727)
1216. StyleSDF- High-Resolution 3D-Consistent Image and Geometry Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Or-El_StyleSDF_High-Resolution_3D-Consistent_Image_and_Geometry_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Or-El_StyleSDF_High-Resolution_3D-Consistent_Image_and_Geometry_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Or-El_StyleSDF_High-Resolution_3D-Consistent_CVPR_2022_supplemental.pdf)
1217. GLAMR- Global Occlusion-Aware Human Mesh Recovery With Dynamic Cameras | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_GLAMR_Global_Occlusion-Aware_Human_Mesh_Recovery_With_Dynamic_Cameras_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_GLAMR_Global_Occlusion-Aware_Human_Mesh_Recovery_With_Dynamic_Cameras_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yuan_GLAMR_Global_Occlusion-Aware_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2112.01524)
1218. Capturing and Inferring Dense Full-Body Human-Scene Contact | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Capturing_and_Inferring_Dense_Full-Body_Human-Scene_Contact_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Capturing_and_Inferring_Dense_Full-Body_Human-Scene_Contact_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Capturing_and_Inferring_CVPR_2022_supplemental.pdf)
1219. Diverse Plausible 360-Degree Image Outpainting for Efficient 3DCG Background Creation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Akimoto_Diverse_Plausible_360-Degree_Image_Outpainting_for_Efficient_3DCG_Background_Creation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Akimoto_Diverse_Plausible_360-Degree_Image_Outpainting_for_Efficient_3DCG_Background_Creation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Akimoto_Diverse_Plausible_360-Degree_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14668)
1220. Generating High Fidelity Data From Low-Density Regions Using Diffusion Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sehwag_Generating_High_Fidelity_Data_From_Low-Density_Regions_Using_Diffusion_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sehwag_Generating_High_Fidelity_Data_From_Low-Density_Regions_Using_Diffusion_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sehwag_Generating_High_Fidelity_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.17260)
1221. CAFE- Learning To Condense Dataset by Aligning Features | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_CAFE_Learning_To_Condense_Dataset_by_Aligning_Features_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_CAFE_Learning_To_Condense_Dataset_by_Aligning_Features_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.01531)
1222. Generalized Few-Shot Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tian_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tian_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tian_Generalized_Few-Shot_Semantic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2010.05210)
1223. Exploiting Rigidity Constraints for LiDAR Scene Flow Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Exploiting_Rigidity_Constraints_for_LiDAR_Scene_Flow_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Exploiting_Rigidity_Constraints_for_LiDAR_Scene_Flow_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_Exploiting_Rigidity_Constraints_CVPR_2022_supplemental.pdf)
1224. PoseKernelLifter- Metric Lifting of 3D Human Pose Using Sound | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_PoseKernelLifter_Metric_Lifting_of_3D_Human_Pose_Using_Sound_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_PoseKernelLifter_Metric_Lifting_of_3D_Human_Pose_Using_Sound_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.00216)
1225. AlignQ- Alignment Quantization With ADMM-Based Correlation Preservation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_AlignQ_Alignment_Quantization_With_ADMM-Based_Correlation_Preservation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_AlignQ_Alignment_Quantization_With_ADMM-Based_Correlation_Preservation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_AlignQ_Alignment_Quantization_CVPR_2022_supplemental.pdf)
1226. Self-Distillation From the Last Mini-Batch for Consistency Regularization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shen_Self-Distillation_From_the_Last_Mini-Batch_for_Consistency_Regularization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Self-Distillation_From_the_Last_Mini-Batch_for_Consistency_Regularization_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16172)
1227. Interactive Multi-Class Tiny-Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Interactive_Multi-Class_Tiny-Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Interactive_Multi-Class_Tiny-Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Interactive_Multi-Class_Tiny-Object_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.15266)
1228. ART-Point- Improving Rotation Robustness of Point Cloud Classifiers via Adversarial Rotation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ART-Point_Improving_Rotation_Robustness_of_Point_Cloud_Classifiers_via_Adversarial_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ART-Point_Improving_Rotation_Robustness_of_Point_Cloud_Classifiers_via_Adversarial_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_ART-Point_Improving_Rotation_CVPR_2022_supplemental.pdf)
1229. 360-Attack- Distortion-Aware Perturbations From Perspective-Views | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_360-Attack_Distortion-Aware_Perturbations_From_Perspective-Views_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_360-Attack_Distortion-Aware_Perturbations_From_Perspective-Views_CVPR_2022_paper.pdf)
1230. Bandits for Structure Perturbation-Based Black-Box Attacks To Graph Neural Networks With Theoretical Guarantees | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Bandits_for_Structure_Perturbation-Based_Black-Box_Attacks_To_Graph_Neural_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Bandits_for_Structure_Perturbation-Based_Black-Box_Attacks_To_Graph_Neural_Networks_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.03546)
1231. Decoupling Makes Weakly Supervised Local Feature Better | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Decoupling_Makes_Weakly_Supervised_Local_Feature_Better_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Decoupling_Makes_Weakly_Supervised_Local_Feature_Better_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Decoupling_Makes_Weakly_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.02861)
1232. A Unified Model for Line Projections in Catadioptric Cameras With Rotationally Symmetric Mirrors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Miraldo_A_Unified_Model_for_Line_Projections_in_Catadioptric_Cameras_With_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Miraldo_A_Unified_Model_for_Line_Projections_in_Catadioptric_Cameras_With_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Miraldo_A_Unified_Model_CVPR_2022_supplemental.pdf)
1233. Self-Supervised Neural Articulated Shape and Appearance Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wei_Self-Supervised_Neural_Articulated_Shape_and_Appearance_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Self-Supervised_Neural_Articulated_Shape_and_Appearance_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wei_Self-Supervised_Neural_Articulated_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2205.08525)
1234. TCTrack- Temporal Contexts for Aerial Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cao_TCTrack_Temporal_Contexts_for_Aerial_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_TCTrack_Temporal_Contexts_for_Aerial_Tracking_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cao_TCTrack_Temporal_Contexts_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01885)
1235. GAN-Supervised Dense Visual Alignment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Peebles_GAN-Supervised_Dense_Visual_Alignment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Peebles_GAN-Supervised_Dense_Visual_Alignment_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Peebles_GAN-Supervised_Dense_Visual_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.05143)
1236. GIFS- Neural Implicit Function for General Shape Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_GIFS_Neural_Implicit_Function_for_General_Shape_Representation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_GIFS_Neural_Implicit_Function_for_General_Shape_Representation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_GIFS_Neural_Implicit_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07126)
1237. Deblur-NeRF- Neural Radiance Fields From Blurry Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Deblur-NeRF_Neural_Radiance_Fields_From_Blurry_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Deblur-NeRF_Neural_Radiance_Fields_From_Blurry_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_Deblur-NeRF_Neural_Radiance_CVPR_2022_supplemental.pdf)
1238. DoubleField- Bridging the Neural Surface and Radiance Fields for High-Fidelity Human Reconstruction and Rendering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shao_DoubleField_Bridging_the_Neural_Surface_and_Radiance_Fields_for_High-Fidelity_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shao_DoubleField_Bridging_the_Neural_Surface_and_Radiance_Fields_for_High-Fidelity_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shao_DoubleField_Bridging_the_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.03798)
1239. UnweaveNet- Unweaving Activity Stories | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Price_UnweaveNet_Unweaving_Activity_Stories_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Price_UnweaveNet_Unweaving_Activity_Stories_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Price_UnweaveNet_Unweaving_Activity_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2112.10194)
1240. Look Closer To Supervise Better- One-Shot Font Generation via Component-Based Discriminator | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kong_Look_Closer_To_Supervise_Better_One-Shot_Font_Generation_via_Component-Based_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_Look_Closer_To_Supervise_Better_One-Shot_Font_Generation_via_Component-Based_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kong_Look_Closer_To_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.00146)
1241. PhyIR- Physics-Based Inverse Rendering for Panoramic Indoor Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_PhyIR_Physics-Based_Inverse_Rendering_for_Panoramic_Indoor_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_PhyIR_Physics-Based_Inverse_Rendering_for_Panoramic_Indoor_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_PhyIR_Physics-Based_Inverse_CVPR_2022_supplemental.pdf)
1242. Beyond Fixation- Dynamic Window Visual Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Beyond_Fixation_Dynamic_Window_Visual_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Beyond_Fixation_Dynamic_Window_Visual_Transformer_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.12856)
1243. Improving GAN Equilibrium by Raising Spatial Awareness | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Improving_GAN_Equilibrium_by_Raising_Spatial_Awareness_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Improving_GAN_Equilibrium_by_Raising_Spatial_Awareness_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Improving_GAN_Equilibrium_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00718)
1244. Propagation Regularizer for Semi-Supervised Learning With Extremely Scarce Labeled Samples | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Propagation_Regularizer_for_Semi-Supervised_Learning_With_Extremely_Scarce_Labeled_Samples_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Propagation_Regularizer_for_Semi-Supervised_Learning_With_Extremely_Scarce_Labeled_Samples_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Propagation_Regularizer_for_CVPR_2022_supplemental.zip)
1245. Bailando- 3D Dance Generation by Actor-Critic GPT With Choreographic Memory | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Siyao_Bailando_3D_Dance_Generation_by_Actor-Critic_GPT_With_Choreographic_Memory_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Siyao_Bailando_3D_Dance_Generation_by_Actor-Critic_GPT_With_Choreographic_Memory_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Siyao_Bailando_3D_Dance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13055)
1246. Learning Local-Global Contextual Adaptation for Multi-Person Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Learning_Local-Global_Contextual_Adaptation_for_Multi-Person_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Learning_Local-Global_Contextual_Adaptation_for_Multi-Person_Pose_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xue_Learning_Local-Global_Contextual_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2109.03622)
1247. TVConv- Efficient Translation Variant Convolution for Layout-Aware Visual Processing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_TVConv_Efficient_Translation_Variant_Convolution_for_Layout-Aware_Visual_Processing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_TVConv_Efficient_Translation_Variant_Convolution_for_Layout-Aware_Visual_Processing_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.10489)
1248. Vision-Language Pre-Training for Boosting Scene Text Detectors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Song_Vision-Language_Pre-Training_for_Boosting_Scene_Text_Detectors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Song_Vision-Language_Pre-Training_for_Boosting_Scene_Text_Detectors_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.13867)
1249. Simple but Effective- CLIP Embeddings for Embodied AI | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Khandelwal_Simple_but_Effective_CLIP_Embeddings_for_Embodied_AI_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Khandelwal_Simple_but_Effective_CLIP_Embeddings_for_Embodied_AI_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Khandelwal_Simple_but_Effective_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.09888)
1250. NomMer- Nominate Synergistic Context in Vision Transformer for Visual Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_NomMer_Nominate_Synergistic_Context_in_Vision_Transformer_for_Visual_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_NomMer_Nominate_Synergistic_Context_in_Vision_Transformer_for_Visual_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_NomMer_Nominate_Synergistic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12994)
1251. Not All Labels Are Equal- Rationalizing the Labeling Costs for Training Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Elezi_Not_All_Labels_Are_Equal_Rationalizing_the_Labeling_Costs_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Elezi_Not_All_Labels_Are_Equal_Rationalizing_the_Labeling_Costs_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Elezi_Not_All_Labels_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.11921)
1252. Interact Before Align- Leveraging Cross-Modal Knowledge for Domain Adaptive Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Interact_Before_Align_Leveraging_Cross-Modal_Knowledge_for_Domain_Adaptive_Action_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Interact_Before_Align_Leveraging_Cross-Modal_Knowledge_for_Domain_Adaptive_Action_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Interact_Before_Align_CVPR_2022_supplemental.pdf)
1253. Dynamic MLP for Fine-Grained Image Classification by Leveraging Geographical and Temporal Information | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Dynamic_MLP_for_Fine-Grained_Image_Classification_by_Leveraging_Geographical_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Dynamic_MLP_for_Fine-Grained_Image_Classification_by_Leveraging_Geographical_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Dynamic_MLP_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03253)
1254. Bending Graphs- Hierarchical Shape Matching Using Gated Optimal Transport | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Saleh_Bending_Graphs_Hierarchical_Shape_Matching_Using_Gated_Optimal_Transport_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Saleh_Bending_Graphs_Hierarchical_Shape_Matching_Using_Gated_Optimal_Transport_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Saleh_Bending_Graphs_Hierarchical_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.01537)
1255. RCL- Recurrent Continuous Localization for Temporal Action Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_RCL_Recurrent_Continuous_Localization_for_Temporal_Action_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RCL_Recurrent_Continuous_Localization_for_Temporal_Action_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_RCL_Recurrent_Continuous_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.07112)
1256. FoggyStereo- Stereo Matching With Fog Volume Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yao_FoggyStereo_Stereo_Matching_With_Fog_Volume_Representation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yao_FoggyStereo_Stereo_Matching_With_Fog_Volume_Representation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yao_FoggyStereo_Stereo_Matching_CVPR_2022_supplemental.pdf)
1257. Trajectory Optimization for Physics-Based Reconstruction of 3D Human Pose From Monocular Video | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gartner_Trajectory_Optimization_for_Physics-Based_Reconstruction_of_3D_Human_Pose_From_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gartner_Trajectory_Optimization_for_Physics-Based_Reconstruction_of_3D_Human_Pose_From_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gartner_Trajectory_Optimization_for_CVPR_2022_supplemental.pdf)
1258. Lifelong Unsupervised Domain Adaptive Person Re-Identification With Coordinated Anti-Forgetting and Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Lifelong_Unsupervised_Domain_Adaptive_Person_Re-Identification_With_Coordinated_Anti-Forgetting_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Lifelong_Unsupervised_Domain_Adaptive_Person_Re-Identification_With_Coordinated_Anti-Forgetting_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Lifelong_Unsupervised_Domain_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.06632)
1259. Dynamic Scene Graph Generation via Anticipatory Pre-Training | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Dynamic_Scene_Graph_Generation_via_Anticipatory_Pre-Training_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Dynamic_Scene_Graph_Generation_via_Anticipatory_Pre-Training_CVPR_2022_paper.pdf)
1260. CSWin Transformer- A General Vision Transformer Backbone With Cross-Shaped Windows | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_CSWin_Transformer_A_General_Vision_Transformer_Backbone_With_Cross-Shaped_Windows_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_CSWin_Transformer_A_General_Vision_Transformer_Backbone_With_Cross-Shaped_Windows_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_CSWin_Transformer_A_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2107.00652)
1261. ITSA- An Information-Theoretic Approach to Automatic Shortcut Avoidance and Domain Generalization in Stereo Matching Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chuah_ITSA_An_Information-Theoretic_Approach_to_Automatic_Shortcut_Avoidance_and_Domain_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chuah_ITSA_An_Information-Theoretic_Approach_to_Automatic_Shortcut_Avoidance_and_Domain_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chuah_ITSA_An_Information-Theoretic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.02263)
1262. Reduce Information Loss in Transformers for Pluralistic Image Inpainting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Reduce_Information_Loss_in_Transformers_for_Pluralistic_Image_Inpainting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Reduce_Information_Loss_in_Transformers_for_Pluralistic_Image_Inpainting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Reduce_Information_Loss_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.05076)
1263. Cross-Modal Transferable Adversarial Attacks From Images to Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wei_Cross-Modal_Transferable_Adversarial_Attacks_From_Images_to_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Cross-Modal_Transferable_Adversarial_Attacks_From_Images_to_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wei_Cross-Modal_Transferable_Adversarial_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.05379)
1264. Occlusion-Robust Face Alignment Using a Viewpoint-Invariant Hierarchical Network Architecture | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Occlusion-Robust_Face_Alignment_Using_a_Viewpoint-Invariant_Hierarchical_Network_Architecture_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Occlusion-Robust_Face_Alignment_Using_a_Viewpoint-Invariant_Hierarchical_Network_Architecture_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Occlusion-Robust_Face_Alignment_CVPR_2022_supplemental.pdf)
1265. Physical Simulation Layer for Accurate 3D Modeling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mezghanni_Physical_Simulation_Layer_for_Accurate_3D_Modeling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mezghanni_Physical_Simulation_Layer_for_Accurate_3D_Modeling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mezghanni_Physical_Simulation_Layer_CVPR_2022_supplemental.pdf)
1266. Probabilistic Representations for Video Contrastive Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Park_Probabilistic_Representations_for_Video_Contrastive_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Probabilistic_Representations_for_Video_Contrastive_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Park_Probabilistic_Representations_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03946)
1267. EnvEdit- Environment Editing for Vision-and-Language Navigation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_EnvEdit_Environment_Editing_for_Vision-and-Language_Navigation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_EnvEdit_Environment_Editing_for_Vision-and-Language_Navigation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_EnvEdit_Environment_Editing_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15685)
1268. Neural Shape Mating- Self-Supervised Object Assembly With Adversarial Shape Priors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Neural_Shape_Mating_Self-Supervised_Object_Assembly_With_Adversarial_Shape_Priors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Neural_Shape_Mating_Self-Supervised_Object_Assembly_With_Adversarial_Shape_Priors_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.14886)
1269. DECORE- Deep Compression With Reinforcement Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Alwani_DECORE_Deep_Compression_With_Reinforcement_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Alwani_DECORE_Deep_Compression_With_Reinforcement_Learning_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2106.06091)
1270. Open-Domain, Content-Based, Multi-Modal Fact-Checking of Out-of-Context Images via Online Resources | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Abdelnabi_Open-Domain_Content-Based_Multi-Modal_Fact-Checking_of_Out-of-Context_Images_via_Online_Resources_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Abdelnabi_Open-Domain_Content-Based_Multi-Modal_Fact-Checking_of_Out-of-Context_Images_via_Online_Resources_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Abdelnabi_Open-Domain_Content-Based_Multi-Modal_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00061)
1271. Masked Feature Prediction for Self-Supervised Visual Pre-Training | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wei_Masked_Feature_Prediction_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Masked_Feature_Prediction_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wei_Masked_Feature_Prediction_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.09133)
1272. Certified Patch Robustness via Smoothed Vision Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Salman_Certified_Patch_Robustness_via_Smoothed_Vision_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Salman_Certified_Patch_Robustness_via_Smoothed_Vision_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Salman_Certified_Patch_Robustness_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.07719)
1273. The Principle of Diversity- Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_The_Principle_of_Diversity_Training_Stronger_Vision_Transformers_Calls_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_The_Principle_of_Diversity_Training_Stronger_Vision_Transformers_Calls_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_The_Principle_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06345)
1274. Active Learning by Feature Mixing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Parvaneh_Active_Learning_by_Feature_Mixing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Parvaneh_Active_Learning_by_Feature_Mixing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Parvaneh_Active_Learning_by_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.07034)
1275. Class-Aware Contrastive Semi-Supervised Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Class-Aware_Contrastive_Semi-Supervised_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Class-Aware_Contrastive_Semi-Supervised_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Class-Aware_Contrastive_Semi-Supervised_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02261)
1276. Debiased Learning From Naturally Imbalanced Pseudo-Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Debiased_Learning_From_Naturally_Imbalanced_Pseudo-Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Debiased_Learning_From_Naturally_Imbalanced_Pseudo-Labels_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2201.01490)
1277. RNNPose- Recurrent 6-DoF Object Pose Refinement With Robust Correspondence Field Estimation and Pose Optimization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_RNNPose_Recurrent_6-DoF_Object_Pose_Refinement_With_Robust_Correspondence_Field_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_RNNPose_Recurrent_6-DoF_Object_Pose_Refinement_With_Robust_Correspondence_Field_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_RNNPose_Recurrent_6-DoF_CVPR_2022_supplemental.pdf)
1278. Towards Efficient Data Free Black-Box Adversarial Attack | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Towards_Efficient_Data_Free_Black-Box_Adversarial_Attack_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Towards_Efficient_Data_Free_Black-Box_Adversarial_Attack_CVPR_2022_paper.pdf)
1279. Depth-Supervised NeRF- Fewer Views and Faster Training for Free | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Deng_Depth-Supervised_NeRF_Fewer_Views_and_Faster_Training_for_Free_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_Depth-Supervised_NeRF_Fewer_Views_and_Faster_Training_for_Free_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2107.02791)
1280. Differentiable Dynamics for Articulated 3D Human Motion Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gartner_Differentiable_Dynamics_for_Articulated_3D_Human_Motion_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gartner_Differentiable_Dynamics_for_Articulated_3D_Human_Motion_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gartner_Differentiable_Dynamics_for_CVPR_2022_supplemental.pdf)
1281. GOAL- Generating 4D Whole-Body Motion for Hand-Object Grasping | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Taheri_GOAL_Generating_4D_Whole-Body_Motion_for_Hand-Object_Grasping_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Taheri_GOAL_Generating_4D_Whole-Body_Motion_for_Hand-Object_Grasping_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Taheri_GOAL_Generating_4D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.11454)
1282. Multi-Robot Active Mapping via Neural Bipartite Graph Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Multi-Robot_Active_Mapping_via_Neural_Bipartite_Graph_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Multi-Robot_Active_Mapping_via_Neural_Bipartite_Graph_Matching_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_Multi-Robot_Active_Mapping_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16319)
1283. Adversarial Texture for Fooling Person Detectors in the Physical World | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Adversarial_Texture_for_Fooling_Person_Detectors_in_the_Physical_World_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Adversarial_Texture_for_Fooling_Person_Detectors_in_the_Physical_World_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_Adversarial_Texture_for_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.03373)
1284. TO-FLOW- Efficient Continuous Normalizing Flows With Temporal Optimization Adjoint With Moving Speed | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Du_TO-FLOW_Efficient_Continuous_Normalizing_Flows_With_Temporal_Optimization_Adjoint_With_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Du_TO-FLOW_Efficient_Continuous_Normalizing_Flows_With_Temporal_Optimization_Adjoint_With_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Du_TO-FLOW_Efficient_Continuous_CVPR_2022_supplemental.pdf)
1285. Arbitrary-Scale Image Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ntavelis_Arbitrary-Scale_Image_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ntavelis_Arbitrary-Scale_Image_Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ntavelis_Arbitrary-Scale_Image_Synthesis_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.02273)
1286. Retrieval-Based Spatially Adaptive Normalization for Semantic Image Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_Retrieval-Based_Spatially_Adaptive_Normalization_for_Semantic_Image_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Retrieval-Based_Spatially_Adaptive_Normalization_for_Semantic_Image_Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shi_Retrieval-Based_Spatially_Adaptive_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02854)
1287. Primitive3D- 3D Object Dataset Synthesis From Randomly Assembled Primitives | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Primitive3D_3D_Object_Dataset_Synthesis_From_Randomly_Assembled_Primitives_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Primitive3D_3D_Object_Dataset_Synthesis_From_Randomly_Assembled_Primitives_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Primitive3D_3D_Object_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.12627)
1288. FisherMatch- Semi-Supervised Rotation Regression via Entropy-Based Filtering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yin_FisherMatch_Semi-Supervised_Rotation_Regression_via_Entropy-Based_Filtering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_FisherMatch_Semi-Supervised_Rotation_Regression_via_Entropy-Based_Filtering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yin_FisherMatch_Semi-Supervised_Rotation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15765)
1289. NPBG++- Accelerating Neural Point-Based Graphics | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rakhimov_NPBG_Accelerating_Neural_Point-Based_Graphics_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rakhimov_NPBG_Accelerating_Neural_Point-Based_Graphics_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rakhimov_NPBG_Accelerating_Neural_CVPR_2022_supplemental.pdf)
1290. Panoptic-PHNet- Towards Real-Time and High-Precision LiDAR Panoptic Segmentation via Clustering Pseudo Heatmap | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Panoptic-PHNet_Towards_Real-Time_and_High-Precision_LiDAR_Panoptic_Segmentation_via_Clustering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Panoptic-PHNet_Towards_Real-Time_and_High-Precision_LiDAR_Panoptic_Segmentation_via_Clustering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Panoptic-PHNet_Towards_Real-Time_CVPR_2022_supplemental.pdf)
1291. Dual-Key Multimodal Backdoors for Visual Question Answering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Walmer_Dual-Key_Multimodal_Backdoors_for_Visual_Question_Answering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Walmer_Dual-Key_Multimodal_Backdoors_for_Visual_Question_Answering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Walmer_Dual-Key_Multimodal_Backdoors_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.07668)
1292. STRPM- A Spatiotemporal Residual Predictive Model for High-Resolution Video Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chang_STRPM_A_Spatiotemporal_Residual_Predictive_Model_for_High-Resolution_Video_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_STRPM_A_Spatiotemporal_Residual_Predictive_Model_for_High-Resolution_Video_Prediction_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16084)
1293. Learning From Untrimmed Videos- Self-Supervised Video Representation Learning With Hierarchical Consistency | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qing_Learning_From_Untrimmed_Videos_Self-Supervised_Video_Representation_Learning_With_Hierarchical_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qing_Learning_From_Untrimmed_Videos_Self-Supervised_Video_Representation_Learning_With_Hierarchical_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Qing_Learning_From_Untrimmed_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03017)
1294. Large Loss Matters in Weakly Supervised Multi-Label Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Large_Loss_Matters_in_Weakly_Supervised_Multi-Label_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Large_Loss_Matters_in_Weakly_Supervised_Multi-Label_Classification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Large_Loss_Matters_CVPR_2022_supplemental.pdf)
1295. Attention Concatenation Volume for Accurate and Efficient Stereo Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Attention_Concatenation_Volume_for_Accurate_and_Efficient_Stereo_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Attention_Concatenation_Volume_for_Accurate_and_Efficient_Stereo_Matching_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.02146)
1296. Zero-Query Transfer Attacks on Context-Aware Object Detectors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cai_Zero-Query_Transfer_Attacks_on_Context-Aware_Object_Detectors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Zero-Query_Transfer_Attacks_on_Context-Aware_Object_Detectors_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cai_Zero-Query_Transfer_Attacks_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15230)
1297. GraftNet- Towards Domain Generalized Stereo Matching With a Broad-Spectrum and Task-Oriented Feature | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_GraftNet_Towards_Domain_Generalized_Stereo_Matching_With_a_Broad-Spectrum_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_GraftNet_Towards_Domain_Generalized_Stereo_Matching_With_a_Broad-Spectrum_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_GraftNet_Towards_Domain_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00179)
1298. Towards Total Recall in Industrial Anomaly Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Roth_Towards_Total_Recall_in_Industrial_Anomaly_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Roth_Towards_Total_Recall_in_Industrial_Anomaly_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Roth_Towards_Total_Recall_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.08265)
1299. DTA- Physical Camouflage Attacks Using Differentiable Transformation Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Suryanto_DTA_Physical_Camouflage_Attacks_Using_Differentiable_Transformation_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Suryanto_DTA_Physical_Camouflage_Attacks_Using_Differentiable_Transformation_Network_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Suryanto_DTA_Physical_Camouflage_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09831)
1300. Active Teacher for Semi-Supervised Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mi_Active_Teacher_for_Semi-Supervised_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mi_Active_Teacher_for_Semi-Supervised_Object_Detection_CVPR_2022_paper.pdf)
1301. Audio-Adaptive Activity Recognition Across Video Domains | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Audio-Adaptive_Activity_Recognition_Across_Video_Domains_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Audio-Adaptive_Activity_Recognition_Across_Video_Domains_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Audio-Adaptive_Activity_Recognition_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14240)
1302. Merry Go Round- Rotate a Frame and Fool a DNN | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Thapar_Merry_Go_Round_Rotate_a_Frame_and_Fool_a_DNN_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Thapar_Merry_Go_Round_Rotate_a_Frame_and_Fool_a_DNN_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Thapar_Merry_Go_Round_CVPR_2022_supplemental.zip)
1303. H2FA R-CNN- Holistic and Hierarchical Feature Alignment for Cross-Domain Weakly Supervised Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_H2FA_R-CNN_Holistic_and_Hierarchical_Feature_Alignment_for_Cross-Domain_Weakly_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_H2FA_R-CNN_Holistic_and_Hierarchical_Feature_Alignment_for_Cross-Domain_Weakly_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_H2FA_R-CNN_Holistic_CVPR_2022_supplemental.pdf)
1304. A ConvNet for the 2020s | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_A_ConvNet_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.03545)
1305. Deep Anomaly Discovery From Unlabeled Videos via Normality Advantage and Self-Paced Refinement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Deep_Anomaly_Discovery_From_Unlabeled_Videos_via_Normality_Advantage_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Deep_Anomaly_Discovery_From_Unlabeled_Videos_via_Normality_Advantage_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_Deep_Anomaly_Discovery_CVPR_2022_supplemental.pdf)
1306. Proactive Image Manipulation Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Asnani_Proactive_Image_Manipulation_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Asnani_Proactive_Image_Manipulation_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Asnani_Proactive_Image_Manipulation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15880)
1307. StyTr2- Image Style Transfer With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Deng_StyTr2_Image_Style_Transfer_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_StyTr2_Image_Style_Transfer_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Deng_StyTr2_Image_Style_CVPR_2022_supplemental.pdf)
1308. GreedyNASv2- Greedier Search With a Greedy Path Filter | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_GreedyNASv2_Greedier_Search_With_a_Greedy_Path_Filter_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_GreedyNASv2_Greedier_Search_With_a_Greedy_Path_Filter_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_GreedyNASv2_Greedier_Search_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12609)
1309. BEVT- BERT Pretraining of Video Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_BEVT_BERT_Pretraining_of_Video_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_BEVT_BERT_Pretraining_of_Video_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_BEVT_BERT_Pretraining_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01529)
1310. Automatic Relation-Aware Graph Network Proliferation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cai_Automatic_Relation-Aware_Graph_Network_Proliferation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Automatic_Relation-Aware_Graph_Network_Proliferation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cai_Automatic_Relation-Aware_Graph_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.15678)
1311. Contextual Instance Decoupling for Robust Multi-Person Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Contextual_Instance_Decoupling_for_Robust_Multi-Person_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Contextual_Instance_Decoupling_for_Robust_Multi-Person_Pose_Estimation_CVPR_2022_paper.pdf)
1312. A Simple Data Mixing Prior for Improving Self-Supervised Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_A_Simple_Data_Mixing_Prior_for_Improving_Self-Supervised_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_A_Simple_Data_Mixing_Prior_for_Improving_Self-Supervised_Learning_CVPR_2022_paper.pdf)
1313. Multi-Modal Alignment Using Representation Codebook | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Duan_Multi-Modal_Alignment_Using_Representation_Codebook_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_Multi-Modal_Alignment_Using_Representation_Codebook_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.00048)
1314. HARA- A Hierarchical Approach for Robust Rotation Averaging | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_HARA_A_Hierarchical_Approach_for_Robust_Rotation_Averaging_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_HARA_A_Hierarchical_Approach_for_Robust_Rotation_Averaging_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_HARA_A_Hierarchical_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.08831)
1315. Diffusion Autoencoders- Toward a Meaningful and Decodable Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Preechakul_Diffusion_Autoencoders_Toward_a_Meaningful_and_Decodable_Representation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Preechakul_Diffusion_Autoencoders_Toward_a_Meaningful_and_Decodable_Representation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Preechakul_Diffusion_Autoencoders_Toward_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15640)
1316. Knowledge Distillation With the Reused Teacher Classifier | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Knowledge_Distillation_With_the_Reused_Teacher_Classifier_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Knowledge_Distillation_With_the_Reused_Teacher_Classifier_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Knowledge_Distillation_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14001)
1317. Contrastive Learning for Unsupervised Video Highlight Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Badamdorj_Contrastive_Learning_for_Unsupervised_Video_Highlight_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Badamdorj_Contrastive_Learning_for_Unsupervised_Video_Highlight_Detection_CVPR_2022_paper.pdf)
1318. MetaFSCIL- A Meta-Learning Approach for Few-Shot Class Incremental Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chi_MetaFSCIL_A_Meta-Learning_Approach_for_Few-Shot_Class_Incremental_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chi_MetaFSCIL_A_Meta-Learning_Approach_for_Few-Shot_Class_Incremental_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chi_MetaFSCIL_A_Meta-Learning_CVPR_2022_supplemental.pdf)
1319. Dense Depth Priors for Neural Radiance Fields From Sparse Input Views | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Roessle_Dense_Depth_Priors_for_Neural_Radiance_Fields_From_Sparse_Input_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Roessle_Dense_Depth_Priors_for_Neural_Radiance_Fields_From_Sparse_Input_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Roessle_Dense_Depth_Priors_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.03288)
1320. Camera Pose Estimation Using Implicit Distortion Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pan_Camera_Pose_Estimation_Using_Implicit_Distortion_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Camera_Pose_Estimation_Using_Implicit_Distortion_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Pan_Camera_Pose_Estimation_CVPR_2022_supplemental.pdf)
1321. Shape-Invariant 3D Adversarial Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Shape-Invariant_3D_Adversarial_Point_Clouds_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Shape-Invariant_3D_Adversarial_Point_Clouds_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Shape-Invariant_3D_Adversarial_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04041)
1322. LAS-AT- Adversarial Training With Learnable Attack Strategy | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jia_LAS-AT_Adversarial_Training_With_Learnable_Attack_Strategy_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_LAS-AT_Adversarial_Training_With_Learnable_Attack_Strategy_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jia_LAS-AT_Adversarial_Training_CVPR_2022_supplemental.pdf)
1323. ELSR- Efficient Line Segment Reconstruction With Planes and Points Guidance | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wei_ELSR_Efficient_Line_Segment_Reconstruction_With_Planes_and_Points_Guidance_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_ELSR_Efficient_Line_Segment_Reconstruction_With_Planes_and_Points_Guidance_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wei_ELSR_Efficient_Line_CVPR_2022_supplemental.pdf)
1324. DST- Dynamic Substitute Training for Data-Free Black-Box Attack | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_DST_Dynamic_Substitute_Training_for_Data-Free_Black-Box_Attack_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_DST_Dynamic_Substitute_Training_for_Data-Free_Black-Box_Attack_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.00972)
1325. Unsupervised Pre-Training for Temporal Action Localization Tasks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Unsupervised_Pre-Training_for_Temporal_Action_Localization_Tasks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Unsupervised_Pre-Training_for_Temporal_Action_Localization_Tasks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Unsupervised_Pre-Training_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13609)
1326. Come-Closer-Diffuse-Faster- Accelerating Conditional Diffusion Models for Inverse Problems Through Stochastic Contraction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chung_Come-Closer-Diffuse-Faster_Accelerating_Conditional_Diffusion_Models_for_Inverse_Problems_Through_Stochastic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chung_Come-Closer-Diffuse-Faster_Accelerating_Conditional_Diffusion_Models_for_Inverse_Problems_Through_Stochastic_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chung_Come-Closer-Diffuse-Faster_Accelerating_Conditional_CVPR_2022_supplemental.pdf)
1327. Smooth-Swap- A Simple Enhancement for Face-Swapping With Smoothness | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Smooth-Swap_A_Simple_Enhancement_for_Face-Swapping_With_Smoothness_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Smooth-Swap_A_Simple_Enhancement_for_Face-Swapping_With_Smoothness_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Smooth-Swap_A_Simple_CVPR_2022_supplemental.pdf)
1328. High-Fidelity Human Avatars From a Single RGB Camera | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_High-Fidelity_Human_Avatars_From_a_Single_RGB_Camera_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_High-Fidelity_Human_Avatars_From_a_Single_RGB_Camera_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_High-Fidelity_Human_Avatars_CVPR_2022_supplemental.pdf)
1329. ADAPT- Vision-Language Navigation With Modality-Aligned Action Prompts | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_ADAPT_Vision-Language_Navigation_With_Modality-Aligned_Action_Prompts_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_ADAPT_Vision-Language_Navigation_With_Modality-Aligned_Action_Prompts_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_ADAPT_Vision-Language_Navigation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.15509)
1330. Automated Progressive Learning for Efficient Training of Vision Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Automated_Progressive_Learning_for_Efficient_Training_of_Vision_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Automated_Progressive_Learning_for_Efficient_Training_of_Vision_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Automated_Progressive_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14509)
1331. Single-Stage Is Enough- Multi-Person Absolute 3D Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jin_Single-Stage_Is_Enough_Multi-Person_Absolute_3D_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Single-Stage_Is_Enough_Multi-Person_Absolute_3D_Pose_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jin_Single-Stage_Is_Enough_CVPR_2022_supplemental.pdf)
1332. MulT- An End-to-End Multitask Learning Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bhattacharjee_MulT_An_End-to-End_Multitask_Learning_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bhattacharjee_MulT_An_End-to-End_Multitask_Learning_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bhattacharjee_MulT_An_End-to-End_CVPR_2022_supplemental.pdf)
1333. DeeCap- Dynamic Early Exiting for Efficient Image Captioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fei_DeeCap_Dynamic_Early_Exiting_for_Efficient_Image_Captioning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fei_DeeCap_Dynamic_Early_Exiting_for_Efficient_Image_Captioning_CVPR_2022_paper.pdf)
1334. Semi-Supervised Few-Shot Learning via Multi-Factor Clustering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ling_Semi-Supervised_Few-Shot_Learning_via_Multi-Factor_Clustering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ling_Semi-Supervised_Few-Shot_Learning_via_Multi-Factor_Clustering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ling_Semi-Supervised_Few-Shot_Learning_CVPR_2022_supplemental.pdf)
1335. Weakly-Supervised Generation and Grounding of Visual Descriptions With Conditional Generative Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mavroudi_Weakly-Supervised_Generation_and_Grounding_of_Visual_Descriptions_With_Conditional_Generative_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mavroudi_Weakly-Supervised_Generation_and_Grounding_of_Visual_Descriptions_With_Conditional_Generative_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mavroudi_Weakly-Supervised_Generation_and_CVPR_2022_supplemental.pdf)
1336. ARCS- Accurate Rotation and Correspondence Search | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Peng_ARCS_Accurate_Rotation_and_Correspondence_Search_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_ARCS_Accurate_Rotation_and_Correspondence_Search_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Peng_ARCS_Accurate_Rotation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14493)
1337. Learning To Anticipate Future With Dynamic Context Removal | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Learning_To_Anticipate_Future_With_Dynamic_Context_Removal_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Learning_To_Anticipate_Future_With_Dynamic_Context_Removal_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Learning_To_Anticipate_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02587)
1338. Perception Prioritized Training of Diffusion Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Choi_Perception_Prioritized_Training_of_Diffusion_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Choi_Perception_Prioritized_Training_of_Diffusion_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Choi_Perception_Prioritized_Training_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00227)
1339. CHEX- CHannel EXploration for CNN Model Compression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hou_CHEX_CHannel_EXploration_for_CNN_Model_Compression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_CHEX_CHannel_EXploration_for_CNN_Model_Compression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hou_CHEX_CHannel_EXploration_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15794)
1340. Generalizable Human Pose Triangulation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bartol_Generalizable_Human_Pose_Triangulation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bartol_Generalizable_Human_Pose_Triangulation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bartol_Generalizable_Human_Pose_CVPR_2022_supplemental.pdf)
1341. BppAttack- Stealthy and Efficient Trojan Attacks Against Deep Neural Networks via Image Quantization and Contrastive Adversarial Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_BppAttack_Stealthy_and_Efficient_Trojan_Attacks_Against_Deep_Neural_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_BppAttack_Stealthy_and_Efficient_Trojan_Attacks_Against_Deep_Neural_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_BppAttack_Stealthy_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.13383)
1342. Ensembling Off-the-Shelf Models for GAN Training | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kumari_Ensembling_Off-the-Shelf_Models_for_GAN_Training_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kumari_Ensembling_Off-the-Shelf_Models_for_GAN_Training_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.09130)
1343. Segment and Complete- Defending Object Detectors Against Adversarial Patch Attacks With Robust Patch Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Segment_and_Complete_Defending_Object_Detectors_Against_Adversarial_Patch_Attacks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Segment_and_Complete_Defending_Object_Detectors_Against_Adversarial_Patch_Attacks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Segment_and_Complete_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.04532)
1344. A Deeper Dive Into What Deep Spatiotemporal Networks Encode- Quantifying Static vs. Dynamic Information | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kowal_A_Deeper_Dive_Into_What_Deep_Spatiotemporal_Networks_Encode_Quantifying_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kowal_A_Deeper_Dive_Into_What_Deep_Spatiotemporal_Networks_Encode_Quantifying_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kowal_A_Deeper_Dive_CVPR_2022_supplemental.zip)
1345. Style Transformer for Image Inversion and Editing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Style_Transformer_for_Image_Inversion_and_Editing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Style_Transformer_for_Image_Inversion_and_Editing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_Style_Transformer_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.07932)
1346. Pyramid Adversarial Training Improves ViT Performance | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Herrmann_Pyramid_Adversarial_Training_Improves_ViT_Performance_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Herrmann_Pyramid_Adversarial_Training_Improves_ViT_Performance_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Herrmann_Pyramid_Adversarial_Training_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15121)
1347. Bridging Global Context Interactions for High-Fidelity Image Completion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Bridging_Global_Context_Interactions_for_High-Fidelity_Image_Completion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Bridging_Global_Context_Interactions_for_High-Fidelity_Image_Completion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_Bridging_Global_Context_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.00845)
1348. InfoNeRF- Ray Entropy Minimization for Few-Shot Neural Volume Rendering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_InfoNeRF_Ray_Entropy_Minimization_for_Few-Shot_Neural_Volume_Rendering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_InfoNeRF_Ray_Entropy_Minimization_for_Few-Shot_Neural_Volume_Rendering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_InfoNeRF_Ray_Entropy_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.15399)
1349. Dist-PU- Positive-Unlabeled Learning From a Label Distribution Perspective | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Dist-PU_Positive-Unlabeled_Learning_From_a_Label_Distribution_Perspective_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Dist-PU_Positive-Unlabeled_Learning_From_a_Label_Distribution_Perspective_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_Dist-PU_Positive-Unlabeled_Learning_CVPR_2022_supplemental.pdf)
1350. SC2-PCR- A Second Order Spatial Compatibility for Efficient and Robust Point Cloud Registration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_SC2-PCR_A_Second_Order_Spatial_Compatibility_for_Efficient_and_Robust_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_SC2-PCR_A_Second_Order_Spatial_Compatibility_for_Efficient_and_Robust_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_SC2-PCR_A_Second_CVPR_2022_supplemental.pdf)
1351. Relative Pose From a Calibrated and an Uncalibrated Smartphone Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Relative_Pose_From_a_Calibrated_and_an_Uncalibrated_Smartphone_Image_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Relative_Pose_From_a_Calibrated_and_an_Uncalibrated_Smartphone_Image_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ding_Relative_Pose_From_CVPR_2022_supplemental.pdf)
1352. Not All Tokens Are Equal- Human-Centric Visual Analysis via Token Clustering Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zeng_Not_All_Tokens_Are_Equal_Human-Centric_Visual_Analysis_via_Token_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_Not_All_Tokens_Are_Equal_Human-Centric_Visual_Analysis_via_Token_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zeng_Not_All_Tokens_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.08680)
1353. Sound and Visual Representation Learning With Multiple Pretraining Tasks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Vasudevan_Sound_and_Visual_Representation_Learning_With_Multiple_Pretraining_Tasks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Vasudevan_Sound_and_Visual_Representation_Learning_With_Multiple_Pretraining_Tasks_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2201.01046)
1354. RePaint- Inpainting Using Denoising Diffusion Probabilistic Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lugmayr_RePaint_Inpainting_Using_Denoising_Diffusion_Probabilistic_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lugmayr_RePaint_Inpainting_Using_Denoising_Diffusion_Probabilistic_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lugmayr_RePaint_Inpainting_Using_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.09865)
1355. Meta Agent Teaming Active Learning for Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gong_Meta_Agent_Teaming_Active_Learning_for_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_Meta_Agent_Teaming_Active_Learning_for_Pose_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gong_Meta_Agent_Teaming_CVPR_2022_supplemental.pdf)
1356. Pseudo-Q- Generating Pseudo Language Queries for Visual Grounding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Pseudo-Q_Generating_Pseudo_Language_Queries_for_Visual_Grounding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Pseudo-Q_Generating_Pseudo_Language_Queries_for_Visual_Grounding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jiang_Pseudo-Q_Generating_Pseudo_CVPR_2022_supplemental.pdf)
1357. Towards Discovering the Effectiveness of Moderately Confident Samples for Semi-Supervised Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Towards_Discovering_the_Effectiveness_of_Moderately_Confident_Samples_for_Semi-Supervised_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Towards_Discovering_the_Effectiveness_of_Moderately_Confident_Samples_for_Semi-Supervised_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_Towards_Discovering_the_CVPR_2022_supplemental.pdf)
1358. The Neurally-Guided Shape Parser- Grammar-Based Labeling of 3D Shape Regions With Approximate Inference | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jones_The_Neurally-Guided_Shape_Parser_Grammar-Based_Labeling_of_3D_Shape_Regions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jones_The_Neurally-Guided_Shape_Parser_Grammar-Based_Labeling_of_3D_Shape_Regions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jones_The_Neurally-Guided_Shape_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.12026)
1359. Weakly-Supervised Online Action Segmentation in Multi-View Instructional Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ghoddoosian_Weakly-Supervised_Online_Action_Segmentation_in_Multi-View_Instructional_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ghoddoosian_Weakly-Supervised_Online_Action_Segmentation_in_Multi-View_Instructional_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ghoddoosian_Weakly-Supervised_Online_Action_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13309)
1360. Disentangling Visual Embeddings for Attributes and Objects | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Saini_Disentangling_Visual_Embeddings_for_Attributes_and_Objects_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Saini_Disentangling_Visual_Embeddings_for_Attributes_and_Objects_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Saini_Disentangling_Visual_Embeddings_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.08536)
1361. MiniViT- Compressing Vision Transformers With Weight Multiplexing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_MiniViT_Compressing_Vision_Transformers_With_Weight_Multiplexing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_MiniViT_Compressing_Vision_Transformers_With_Weight_Multiplexing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_MiniViT_Compressing_Vision_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07154)
1362. Weakly Supervised Segmentation on Outdoor 4D Point Clouds With Temporal Matching and Spatial Graph Propagation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_Weakly_Supervised_Segmentation_on_Outdoor_4D_Point_Clouds_With_Temporal_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Weakly_Supervised_Segmentation_on_Outdoor_4D_Point_Clouds_With_Temporal_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shi_Weakly_Supervised_Segmentation_CVPR_2022_supplemental.pdf)
1363. NeurMiPs- Neural Mixture of Planar Experts for View Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_NeurMiPs_Neural_Mixture_of_Planar_Experts_for_View_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_NeurMiPs_Neural_Mixture_of_Planar_Experts_for_View_Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_NeurMiPs_Neural_Mixture_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.13696)
1364. SplitNets- Designing Neural Architectures for Efficient Distributed Computing on Head-Mounted Systems | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_SplitNets_Designing_Neural_Architectures_for_Efficient_Distributed_Computing_on_Head-Mounted_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_SplitNets_Designing_Neural_Architectures_for_Efficient_Distributed_Computing_on_Head-Mounted_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_SplitNets_Designing_Neural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04705)
1365. Boosting Robustness of Image Matting With Context Assembling and Strong Data Augmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dai_Boosting_Robustness_of_Image_Matting_With_Context_Assembling_and_Strong_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_Boosting_Robustness_of_Image_Matting_With_Context_Assembling_and_Strong_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dai_Boosting_Robustness_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.06889)
1366. Self-Supervised Spatial Reasoning on Multi-View Line Drawings | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xiang_Self-Supervised_Spatial_Reasoning_on_Multi-View_Line_Drawings_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xiang_Self-Supervised_Spatial_Reasoning_on_Multi-View_Line_Drawings_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xiang_Self-Supervised_Spatial_Reasoning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.13433)
1367. Cross-Patch Dense Contrastive Learning for Semi-Supervised Segmentation of Cellular Nuclei in Histopathologic Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Cross-Patch_Dense_Contrastive_Learning_for_Semi-Supervised_Segmentation_of_Cellular_Nuclei_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Cross-Patch_Dense_Contrastive_Learning_for_Semi-Supervised_Segmentation_of_Cellular_Nuclei_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Cross-Patch_Dense_Contrastive_CVPR_2022_supplemental.pdf)
1368. Frame-Wise Action Representations for Long Videos via Sequence Contrastive Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Frame-Wise_Action_Representations_for_Long_Videos_via_Sequence_Contrastive_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Frame-Wise_Action_Representations_for_Long_Videos_via_Sequence_Contrastive_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Frame-Wise_Action_Representations_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.14957)
1369. Generalized Binary Search Network for Highly-Efficient Multi-View Stereo | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mi_Generalized_Binary_Search_Network_for_Highly-Efficient_Multi-View_Stereo_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mi_Generalized_Binary_Search_Network_for_Highly-Efficient_Multi-View_Stereo_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mi_Generalized_Binary_Search_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02338)
1370. Mega-NERF- Scalable Construction of Large-Scale NeRFs for Virtual Fly-Throughs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Turki_Mega-NERF_Scalable_Construction_of_Large-Scale_NeRFs_for_Virtual_Fly-Throughs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Turki_Mega-NERF_Scalable_Construction_of_Large-Scale_NeRFs_for_Virtual_Fly-Throughs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Turki_Mega-NERF_Scalable_Construction_CVPR_2022_supplemental.pdf)
1371. Adversarial Eigen Attack on Black-Box Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Adversarial_Eigen_Attack_on_Black-Box_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Adversarial_Eigen_Attack_on_Black-Box_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Adversarial_Eigen_Attack_CVPR_2022_supplemental.pdf)
1372. Cloth-Changing Person Re-Identification From a Single Image With Gait Prediction and Regularization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jin_Cloth-Changing_Person_Re-Identification_From_a_Single_Image_With_Gait_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Cloth-Changing_Person_Re-Identification_From_a_Single_Image_With_Gait_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jin_Cloth-Changing_Person_Re-Identification_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2103.15537)
1373. Neural Architecture Search With Representation Mutual Information | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Neural_Architecture_Search_With_Representation_Mutual_Information_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Neural_Architecture_Search_With_Representation_Mutual_Information_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_Neural_Architecture_Search_CVPR_2022_supplemental.pdf)
1374. Can Neural Nets Learn the Same Model Twice- Investigating Reproducibility and Double Descent From the Decision Boundary Perspective | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Somepalli_Can_Neural_Nets_Learn_the_Same_Model_Twice_Investigating_Reproducibility_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Somepalli_Can_Neural_Nets_Learn_the_Same_Model_Twice_Investigating_Reproducibility_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Somepalli_Can_Neural_Nets_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08124)
1375. Multi-View Transformer for 3D Visual Grounding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Multi-View_Transformer_for_3D_Visual_Grounding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Multi-View_Transformer_for_3D_Visual_Grounding_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.02174)
1376. Continual Predictive Learning From Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Continual_Predictive_Learning_From_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Continual_Predictive_Learning_From_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Continual_Predictive_Learning_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.05624)
1377. Knowledge Distillation- A Good Teacher Is Patient and Consistent | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Beyer_Knowledge_Distillation_A_Good_Teacher_Is_Patient_and_Consistent_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Beyer_Knowledge_Distillation_A_Good_Teacher_Is_Patient_and_Consistent_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Beyer_Knowledge_Distillation_A_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.05237)
1378. Training High-Performance Low-Latency Spiking Neural Networks by Differentiation on Spike Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Meng_Training_High-Performance_Low-Latency_Spiking_Neural_Networks_by_Differentiation_on_Spike_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_Training_High-Performance_Low-Latency_Spiking_Neural_Networks_by_Differentiation_on_Spike_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Meng_Training_High-Performance_Low-Latency_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.00459)
1379. Lifelong Graph Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Lifelong_Graph_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Lifelong_Graph_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Lifelong_Graph_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2009.00647)
1380. Towards Practical Certifiable Patch Defense With Vision Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Towards_Practical_Certifiable_Patch_Defense_With_Vision_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Towards_Practical_Certifiable_Patch_Defense_With_Vision_Transformer_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.08519)
1381. Label, Verify, Correct- A Simple Few Shot Object Detection Method | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kaul_Label_Verify_Correct_A_Simple_Few_Shot_Object_Detection_Method_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kaul_Label_Verify_Correct_A_Simple_Few_Shot_Object_Detection_Method_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.05749)
1382. Autoregressive Image Generation Using Residual Quantization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Autoregressive_Image_Generation_Using_Residual_Quantization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Autoregressive_Image_Generation_Using_Residual_Quantization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Autoregressive_Image_Generation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01941)
1383. End-to-End Compressed Video Representation Learning for Generic Event Boundary Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_End-to-End_Compressed_Video_Representation_Learning_for_Generic_Event_Boundary_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_End-to-End_Compressed_Video_Representation_Learning_for_Generic_Event_Boundary_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.15336)
1384. TeachAugment- Data Augmentation Optimization Using Teacher Knowledge | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Suzuki_TeachAugment_Data_Augmentation_Optimization_Using_Teacher_Knowledge_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Suzuki_TeachAugment_Data_Augmentation_Optimization_Using_Teacher_Knowledge_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Suzuki_TeachAugment_Data_Augmentation_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2202.12513)
1385. Weakly Supervised Temporal Sentence Grounding With Gaussian-Based Contrastive Proposal Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Weakly_Supervised_Temporal_Sentence_Grounding_With_Gaussian-Based_Contrastive_Proposal_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Weakly_Supervised_Temporal_Sentence_Grounding_With_Gaussian-Based_Contrastive_Proposal_Learning_CVPR_2022_paper.pdf)
1386. Task-Specific Inconsistency Alignment for Domain Adaptive Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Task-Specific_Inconsistency_Alignment_for_Domain_Adaptive_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Task-Specific_Inconsistency_Alignment_for_Domain_Adaptive_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_Task-Specific_Inconsistency_Alignment_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15345)
1387. Capturing Humans in Motion- Temporal-Attentive 3D Human Pose and Shape Estimation From Monocular Video | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wei_Capturing_Humans_in_Motion_Temporal-Attentive_3D_Human_Pose_and_Shape_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Capturing_Humans_in_Motion_Temporal-Attentive_3D_Human_Pose_and_Shape_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wei_Capturing_Humans_in_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08534)
1388. MixFormer- End-to-End Tracking With Iterative Mixed Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cui_MixFormer_End-to-End_Tracking_With_Iterative_Mixed_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cui_MixFormer_End-to-End_Tracking_With_Iterative_Mixed_Attention_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cui_MixFormer_End-to-End_Tracking_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11082)
1389. InOut- Diverse Image Outpainting via GAN Inversion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_InOut_Diverse_Image_Outpainting_via_GAN_Inversion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_InOut_Diverse_Image_Outpainting_via_GAN_Inversion_CVPR_2022_paper.pdf)
1390. What Matters for Meta-Learning Vision Regression Tasks- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gao_What_Matters_for_Meta-Learning_Vision_Regression_Tasks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_What_Matters_for_Meta-Learning_Vision_Regression_Tasks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gao_What_Matters_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04905)
1391. Interspace Pruning- Using Adaptive Filter Representations To Improve Training of Sparse CNNs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wimmer_Interspace_Pruning_Using_Adaptive_Filter_Representations_To_Improve_Training_of_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wimmer_Interspace_Pruning_Using_Adaptive_Filter_Representations_To_Improve_Training_of_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wimmer_Interspace_Pruning_Using_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.07808)
1392. Frequency-Driven Imperceptible Adversarial Attack on Semantic Similarity | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Luo_Frequency-Driven_Imperceptible_Adversarial_Attack_on_Semantic_Similarity_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Frequency-Driven_Imperceptible_Adversarial_Attack_on_Semantic_Similarity_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Luo_Frequency-Driven_Imperceptible_Adversarial_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05151)
1393. ZZ-Net- A Universal Rotation Equivariant Architecture for 2D Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bokman_ZZ-Net_A_Universal_Rotation_Equivariant_Architecture_for_2D_Point_Clouds_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bokman_ZZ-Net_A_Universal_Rotation_Equivariant_Architecture_for_2D_Point_Clouds_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bokman_ZZ-Net_A_Universal_CVPR_2022_supplemental.pdf)
1394. GRAM- Generative Radiance Manifolds for 3D-Aware Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Deng_GRAM_Generative_Radiance_Manifolds_for_3D-Aware_Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_GRAM_Generative_Radiance_Manifolds_for_3D-Aware_Image_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Deng_GRAM_Generative_Radiance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.08867)
1395. UniVIP- A Unified Framework for Self-Supervised Visual Pre-Training | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_UniVIP_A_Unified_Framework_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_UniVIP_A_Unified_Framework_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.06965)
1396. Decoupling Zero-Shot Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Decoupling_Zero-Shot_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Decoupling_Zero-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ding_Decoupling_Zero-Shot_Semantic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.07910)
1397. Towards Robust Vision Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mao_Towards_Robust_Vision_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mao_Towards_Robust_Vision_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mao_Towards_Robust_Vision_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2105.07926)
1398. Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting the Adversarial Transferability | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xiong_Stochastic_Variance_Reduced_Ensemble_Adversarial_Attack_for_Boosting_the_Adversarial_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xiong_Stochastic_Variance_Reduced_Ensemble_Adversarial_Attack_for_Boosting_the_Adversarial_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xiong_Stochastic_Variance_Reduced_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.10752)
1399. Unknown-Aware Object Detection- Learning What You Don't Know From Videos in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Du_Unknown-Aware_Object_Detection_Learning_What_You_Dont_Know_From_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Unknown-Aware_Object_Detection_Learning_What_You_Dont_Know_From_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Du_Unknown-Aware_Object_Detection_CVPR_2022_supplemental.pdf)
1400. Multi-Modal Extreme Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mittal_Multi-Modal_Extreme_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mittal_Multi-Modal_Extreme_Classification_CVPR_2022_paper.pdf)
1401. IFOR- Iterative Flow Minimization for Robotic Object Rearrangement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Goyal_IFOR_Iterative_Flow_Minimization_for_Robotic_Object_Rearrangement_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Goyal_IFOR_Iterative_Flow_Minimization_for_Robotic_Object_Rearrangement_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Goyal_IFOR_Iterative_Flow_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2202.00732)
1402. Training-Free Transformer Architecture Search | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Training-Free_Transformer_Architecture_Search_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Training-Free_Transformer_Architecture_Search_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Training-Free_Transformer_Architecture_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12217)
1403. TopFormer- Token Pyramid Transformer for Mobile Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_TopFormer_Token_Pyramid_Transformer_for_Mobile_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_TopFormer_Token_Pyramid_Transformer_for_Mobile_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_TopFormer_Token_Pyramid_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.05525)
1404. 3DAC- Learning Attribute Compression for Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fang_3DAC_Learning_Attribute_Compression_for_Point_Clouds_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_3DAC_Learning_Attribute_Compression_for_Point_Clouds_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fang_3DAC_Learning_Attribute_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09931)
1405. Few-Shot Backdoor Defense Using Shapley Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guan_Few-Shot_Backdoor_Defense_Using_Shapley_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Few-Shot_Backdoor_Defense_Using_Shapley_Estimation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.14889)
1406. MixSTE- Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_MixSTE_Seq2seq_Mixed_Spatio-Temporal_Encoder_for_3D_Human_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_MixSTE_Seq2seq_Mixed_Spatio-Temporal_Encoder_for_3D_Human_Pose_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_MixSTE_Seq2seq_Mixed_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.00859)
1407. Safe-Student for Safe Deep Semi-Supervised Learning With Unseen-Class Unlabeled Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_Safe-Student_for_Safe_Deep_Semi-Supervised_Learning_With_Unseen-Class_Unlabeled_Data_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Safe-Student_for_Safe_Deep_Semi-Supervised_Learning_With_Unseen-Class_Unlabeled_Data_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_Safe-Student_for_Safe_CVPR_2022_supplemental.pdf)
1408. High-Fidelity GAN Inversion for Image Attribute Editing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_High-Fidelity_GAN_Inversion_for_Image_Attribute_Editing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_High-Fidelity_GAN_Inversion_for_Image_Attribute_Editing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_High-Fidelity_GAN_Inversion_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2109.06590)
1409. MaskGIT- Masked Generative Image Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chang_MaskGIT_Masked_Generative_Image_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_MaskGIT_Masked_Generative_Image_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chang_MaskGIT_Masked_Generative_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.04200)
1410. Instance-Aware Dynamic Neural Network Quantization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Instance-Aware_Dynamic_Neural_Network_Quantization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Instance-Aware_Dynamic_Neural_Network_Quantization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Instance-Aware_Dynamic_Neural_CVPR_2022_supplemental.pdf)
1411. When To Prune- A Policy Towards Early Structural Pruning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shen_When_To_Prune_A_Policy_Towards_Early_Structural_Pruning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_When_To_Prune_A_Policy_Towards_Early_Structural_Pruning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shen_When_To_Prune_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.12007)
1412. COTS- Collaborative Two-Stream Vision-Language Pre-Training Model for Cross-Modal Retrieval | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lu_COTS_Collaborative_Two-Stream_Vision-Language_Pre-Training_Model_for_Cross-Modal_Retrieval_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_COTS_Collaborative_Two-Stream_Vision-Language_Pre-Training_Model_for_Cross-Modal_Retrieval_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lu_COTS_Collaborative_Two-Stream_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07441)
1413. Exploring Effective Data for Surrogate Training Towards Black-Box Attack | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Exploring_Effective_Data_for_Surrogate_Training_Towards_Black-Box_Attack_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Exploring_Effective_Data_for_Surrogate_Training_Towards_Black-Box_Attack_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sun_Exploring_Effective_Data_CVPR_2022_supplemental.pdf)
1414. Investigating Top-k White-Box and Transferable Black-Box Attack | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Investigating_Top-k_White-Box_and_Transferable_Black-Box_Attack_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Investigating_Top-k_White-Box_and_Transferable_Black-Box_Attack_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Investigating_Top-k_White-Box_CVPR_2022_supplemental.pdf)
1415. A Self-Supervised Descriptor for Image Copy Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pizzi_A_Self-Supervised_Descriptor_for_Image_Copy_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pizzi_A_Self-Supervised_Descriptor_for_Image_Copy_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Pizzi_A_Self-Supervised_Descriptor_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.10261)
1416. Manifold Learning Benefits GANs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ni_Manifold_Learning_Benefits_GANs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ni_Manifold_Learning_Benefits_GANs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ni_Manifold_Learning_Benefits_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.12618)
1417. Negative-Aware Attention Framework for Image-Text Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Negative-Aware_Attention_Framework_for_Image-Text_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Negative-Aware_Attention_Framework_for_Image-Text_Matching_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Negative-Aware_Attention_Framework_CVPR_2022_supplemental.pdf)
1418. An Image Patch Is a Wave- Phase-Aware Vision MLP | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_An_Image_Patch_Is_a_Wave_Phase-Aware_Vision_MLP_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_An_Image_Patch_Is_a_Wave_Phase-Aware_Vision_MLP_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_An_Image_Patch_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12294)
1419. Shunted Self-Attention via Multi-Scale Token Aggregation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Shunted_Self-Attention_via_Multi-Scale_Token_Aggregation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Shunted_Self-Attention_via_Multi-Scale_Token_Aggregation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.15193)
1420. Shadows Can Be Dangerous- Stealthy and Effective Physical-World Adversarial Attack by Natural Phenomenon | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_Shadows_Can_Be_Dangerous_Stealthy_and_Effective_Physical-World_Adversarial_Attack_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Shadows_Can_Be_Dangerous_Stealthy_and_Effective_Physical-World_Adversarial_Attack_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.03818)
1421. ImplicitAtlas- Learning Deformable Shape Templates in Medical Imaging | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_ImplicitAtlas_Learning_Deformable_Shape_Templates_in_Medical_Imaging_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_ImplicitAtlas_Learning_Deformable_Shape_Templates_in_Medical_Imaging_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_ImplicitAtlas_Learning_Deformable_CVPR_2022_supplemental.zip)
1422. Contrastive Learning for Space-Time Correspondence via Self-Cycle Consistency | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Son_Contrastive_Learning_for_Space-Time_Correspondence_via_Self-Cycle_Consistency_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Son_Contrastive_Learning_for_Space-Time_Correspondence_via_Self-Cycle_Consistency_CVPR_2022_paper.pdf)
1423. Scale-Equivalent Distillation for Semi-Supervised Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Scale-Equivalent_Distillation_for_Semi-Supervised_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Scale-Equivalent_Distillation_for_Semi-Supervised_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_Scale-Equivalent_Distillation_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12244)
1424. Attribute Group Editing for Reliable Few-Shot Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Attribute_Group_Editing_for_Reliable_Few-Shot_Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Attribute_Group_Editing_for_Reliable_Few-Shot_Image_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ding_Attribute_Group_Editing_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08422)
1425. Polymorphic-GAN- Generating Aligned Samples Across Multiple Domains With Learned Morph Maps | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Polymorphic-GAN_Generating_Aligned_Samples_Across_Multiple_Domains_With_Learned_Morph_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Polymorphic-GAN_Generating_Aligned_Samples_Across_Multiple_Domains_With_Learned_Morph_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Polymorphic-GAN_Generating_Aligned_CVPR_2022_supplemental.zip)
1426. Appearance and Structure Aware Robust Deep Visual Graph Matching- Attack, Defense and Beyond | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Appearance_and_Structure_Aware_Robust_Deep_Visual_Graph_Matching_Attack_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Appearance_and_Structure_Aware_Robust_Deep_Visual_Graph_Matching_Attack_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ren_Appearance_and_Structure_CVPR_2022_supplemental.pdf)
1427. Feature Statistics Mixing Regularization for Generative Adversarial Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Feature_Statistics_Mixing_Regularization_for_Generative_Adversarial_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Feature_Statistics_Mixing_Regularization_for_Generative_Adversarial_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Feature_Statistics_Mixing_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.04120)
1428. Urban Radiance Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rematas_Urban_Radiance_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rematas_Urban_Radiance_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rematas_Urban_Radiance_Fields_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14643)
1429. Upright-Net- Learning Upright Orientation for 3D Point Cloud | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pang_Upright-Net_Learning_Upright_Orientation_for_3D_Point_Cloud_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pang_Upright-Net_Learning_Upright_Orientation_for_3D_Point_Cloud_CVPR_2022_paper.pdf)
1430. Geometric and Textural Augmentation for Domain Gap Reduction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Geometric_and_Textural_Augmentation_for_Domain_Gap_Reduction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Geometric_and_Textural_Augmentation_for_Domain_Gap_Reduction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Geometric_and_Textural_CVPR_2022_supplemental.pdf)
1431. HybridCR- Weakly-Supervised 3D Point Cloud Semantic Segmentation via Hybrid Contrastive Regularization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_HybridCR_Weakly-Supervised_3D_Point_Cloud_Semantic_Segmentation_via_Hybrid_Contrastive_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_HybridCR_Weakly-Supervised_3D_Point_Cloud_Semantic_Segmentation_via_Hybrid_Contrastive_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_HybridCR_Weakly-Supervised_3D_CVPR_2022_supplemental.pdf)
1432. Fine-Tuning Image Transformers Using Learnable Memory | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sandler_Fine-Tuning_Image_Transformers_Using_Learnable_Memory_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sandler_Fine-Tuning_Image_Transformers_Using_Learnable_Memory_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sandler_Fine-Tuning_Image_Transformers_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15243)
1433. Not All Relations Are Equal- Mining Informative Labels for Scene Graph Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Goel_Not_All_Relations_Are_Equal_Mining_Informative_Labels_for_Scene_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Goel_Not_All_Relations_Are_Equal_Mining_Informative_Labels_for_Scene_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Goel_Not_All_Relations_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13517)
1434. Learning To Detect Scene Landmarks for Camera Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Do_Learning_To_Detect_Scene_Landmarks_for_Camera_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Do_Learning_To_Detect_Scene_Landmarks_for_Camera_Localization_CVPR_2022_paper.pdf)
1435. FashionVLP- Vision Language Transformer for Fashion Retrieval With Feedback | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Goenka_FashionVLP_Vision_Language_Transformer_for_Fashion_Retrieval_With_Feedback_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Goenka_FashionVLP_Vision_Language_Transformer_for_Fashion_Retrieval_With_Feedback_CVPR_2022_paper.pdf)
1436. Cross-Image Relational Knowledge Distillation for Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Cross-Image_Relational_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Cross-Image_Relational_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Cross-Image_Relational_Knowledge_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.06986)
1437. A-ViT- Adaptive Tokens for Efficient Vision Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yin_A-ViT_Adaptive_Tokens_for_Efficient_Vision_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_A-ViT_Adaptive_Tokens_for_Efficient_Vision_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yin_A-ViT_Adaptive_Tokens_CVPR_2022_supplemental.pdf)
1438. Calibrating Deep Neural Networks by Pairwise Constraints | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Calibrating_Deep_Neural_Networks_by_Pairwise_Constraints_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Calibrating_Deep_Neural_Networks_by_Pairwise_Constraints_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cheng_Calibrating_Deep_Neural_CVPR_2022_supplemental.pdf)
1439. Sign Language Video Retrieval With Free-Form Textual Queries | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Duarte_Sign_Language_Video_Retrieval_With_Free-Form_Textual_Queries_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Duarte_Sign_Language_Video_Retrieval_With_Free-Form_Textual_Queries_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Duarte_Sign_Language_Video_CVPR_2022_supplemental.pdf)
1440. VisualHow- Multimodal Problem Solving | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_VisualHow_Multimodal_Problem_Solving_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_VisualHow_Multimodal_Problem_Solving_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_VisualHow_Multimodal_Problem_CVPR_2022_supplemental.pdf)
1441. OSSGAN- Open-Set Semi-Supervised Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Katsumata_OSSGAN_Open-Set_Semi-Supervised_Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Katsumata_OSSGAN_Open-Set_Semi-Supervised_Image_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Katsumata_OSSGAN_Open-Set_Semi-Supervised_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.14249)
1442. Lite Vision Transformer With Enhanced Self-Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Lite_Vision_Transformer_With_Enhanced_Self-Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Lite_Vision_Transformer_With_Enhanced_Self-Attention_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.10809)
1443. NinjaDesc- Content-Concealing Visual Descriptors via Adversarial Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ng_NinjaDesc_Content-Concealing_Visual_Descriptors_via_Adversarial_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ng_NinjaDesc_Content-Concealing_Visual_Descriptors_via_Adversarial_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ng_NinjaDesc_Content-Concealing_Visual_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.12785)
1444. A Graph Matching Perspective With Transformers on Video Instance Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qin_A_Graph_Matching_Perspective_With_Transformers_on_Video_Instance_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qin_A_Graph_Matching_Perspective_With_Transformers_on_Video_Instance_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Qin_A_Graph_Matching_CVPR_2022_supplemental.pdf)
1445. FLAG- Flow-Based 3D Avatar Generation From Sparse Observations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Aliakbarian_FLAG_Flow-Based_3D_Avatar_Generation_From_Sparse_Observations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Aliakbarian_FLAG_Flow-Based_3D_Avatar_Generation_From_Sparse_Observations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Aliakbarian_FLAG_Flow-Based_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05789)
1446. Panoptic Neural Fields- A Semantic Object-Aware Neural Scene Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kundu_Panoptic_Neural_Fields_A_Semantic_Object-Aware_Neural_Scene_Representation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kundu_Panoptic_Neural_Fields_A_Semantic_Object-Aware_Neural_Scene_Representation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.04334)
1447. Decoupled Knowledge Distillation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Decoupled_Knowledge_Distillation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Decoupled_Knowledge_Distillation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_Decoupled_Knowledge_Distillation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08679)
1448. A Sampling-Based Approach for Efficient Clustering in Large Datasets | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Exarchakis_A_Sampling-Based_Approach_for_Efficient_Clustering_in_Large_Datasets_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Exarchakis_A_Sampling-Based_Approach_for_Efficient_Clustering_in_Large_Datasets_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.14793)
1449. Dual Task Learning by Leveraging Both Dense Correspondence and Mis-Correspondence for Robust Change Detection With Imperfect Matches | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Park_Dual_Task_Learning_by_Leveraging_Both_Dense_Correspondence_and_Mis-Correspondence_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Dual_Task_Learning_by_Leveraging_Both_Dense_Correspondence_and_Mis-Correspondence_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Park_Dual_Task_Learning_CVPR_2022_supplemental.pdf)
1450. Patch Slimming for Efficient Vision Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Patch_Slimming_for_Efficient_Vision_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Patch_Slimming_for_Efficient_Vision_Transformers_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2106.02852)
1451. End-to-End Semi-Supervised Learning for Video Action Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kumar_End-to-End_Semi-Supervised_Learning_for_Video_Action_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kumar_End-to-End_Semi-Supervised_Learning_for_Video_Action_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kumar_End-to-End_Semi-Supervised_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04251)
1452. Cluster-Guided Image Synthesis With Unconditional Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Georgopoulos_Cluster-Guided_Image_Synthesis_With_Unconditional_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Georgopoulos_Cluster-Guided_Image_Synthesis_With_Unconditional_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Georgopoulos_Cluster-Guided_Image_Synthesis_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.12911)
1453. Virtual Correspondence- Humans as a Cue for Extreme-View Geometry | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Virtual_Correspondence_Humans_as_a_Cue_for_Extreme-View_Geometry_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Virtual_Correspondence_Humans_as_a_Cue_for_Extreme-View_Geometry_CVPR_2022_paper.pdf)
1454. Shape From Thermal Radiation- Passive Ranging Using Multi-Spectral LWIR Measurements | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nagase_Shape_From_Thermal_Radiation_Passive_Ranging_Using_Multi-Spectral_LWIR_Measurements_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nagase_Shape_From_Thermal_Radiation_Passive_Ranging_Using_Multi-Spectral_LWIR_Measurements_CVPR_2022_paper.pdf)
1455. CADTransformer- Panoptic Symbol Spotting Transformer for CAD Drawings | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_CADTransformer_Panoptic_Symbol_Spotting_Transformer_for_CAD_Drawings_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_CADTransformer_Panoptic_Symbol_Spotting_Transformer_for_CAD_Drawings_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fan_CADTransformer_Panoptic_Symbol_CVPR_2022_supplemental.pdf)
1456. IntraQ- Learning Synthetic Images With Intra-Class Heterogeneity for Zero-Shot Network Quantization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_IntraQ_Learning_Synthetic_Images_With_Intra-Class_Heterogeneity_for_Zero-Shot_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_IntraQ_Learning_Synthetic_Images_With_Intra-Class_Heterogeneity_for_Zero-Shot_Network_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhong_IntraQ_Learning_Synthetic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.09136)
1457. I M Avatar- Implicit Morphable Head Avatars From Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_I_M_Avatar_Implicit_Morphable_Head_Avatars_From_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_I_M_Avatar_Implicit_Morphable_Head_Avatars_From_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_I_M_Avatar_CVPR_2022_supplemental.pdf)
1458. BodyMap- Learning Full-Body Dense Correspondence Map | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ianina_BodyMap_Learning_Full-Body_Dense_Correspondence_Map_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ianina_BodyMap_Learning_Full-Body_Dense_Correspondence_Map_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ianina_BodyMap_Learning_Full-Body_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2205.09111)
1459. A Hybrid Egocentric Activity Anticipation Framework via Memory-Augmented Recurrent and One-Shot Representation Forecasting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_A_Hybrid_Egocentric_Activity_Anticipation_Framework_via_Memory-Augmented_Recurrent_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_Hybrid_Egocentric_Activity_Anticipation_Framework_via_Memory-Augmented_Recurrent_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_A_Hybrid_Egocentric_CVPR_2022_supplemental.pdf)
1460. Multi-Modal Dynamic Graph Transformer for Visual Grounding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Multi-Modal_Dynamic_Graph_Transformer_for_Visual_Grounding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Multi-Modal_Dynamic_Graph_Transformer_for_Visual_Grounding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Multi-Modal_Dynamic_Graph_CVPR_2022_supplemental.pdf)
1461. Generative Cooperative Learning for Unsupervised Video Anomaly Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zaheer_Generative_Cooperative_Learning_for_Unsupervised_Video_Anomaly_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zaheer_Generative_Cooperative_Learning_for_Unsupervised_Video_Anomaly_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zaheer_Generative_Cooperative_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03962)
1462. Geometric Transformer for Fast and Robust Point Cloud Registration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qin_Geometric_Transformer_for_Fast_and_Robust_Point_Cloud_Registration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qin_Geometric_Transformer_for_Fast_and_Robust_Point_Cloud_Registration_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Qin_Geometric_Transformer_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.06688)
1463. Demystifying the Neural Tangent Kernel From a Practical Perspective- Can It Be Trusted for Neural Architecture Search Without Training- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mok_Demystifying_the_Neural_Tangent_Kernel_From_a_Practical_Perspective_Can_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mok_Demystifying_the_Neural_Tangent_Kernel_From_a_Practical_Perspective_Can_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mok_Demystifying_the_Neural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14577)
1464. Learning To Find Good Models in RANSAC | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Barath_Learning_To_Find_Good_Models_in_RANSAC_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Barath_Learning_To_Find_Good_Models_in_RANSAC_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Barath_Learning_To_Find_CVPR_2022_supplemental.pdf)
1465. Deep Depth From Focus With Differential Focus Volume | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Deep_Depth_From_Focus_With_Differential_Focus_Volume_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Deep_Depth_From_Focus_With_Differential_Focus_Volume_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Deep_Depth_From_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01712)
1466. DiLiGenT102- A Photometric Stereo Benchmark Dataset With Controlled Shape and Material Variation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_DiLiGenT102_A_Photometric_Stereo_Benchmark_Dataset_With_Controlled_Shape_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_DiLiGenT102_A_Photometric_Stereo_Benchmark_Dataset_With_Controlled_Shape_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ren_DiLiGenT102_A_Photometric_CVPR_2022_supplemental.pdf)
1467. Towards Data-Free Model Stealing in a Hard Label Setting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sanyal_Towards_Data-Free_Model_Stealing_in_a_Hard_Label_Setting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sanyal_Towards_Data-Free_Model_Stealing_in_a_Hard_Label_Setting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sanyal_Towards_Data-Free_Model_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.11022)
1468. GAT-CADNet- Graph Attention Network for Panoptic Symbol Spotting in CAD Drawings | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_GAT-CADNet_Graph_Attention_Network_for_Panoptic_Symbol_Spotting_in_CAD_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_GAT-CADNet_Graph_Attention_Network_for_Panoptic_Symbol_Spotting_in_CAD_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_GAT-CADNet_Graph_Attention_CVPR_2022_supplemental.pdf)
1469. Degradation-Agnostic Correspondence From Resolution-Asymmetric Stereo | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Degradation-Agnostic_Correspondence_From_Resolution-Asymmetric_Stereo_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Degradation-Agnostic_Correspondence_From_Resolution-Asymmetric_Stereo_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Degradation-Agnostic_Correspondence_From_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01429)
1470. GPU-Based Homotopy Continuation for Minimal Problems in Computer Vision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chien_GPU-Based_Homotopy_Continuation_for_Minimal_Problems_in_Computer_Vision_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chien_GPU-Based_Homotopy_Continuation_for_Minimal_Problems_in_Computer_Vision_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chien_GPU-Based_Homotopy_Continuation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.03444)
1471. Lite Pose- Efficient Architecture Design for 2D Human Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Lite_Pose_Efficient_Architecture_Design_for_2D_Human_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Lite_Pose_Efficient_Architecture_Design_for_2D_Human_Pose_Estimation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.01271)
1472. Boosting Black-Box Attack With Partially Transferred Conditional Adversarial Distribution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Boosting_Black-Box_Attack_With_Partially_Transferred_Conditional_Adversarial_Distribution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Boosting_Black-Box_Attack_With_Partially_Transferred_Conditional_Adversarial_Distribution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Feng_Boosting_Black-Box_Attack_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2006.08538)
1473. Multi-Person Extreme Motion Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Multi-Person_Extreme_Motion_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Multi-Person_Extreme_Motion_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_Multi-Person_Extreme_Motion_CVPR_2022_supplemental.pdf)
1474. Masking Adversarial Damage- Finding Adversarial Saliency for Robust and Sparse Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Masking_Adversarial_Damage_Finding_Adversarial_Saliency_for_Robust_and_Sparse_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Masking_Adversarial_Damage_Finding_Adversarial_Saliency_for_Robust_and_Sparse_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Masking_Adversarial_Damage_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02738)
1475. Channel Balancing for Accurate Quantization of Winograd Convolutions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chikin_Channel_Balancing_for_Accurate_Quantization_of_Winograd_Convolutions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chikin_Channel_Balancing_for_Accurate_Quantization_of_Winograd_Convolutions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chikin_Channel_Balancing_for_CVPR_2022_supplemental.pdf)
1476. Structured Local Radiance Fields for Human Avatar Modeling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Structured_Local_Radiance_Fields_for_Human_Avatar_Modeling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Structured_Local_Radiance_Fields_for_Human_Avatar_Modeling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_Structured_Local_Radiance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14478)
1477. Learnable Lookup Table for Neural Network Quantization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Learnable_Lookup_Table_for_Neural_Network_Quantization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learnable_Lookup_Table_for_Neural_Network_Quantization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Learnable_Lookup_Table_CVPR_2022_supplemental.pdf)
1478. AdaViT- Adaptive Vision Transformers for Efficient Image Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Meng_AdaViT_Adaptive_Vision_Transformers_for_Efficient_Image_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_AdaViT_Adaptive_Vision_Transformers_for_Efficient_Image_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Meng_AdaViT_Adaptive_Vision_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15668)
1479. NAN- Noise-Aware NeRFs for Burst-Denoising | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pearl_NAN_Noise-Aware_NeRFs_for_Burst-Denoising_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pearl_NAN_Noise-Aware_NeRFs_for_Burst-Denoising_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.04668)
1480. Physical Inertial Poser (PIP)- Physics-Aware Real-Time Human Motion Tracking From Sparse Inertial Sensors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yi_Physical_Inertial_Poser_PIP_Physics-Aware_Real-Time_Human_Motion_Tracking_From_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yi_Physical_Inertial_Poser_PIP_Physics-Aware_Real-Time_Human_Motion_Tracking_From_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yi_Physical_Inertial_Poser_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08528)
1481. b-DARTS- Beta-Decay Regularization for Differentiable Architecture Search | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_b-DARTS_Beta-Decay_Regularization_for_Differentiable_Architecture_Search_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_b-DARTS_Beta-Decay_Regularization_for_Differentiable_Architecture_Search_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_b-DARTS_Beta-Decay_Regularization_CVPR_2022_supplemental.pdf)
1482. Vector Quantized Diffusion Model for Text-to-Image Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gu_Vector_Quantized_Diffusion_Model_for_Text-to-Image_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Vector_Quantized_Diffusion_Model_for_Text-to-Image_Synthesis_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.14822)
1483. CMT- Convolutional Neural Networks Meet Vision Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_CMT_Convolutional_Neural_Networks_Meet_Vision_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_CMT_Convolutional_Neural_Networks_Meet_Vision_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_CMT_Convolutional_Neural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2107.06263)
1484. Optimizing Elimination Templates by Greedy Parameter Search | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Martyushev_Optimizing_Elimination_Templates_by_Greedy_Parameter_Search_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Martyushev_Optimizing_Elimination_Templates_by_Greedy_Parameter_Search_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Martyushev_Optimizing_Elimination_Templates_CVPR_2022_supplemental.pdf)
1485. TransMix- Attend To Mix for Vision Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_TransMix_Attend_To_Mix_for_Vision_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_TransMix_Attend_To_Mix_for_Vision_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_TransMix_Attend_To_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.09833)
1486. HOP- History-and-Order Aware Pre-Training for Vision-and-Language Navigation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qiao_HOP_History-and-Order_Aware_Pre-Training_for_Vision-and-Language_Navigation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qiao_HOP_History-and-Order_Aware_Pre-Training_for_Vision-and-Language_Navigation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Qiao_HOP_History-and-Order_Aware_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11591)
1487. Exploring the Equivalence of Siamese Self-Supervised Learning via a Unified Gradient Framework | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tao_Exploring_the_Equivalence_of_Siamese_Self-Supervised_Learning_via_a_Unified_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Exploring_the_Equivalence_of_Siamese_Self-Supervised_Learning_via_a_Unified_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tao_Exploring_the_Equivalence_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.05141)
1488. Enhancing Classifier Conservativeness and Robustness by Polynomiality | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Enhancing_Classifier_Conservativeness_and_Robustness_by_Polynomiality_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Enhancing_Classifier_Conservativeness_and_Robustness_by_Polynomiality_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.12693)
1489. Revisiting Domain Generalized Stereo Matching Networks From a Feature Consistency Perspective | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Revisiting_Domain_Generalized_Stereo_Matching_Networks_From_a_Feature_Consistency_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Revisiting_Domain_Generalized_Stereo_Matching_Networks_From_a_Feature_Consistency_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Revisiting_Domain_Generalized_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10887)
1490. TubeFormer-DeepLab- Video Mask Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_TubeFormer-DeepLab_Video_Mask_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_TubeFormer-DeepLab_Video_Mask_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_TubeFormer-DeepLab_Video_Mask_CVPR_2022_supplemental.zip)
1491. Continuous Scene Representations for Embodied AI | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gadre_Continuous_Scene_Representations_for_Embodied_AI_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gadre_Continuous_Scene_Representations_for_Embodied_AI_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gadre_Continuous_Scene_Representations_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.17251)
1492. Marginal Contrastive Correspondence for Guided Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhan_Marginal_Contrastive_Correspondence_for_Guided_Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhan_Marginal_Contrastive_Correspondence_for_Guided_Image_Generation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.00442)
1493. Complex Backdoor Detection by Symmetric Feature Differencing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Complex_Backdoor_Detection_by_Symmetric_Feature_Differencing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Complex_Backdoor_Detection_by_Symmetric_Feature_Differencing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Complex_Backdoor_Detection_CVPR_2022_supplemental.pdf)
1494. Adversarial Parametric Pose Prior | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Davydov_Adversarial_Parametric_Pose_Prior_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Davydov_Adversarial_Parametric_Pose_Prior_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Davydov_Adversarial_Parametric_Pose_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.04203)
1495. Location-Free Human Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Location-Free_Human_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Location-Free_Human_Pose_Estimation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.12619)
1496. Proper Reuse of Image Classification Features Improves Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Vasconcelos_Proper_Reuse_of_Image_Classification_Features_Improves_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Vasconcelos_Proper_Reuse_of_Image_Classification_Features_Improves_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Vasconcelos_Proper_Reuse_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00484)
1497. Optimal LED Spectral Multiplexing for NIR2RGB Translation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Optimal_LED_Spectral_Multiplexing_for_NIR2RGB_Translation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Optimal_LED_Spectral_Multiplexing_for_NIR2RGB_Translation_CVPR_2022_paper.pdf)
1498. Expanding Large Pre-Trained Unimodal Models With Multimodal Information Injection for Image-Text Multimodal Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Expanding_Large_Pre-Trained_Unimodal_Models_With_Multimodal_Information_Injection_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Expanding_Large_Pre-Trained_Unimodal_Models_With_Multimodal_Information_Injection_for_CVPR_2022_paper.pdf)
1499. ClusterGNN- Cluster-Based Coarse-To-Fine Graph Neural Network for Efficient Feature Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_ClusterGNN_Cluster-Based_Coarse-To-Fine_Graph_Neural_Network_for_Efficient_Feature_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_ClusterGNN_Cluster-Based_Coarse-To-Fine_Graph_Neural_Network_for_Efficient_Feature_Matching_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.11700)
1500. AdaptPose- Cross-Dataset Adaptation for 3D Human Pose Estimation by Learnable Motion Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gholami_AdaptPose_Cross-Dataset_Adaptation_for_3D_Human_Pose_Estimation_by_Learnable_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gholami_AdaptPose_Cross-Dataset_Adaptation_for_3D_Human_Pose_Estimation_by_Learnable_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gholami_AdaptPose_Cross-Dataset_Adaptation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.11593)
1501. ClothFormer- Taming Video Virtual Try-On in All Module | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_ClothFormer_Taming_Video_Virtual_Try-On_in_All_Module_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_ClothFormer_Taming_Video_Virtual_Try-On_in_All_Module_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jiang_ClothFormer_Taming_Video_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.12151)
1502. Class-Balanced Pixel-Level Self-Labeling for Domain Adaptive Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Class-Balanced_Pixel-Level_Self-Labeling_for_Domain_Adaptive_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Class-Balanced_Pixel-Level_Self-Labeling_for_Domain_Adaptive_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Class-Balanced_Pixel-Level_Self-Labeling_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09744)
1503. Improving Robustness Against Stealthy Weight Bit-Flip Attacks by Output Code Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ozdenizci_Improving_Robustness_Against_Stealthy_Weight_Bit-Flip_Attacks_by_Output_Code_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ozdenizci_Improving_Robustness_Against_Stealthy_Weight_Bit-Flip_Attacks_by_Output_Code_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ozdenizci_Improving_Robustness_Against_CVPR_2022_supplemental.pdf)
1504. TubeR- Tubelet Transformer for Video Action Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_TubeR_Tubelet_Transformer_for_Video_Action_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_TubeR_Tubelet_Transformer_for_Video_Action_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_TubeR_Tubelet_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.00969)
1505. LASER- LAtent SpacE Rendering for 2D Visual Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Min_LASER_LAtent_SpacE_Rendering_for_2D_Visual_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Min_LASER_LAtent_SpacE_Rendering_for_2D_Visual_Localization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Min_LASER_LAtent_SpacE_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00157)
1506. MUM- Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_MUM_Mix_Image_Tiles_and_UnMix_Feature_Tiles_for_Semi-Supervised_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_MUM_Mix_Image_Tiles_and_UnMix_Feature_Tiles_for_Semi-Supervised_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_MUM_Mix_Image_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.10958)
1507. On Adversarial Robustness of Trajectory Prediction for Autonomous Vehicles | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_On_Adversarial_Robustness_of_Trajectory_Prediction_for_Autonomous_Vehicles_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_On_Adversarial_Robustness_of_Trajectory_Prediction_for_Autonomous_Vehicles_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_On_Adversarial_Robustness_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.05057)
1508. Pushing the Performance Limit of Scene Text Recognizer Without Human Annotation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Pushing_the_Performance_Limit_of_Scene_Text_Recognizer_Without_Human_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Pushing_the_Performance_Limit_of_Scene_Text_Recognizer_Without_Human_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_Pushing_the_Performance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07714)
1509. Boosting 3D Object Detection by Simulating Multimodality on Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Boosting_3D_Object_Detection_by_Simulating_Multimodality_on_Point_Clouds_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Boosting_3D_Object_Detection_by_Simulating_Multimodality_on_Point_Clouds_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_Boosting_3D_Object_CVPR_2022_supplemental.pdf)
1510. UDA-COPE- Unsupervised Domain Adaptation for Category-Level Object Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_UDA-COPE_Unsupervised_Domain_Adaptation_for_Category-Level_Object_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_UDA-COPE_Unsupervised_Domain_Adaptation_for_Category-Level_Object_Pose_Estimation_CVPR_2022_paper.pdf)
1511. Learning Non-Target Knowledge for Few-Shot Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_Non-Target_Knowledge_for_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Non-Target_Knowledge_for_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.04903)
1512. Real-Time Hyperspectral Imaging in Hardware via Trained Metasurface Encoders | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Makarenko_Real-Time_Hyperspectral_Imaging_in_Hardware_via_Trained_Metasurface_Encoders_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Makarenko_Real-Time_Hyperspectral_Imaging_in_Hardware_via_Trained_Metasurface_Encoders_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Makarenko_Real-Time_Hyperspectral_Imaging_CVPR_2022_supplemental.pdf)
1513. Contextual Debiasing for Visual Recognition With Causal Mechanisms | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Contextual_Debiasing_for_Visual_Recognition_With_Causal_Mechanisms_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Contextual_Debiasing_for_Visual_Recognition_With_Causal_Mechanisms_CVPR_2022_paper.pdf)
1514. PokeBNN- A Binary Pursuit of Lightweight Accuracy | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_PokeBNN_A_Binary_Pursuit_of_Lightweight_Accuracy_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_PokeBNN_A_Binary_Pursuit_of_Lightweight_Accuracy_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_PokeBNN_A_Binary_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00133)
1515. How Do You Do It- Fine-Grained Action Understanding With Pseudo-Adverbs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Doughty_How_Do_You_Do_It_Fine-Grained_Action_Understanding_With_Pseudo-Adverbs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Doughty_How_Do_You_Do_It_Fine-Grained_Action_Understanding_With_Pseudo-Adverbs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Doughty_How_Do_You_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.12344)
1516. SOMSI- Spherical Novel View Synthesis With Soft Occlusion Multi-Sphere Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Habtegebrial_SOMSI_Spherical_Novel_View_Synthesis_With_Soft_Occlusion_Multi-Sphere_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Habtegebrial_SOMSI_Spherical_Novel_View_Synthesis_With_Soft_Occlusion_Multi-Sphere_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Habtegebrial_SOMSI_Spherical_Novel_CVPR_2022_supplemental.pdf)
1517. PoseTriplet- Co-Evolving 3D Human Pose Estimation, Imitation, and Hallucination Under Self-Supervision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gong_PoseTriplet_Co-Evolving_3D_Human_Pose_Estimation_Imitation_and_Hallucination_Under_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_PoseTriplet_Co-Evolving_3D_Human_Pose_Estimation_Imitation_and_Hallucination_Under_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gong_PoseTriplet_Co-Evolving_3D_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.15625)
1518. Coarse-To-Fine Q-Attention- Efficient Learning for Visual Robotic Manipulation via Discretisation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/James_Coarse-To-Fine_Q-Attention_Efficient_Learning_for_Visual_Robotic_Manipulation_via_Discretisation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/James_Coarse-To-Fine_Q-Attention_Efficient_Learning_for_Visual_Robotic_Manipulation_via_Discretisation_CVPR_2022_paper.pdf)
1519. Visual Abductive Reasoning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Visual_Abductive_Reasoning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Visual_Abductive_Reasoning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liang_Visual_Abductive_Reasoning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14040)
1520. NICGSlowDown- Evaluating the Efficiency Robustness of Neural Image Caption Generation Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_NICGSlowDown_Evaluating_the_Efficiency_Robustness_of_Neural_Image_Caption_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_NICGSlowDown_Evaluating_the_Efficiency_Robustness_of_Neural_Image_Caption_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_NICGSlowDown_Evaluating_the_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15859)
1521. Keypoint Transformer- Solving Joint Identification in Challenging Hands and Object Interactions for Accurate 3D Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hampali_Keypoint_Transformer_Solving_Joint_Identification_in_Challenging_Hands_and_Object_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hampali_Keypoint_Transformer_Solving_Joint_Identification_in_Challenging_Hands_and_Object_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hampali_Keypoint_Transformer_Solving_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.14639)
1522. SemanticStyleGAN- Learning Compositional Generative Priors for Controllable Image Synthesis and Editing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_SemanticStyleGAN_Learning_Compositional_Generative_Priors_for_Controllable_Image_Synthesis_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_SemanticStyleGAN_Learning_Compositional_Generative_Priors_for_Controllable_Image_Synthesis_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shi_SemanticStyleGAN_Learning_Compositional_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02236)
1523. Label-Only Model Inversion Attacks via Boundary Repulsion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kahla_Label-Only_Model_Inversion_Attacks_via_Boundary_Repulsion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kahla_Label-Only_Model_Inversion_Attacks_via_Boundary_Repulsion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kahla_Label-Only_Model_Inversion_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01925)
1524. Learning Where To Learn in Cross-View Self-Supervised Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Learning_Where_To_Learn_in_Cross-View_Self-Supervised_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Learning_Where_To_Learn_in_Cross-View_Self-Supervised_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_Learning_Where_To_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14898)
1525. SemAffiNet- Semantic-Affine Transformation for Point Cloud Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_SemAffiNet_Semantic-Affine_Transformation_for_Point_Cloud_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_SemAffiNet_Semantic-Affine_Transformation_for_Point_Cloud_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_SemAffiNet_Semantic-Affine_Transformation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.13490)
1526. Shapley-NAS- Discovering Operation Contribution for Neural Architecture Search | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xiao_Shapley-NAS_Discovering_Operation_Contribution_for_Neural_Architecture_Search_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xiao_Shapley-NAS_Discovering_Operation_Contribution_for_Neural_Architecture_Search_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xiao_Shapley-NAS_Discovering_Operation_CVPR_2022_supplemental.pdf)
1527. Vision-Language Pre-Training With Triple Contrastive Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Vision-Language_Pre-Training_With_Triple_Contrastive_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Vision-Language_Pre-Training_With_Triple_Contrastive_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Vision-Language_Pre-Training_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.10401)
1528. Fourier PlenOctrees for Dynamic Radiance Field Rendering in Real-Time | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Fourier_PlenOctrees_for_Dynamic_Radiance_Field_Rendering_in_Real-Time_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Fourier_PlenOctrees_for_Dynamic_Radiance_Field_Rendering_in_Real-Time_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Fourier_PlenOctrees_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.08614)
1529. Towards Practical Deployment-Stage Backdoor Attack on Deep Neural Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qi_Towards_Practical_Deployment-Stage_Backdoor_Attack_on_Deep_Neural_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qi_Towards_Practical_Deployment-Stage_Backdoor_Attack_on_Deep_Neural_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Qi_Towards_Practical_Deployment-Stage_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12965)
1530. Scaling Vision Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhai_Scaling_Vision_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhai_Scaling_Vision_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhai_Scaling_Vision_Transformers_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2106.04560)
1531. Learned Queries for Efficient Local Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Arar_Learned_Queries_for_Efficient_Local_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Arar_Learned_Queries_for_Efficient_Local_Attention_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Arar_Learned_Queries_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.11435)
1532. Stereoscopic Universal Perturbations Across Different Architectures and Datasets | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Berger_Stereoscopic_Universal_Perturbations_Across_Different_Architectures_and_Datasets_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Berger_Stereoscopic_Universal_Perturbations_Across_Different_Architectures_and_Datasets_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Berger_Stereoscopic_Universal_Perturbations_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.06116)
1533. AutoGPart- Intermediate Supervision Search for Generalizable 3D Part Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_AutoGPart_Intermediate_Supervision_Search_for_Generalizable_3D_Part_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_AutoGPart_Intermediate_Supervision_Search_for_Generalizable_3D_Part_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_AutoGPart_Intermediate_Supervision_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06558)
1534. DeltaCNN- End-to-End CNN Inference of Sparse Frame Differences in Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Parger_DeltaCNN_End-to-End_CNN_Inference_of_Sparse_Frame_Differences_in_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Parger_DeltaCNN_End-to-End_CNN_Inference_of_Sparse_Frame_Differences_in_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Parger_DeltaCNN_End-to-End_CNN_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03996)
1535. MNSRNet- Multimodal Transformer Network for 3D Surface Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_MNSRNet_Multimodal_Transformer_Network_for_3D_Surface_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_MNSRNet_Multimodal_Transformer_Network_for_3D_Surface_Super-Resolution_CVPR_2022_paper.pdf)
1536. Scene Graph Expansion for Semantics-Guided Image Outpainting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Scene_Graph_Expansion_for_Semantics-Guided_Image_Outpainting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Scene_Graph_Expansion_for_Semantics-Guided_Image_Outpainting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Scene_Graph_Expansion_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.02958)
1537. Bridged Transformer for Vision and Point Cloud 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Bridged_Transformer_for_Vision_and_Point_Cloud_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Bridged_Transformer_for_Vision_and_Point_Cloud_3D_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Bridged_Transformer_for_CVPR_2022_supplemental.pdf)
1538. TransVPR- Transformer-Based Place Recognition With Multi-Level Attention Aggregation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_TransVPR_Transformer-Based_Place_Recognition_With_Multi-Level_Attention_Aggregation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_TransVPR_Transformer-Based_Place_Recognition_With_Multi-Level_Attention_Aggregation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_TransVPR_Transformer-Based_Place_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.02001)
1539. Give Me Your Attention- Dot-Product Attention Considered Harmful for Adversarial Patch Robustness | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lovisotto_Give_Me_Your_Attention_Dot-Product_Attention_Considered_Harmful_for_Adversarial_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lovisotto_Give_Me_Your_Attention_Dot-Product_Attention_Considered_Harmful_for_Adversarial_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lovisotto_Give_Me_Your_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13639)
1540. AKB-48- A Real-World Articulated Object Knowledge Base | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_AKB-48_A_Real-World_Articulated_Object_Knowledge_Base_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_AKB-48_A_Real-World_Articulated_Object_Knowledge_Base_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_AKB-48_A_Real-World_CVPR_2022_supplemental.pdf)
1541. Aug-NeRF- Training Stronger Neural Radiance Fields With Triple-Level Physically-Grounded Augmentations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Aug-NeRF_Training_Stronger_Neural_Radiance_Fields_With_Triple-Level_Physically-Grounded_Augmentations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Aug-NeRF_Training_Stronger_Neural_Radiance_Fields_With_Triple-Level_Physically-Grounded_Augmentations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Aug-NeRF_Training_Stronger_CVPR_2022_supplemental.pdf)
1542. RGB-Multispectral Matching- Dataset, Learning Methodology, Evaluation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tosi_RGB-Multispectral_Matching_Dataset_Learning_Methodology_Evaluation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tosi_RGB-Multispectral_Matching_Dataset_Learning_Methodology_Evaluation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tosi_RGB-Multispectral_Matching_Dataset_CVPR_2022_supplemental.pdf)
1543. Id-Free Person Similarity Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shuai_Id-Free_Person_Similarity_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shuai_Id-Free_Person_Similarity_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shuai_Id-Free_Person_Similarity_CVPR_2022_supplemental.pdf)
1544. Semantic-Shape Adaptive Feature Modulation for Semantic Image Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lv_Semantic-Shape_Adaptive_Feature_Modulation_for_Semantic_Image_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lv_Semantic-Shape_Adaptive_Feature_Modulation_for_Semantic_Image_Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lv_Semantic-Shape_Adaptive_Feature_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16898)
1545. Day-to-Night Image Synthesis for Training Nighttime Neural ISPs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Punnappurath_Day-to-Night_Image_Synthesis_for_Training_Nighttime_Neural_ISPs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Punnappurath_Day-to-Night_Image_Synthesis_for_Training_Nighttime_Neural_ISPs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Punnappurath_Day-to-Night_Image_Synthesis_CVPR_2022_supplemental.pdf)
1546. Holocurtains- Programming Light Curtains via Binary Holography | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chan_Holocurtains_Programming_Light_Curtains_via_Binary_Holography_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Holocurtains_Programming_Light_Curtains_via_Binary_Holography_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chan_Holocurtains_Programming_Light_CVPR_2022_supplemental.zip)
1547. Learning Adaptive Warping for Real-World Rolling Shutter Correction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cao_Learning_Adaptive_Warping_for_Real-World_Rolling_Shutter_Correction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_Learning_Adaptive_Warping_for_Real-World_Rolling_Shutter_Correction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cao_Learning_Adaptive_Warping_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.13886)
1548. Bongard-HOI- Benchmarking Few-Shot Visual Reasoning for Human-Object Interactions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Bongard-HOI_Benchmarking_Few-Shot_Visual_Reasoning_for_Human-Object_Interactions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Bongard-HOI_Benchmarking_Few-Shot_Visual_Reasoning_for_Human-Object_Interactions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jiang_Bongard-HOI_Benchmarking_Few-Shot_CVPR_2022_supplemental.pdf)
1549. ZeroCap- Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tewel_ZeroCap_Zero-Shot_Image-to-Text_Generation_for_Visual-Semantic_Arithmetic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tewel_ZeroCap_Zero-Shot_Image-to-Text_Generation_for_Visual-Semantic_Arithmetic_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tewel_ZeroCap_Zero-Shot_Image-to-Text_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14447)
1550. End-to-End Generative Pretraining for Multimodal Video Captioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Seo_End-to-End_Generative_Pretraining_for_Multimodal_Video_Captioning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Seo_End-to-End_Generative_Pretraining_for_Multimodal_Video_Captioning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Seo_End-to-End_Generative_Pretraining_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2201.08264)
1551. Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gu_Stochastic_Trajectory_Prediction_via_Motion_Indeterminacy_Diffusion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Stochastic_Trajectory_Prediction_via_Motion_Indeterminacy_Diffusion_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gu_Stochastic_Trajectory_Prediction_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13777)
1552. Cross-Modal Clinical Graph Transformer for Ophthalmic Report Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Cross-Modal_Clinical_Graph_Transformer_for_Ophthalmic_Report_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Cross-Modal_Clinical_Graph_Transformer_for_Ophthalmic_Report_Generation_CVPR_2022_paper.pdf)
1553. Human-Object Interaction Detection via Disentangled Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Human-Object_Interaction_Detection_via_Disentangled_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Human-Object_Interaction_Detection_via_Disentangled_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Human-Object_Interaction_Detection_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.09290)
1554. CVF-SID- Cyclic Multi-Variate Function for Self-Supervised Image Denoising by Disentangling Noise From Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Neshatavar_CVF-SID_Cyclic_Multi-Variate_Function_for_Self-Supervised_Image_Denoising_by_Disentangling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Neshatavar_CVF-SID_Cyclic_Multi-Variate_Function_for_Self-Supervised_Image_Denoising_by_Disentangling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Neshatavar_CVF-SID_Cyclic_Multi-Variate_CVPR_2022_supplemental.pdf)
1555. FaceFormer- Speech-Driven 3D Facial Animation With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_FaceFormer_Speech-Driven_3D_Facial_Animation_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_FaceFormer_Speech-Driven_3D_Facial_Animation_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fan_FaceFormer_Speech-Driven_3D_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2112.05329)
1556. Exploring Patch-Wise Semantic Relation for Contrastive Learning in Image-to-Image Translation Tasks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jung_Exploring_Patch-Wise_Semantic_Relation_for_Contrastive_Learning_in_Image-to-Image_Translation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jung_Exploring_Patch-Wise_Semantic_Relation_for_Contrastive_Learning_in_Image-to-Image_Translation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jung_Exploring_Patch-Wise_Semantic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01532)
1557. Towards General Purpose Vision Systems- An End-to-End Task-Agnostic Vision-Language Architecture | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gupta_Towards_General_Purpose_Vision_Systems_An_End-to-End_Task-Agnostic_Vision-Language_Architecture_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gupta_Towards_General_Purpose_Vision_Systems_An_End-to-End_Task-Agnostic_Vision-Language_Architecture_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gupta_Towards_General_Purpose_CVPR_2022_supplemental.zip)
1558. LiT- Zero-Shot Transfer With Locked-Image Text Tuning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhai_LiT_Zero-Shot_Transfer_With_Locked-Image_Text_Tuning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhai_LiT_Zero-Shot_Transfer_With_Locked-Image_Text_Tuning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhai_LiT_Zero-Shot_Transfer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.07991)
1559. GeoNeRF- Generalizing NeRF With Geometry Priors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Johari_GeoNeRF_Generalizing_NeRF_With_Geometry_Priors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Johari_GeoNeRF_Generalizing_NeRF_With_Geometry_Priors_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Johari_GeoNeRF_Generalizing_NeRF_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13539)
1560. PhoCaL- A Multi-Modal Dataset for Category-Level Object Pose Estimation With Photometrically Challenging Objects | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_PhoCaL_A_Multi-Modal_Dataset_for_Category-Level_Object_Pose_Estimation_With_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_PhoCaL_A_Multi-Modal_Dataset_for_Category-Level_Object_Pose_Estimation_With_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_PhoCaL_A_Multi-Modal_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2205.08811)
1561. Uformer- A General U-Shaped Transformer for Image Restoration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Uformer_A_General_U-Shaped_Transformer_for_Image_Restoration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Uformer_A_General_U-Shaped_Transformer_for_Image_Restoration_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Uformer_A_General_CVPR_2022_supplemental.pdf)
1562. Bridge-Prompt- Towards Ordinal Action Understanding in Instructional Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Bridge-Prompt_Towards_Ordinal_Action_Understanding_in_Instructional_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Bridge-Prompt_Towards_Ordinal_Action_Understanding_in_Instructional_Videos_CVPR_2022_paper.pdf)
1563. Cerberus Transformer- Joint Semantic, Affordance and Attribute Parsing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Cerberus_Transformer_Joint_Semantic_Affordance_and_Attribute_Parsing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Cerberus_Transformer_Joint_Semantic_Affordance_and_Attribute_Parsing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Cerberus_Transformer_Joint_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12608)
1564. Single-Photon Structured Light | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sundar_Single-Photon_Structured_Light_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sundar_Single-Photon_Structured_Light_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sundar_Single-Photon_Structured_Light_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.05300)
1565. Deblurring via Stochastic Refinement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Whang_Deblurring_via_Stochastic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02475)
1566. 3DJCG- A Unified Framework for Joint Dense Captioning and Visual Grounding on 3D Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cai_3DJCG_A_Unified_Framework_for_Joint_Dense_Captioning_and_Visual_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_3DJCG_A_Unified_Framework_for_Joint_Dense_Captioning_and_Visual_CVPR_2022_paper.pdf)
1567. Abandoning the Bayer-Filter To See in the Dark | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Abandoning_the_Bayer-Filter_To_See_in_the_Dark_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Abandoning_the_Bayer-Filter_To_See_in_the_Dark_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_Abandoning_the_Bayer-Filter_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04042)
1568. Exploiting Temporal Relations on Radar Perception for Autonomous Driving | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Exploiting_Temporal_Relations_on_Radar_Perception_for_Autonomous_Driving_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Exploiting_Temporal_Relations_on_Radar_Perception_for_Autonomous_Driving_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Exploiting_Temporal_Relations_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01184)
1569. Forward Compatible Training for Large-Scale Embedding Retrieval Systems | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ramanujan_Forward_Compatible_Training_for_Large-Scale_Embedding_Retrieval_Systems_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ramanujan_Forward_Compatible_Training_for_Large-Scale_Embedding_Retrieval_Systems_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ramanujan_Forward_Compatible_Training_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02805)
1570. Everything at Once - Multi-Modal Fusion Transformer for Video Retrieval | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shvetsova_Everything_at_Once_-_Multi-Modal_Fusion_Transformer_for_Video_Retrieval_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shvetsova_Everything_at_Once_-_Multi-Modal_Fusion_Transformer_for_Video_Retrieval_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shvetsova_Everything_at_Once_CVPR_2022_supplemental.pdf), [arXiv](https://arxiv.org/abs/2112.04446), [](https://arxiv.org/abs/2112.04446)
1571. Neural Template- Topology-Aware Reconstruction and Disentangled Generation of 3D Meshes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hui_Neural_Template_Topology-Aware_Reconstruction_and_Disentangled_Generation_of_3D_Meshes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hui_Neural_Template_Topology-Aware_Reconstruction_and_Disentangled_Generation_of_3D_Meshes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hui_Neural_Template_Topology-Aware_CVPR_2022_supplemental.pdf)
1572. AdaFace- Quality Adaptive Margin for Face Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_AdaFace_Quality_Adaptive_Margin_for_Face_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_AdaFace_Quality_Adaptive_Margin_for_Face_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_AdaFace_Quality_Adaptive_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00964)
1573. Learning Soft Estimator of Keypoint Scale and Orientation With Probabilistic Covariant Loss | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yan_Learning_Soft_Estimator_of_Keypoint_Scale_and_Orientation_With_Probabilistic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Learning_Soft_Estimator_of_Keypoint_Scale_and_Orientation_With_Probabilistic_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yan_Learning_Soft_Estimator_CVPR_2022_supplemental.pdf)
1574. Opening Up Open World Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Opening_Up_Open_World_Tracking_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Opening_Up_Open_World_Tracking_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Opening_Up_Open_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.11221)
1575. OSSO- Obtaining Skeletal Shape From Outside | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Keller_OSSO_Obtaining_Skeletal_Shape_From_Outside_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Keller_OSSO_Obtaining_Skeletal_Shape_From_Outside_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Keller_OSSO_Obtaining_Skeletal_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.10129)
1576. Bayesian Invariant Risk Minimization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Bayesian_Invariant_Risk_Minimization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Bayesian_Invariant_Risk_Minimization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_Bayesian_Invariant_Risk_CVPR_2022_supplemental.pdf)
1577. Alleviating Semantics Distortion in Unsupervised Low-Level Image-to-Image Translation via Structure Consistency Constraint | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Alleviating_Semantics_Distortion_in_Unsupervised_Low-Level_Image-to-Image_Translation_via_Structure_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Alleviating_Semantics_Distortion_in_Unsupervised_Low-Level_Image-to-Image_Translation_via_Structure_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_Alleviating_Semantics_Distortion_CVPR_2022_supplemental.pdf)
1578. Uni-Perceiver- Pre-Training Unified Architecture for Generic Perception for Zero-Shot and Few-Shot Tasks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Uni-Perceiver_Pre-Training_Unified_Architecture_for_Generic_Perception_for_Zero-Shot_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Uni-Perceiver_Pre-Training_Unified_Architecture_for_Generic_Perception_for_Zero-Shot_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Uni-Perceiver_Pre-Training_Unified_CVPR_2022_supplemental.pdf)
1579. The Auto Arborist Dataset- A Large-Scale Benchmark for Multiview Urban Forest Monitoring Under Domain Shift | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Beery_The_Auto_Arborist_Dataset_A_Large-Scale_Benchmark_for_Multiview_Urban_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Beery_The_Auto_Arborist_Dataset_A_Large-Scale_Benchmark_for_Multiview_Urban_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Beery_The_Auto_Arborist_CVPR_2022_supplemental.pdf)
1580. Real-Time, Accurate, and Consistent Video Semantic Segmentation via Unsupervised Adaptation and Cross-Unit Deployment on Mobile Device | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Park_Real-Time_Accurate_and_Consistent_Video_Semantic_Segmentation_via_Unsupervised_Adaptation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Real-Time_Accurate_and_Consistent_Video_Semantic_Segmentation_via_Unsupervised_Adaptation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Park_Real-Time_Accurate_and_CVPR_2022_supplemental.zip)
1581. A Style-Aware Discriminator for Controllable Image Translation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_A_Style-Aware_Discriminator_for_Controllable_Image_Translation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_A_Style-Aware_Discriminator_for_Controllable_Image_Translation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_A_Style-Aware_Discriminator_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15375)
1582. Incremental Cross-View Mutual Distillation for Self-Supervised Medical CT Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fang_Incremental_Cross-View_Mutual_Distillation_for_Self-Supervised_Medical_CT_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_Incremental_Cross-View_Mutual_Distillation_for_Self-Supervised_Medical_CT_Synthesis_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.10325)
1583. Moving Window Regression- A Novel Approach to Ordinal Regression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shin_Moving_Window_Regression_A_Novel_Approach_to_Ordinal_Regression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shin_Moving_Window_Regression_A_Novel_Approach_to_Ordinal_Regression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shin_Moving_Window_Regression_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.13122)
1584. ACPL- Anti-Curriculum Pseudo-Labelling for Semi-Supervised Medical Image Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_ACPL_Anti-Curriculum_Pseudo-Labelling_for_Semi-Supervised_Medical_Image_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_ACPL_Anti-Curriculum_Pseudo-Labelling_for_Semi-Supervised_Medical_Image_Classification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_ACPL_Anti-Curriculum_Pseudo-Labelling_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12918)
1585. Learning to Deblur Using Light Field Generated and Real Defocus Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ruan_Learning_to_Deblur_Using_Light_Field_Generated_and_Real_Defocus_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ruan_Learning_to_Deblur_Using_Light_Field_Generated_and_Real_Defocus_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ruan_Learning_to_Deblur_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00367)
1586. PhotoScene- Photorealistic Material and Lighting Transfer for Indoor Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yeh_PhotoScene_Photorealistic_Material_and_Lighting_Transfer_for_Indoor_Scenes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yeh_PhotoScene_Photorealistic_Material_and_Lighting_Transfer_for_Indoor_Scenes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yeh_PhotoScene_Photorealistic_Material_CVPR_2022_supplemental.zip)
1587. Versatile Multi-Modal Pre-Training for Human-Centric Perception | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Versatile_Multi-Modal_Pre-Training_for_Human-Centric_Perception_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Versatile_Multi-Modal_Pre-Training_for_Human-Centric_Perception_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.13815)
1588. Contrastive Regression for Domain Adaptation on Gaze Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Contrastive_Regression_for_Domain_Adaptation_on_Gaze_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Contrastive_Regression_for_Domain_Adaptation_on_Gaze_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Contrastive_Regression_for_CVPR_2022_supplemental.pdf)
1589. Multi-View Consistent Generative Adversarial Networks for 3D-Aware Image Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Multi-View_Consistent_Generative_Adversarial_Networks_for_3D-Aware_Image_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Multi-View_Consistent_Generative_Adversarial_Networks_for_3D-Aware_Image_Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Multi-View_Consistent_Generative_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.06307)
1590. Memory-Augmented Non-Local Attention for Video Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Memory-Augmented_Non-Local_Attention_for_Video_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Memory-Augmented_Non-Local_Attention_for_Video_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_Memory-Augmented_Non-Local_Attention_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2108.11048)
1591. Classification-Then-Grounding- Reformulating Video Scene Graphs As Temporal Bipartite Graphs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gao_Classification-Then-Grounding_Reformulating_Video_Scene_Graphs_As_Temporal_Bipartite_Graphs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Classification-Then-Grounding_Reformulating_Video_Scene_Graphs_As_Temporal_Bipartite_Graphs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gao_Classification-Then-Grounding_Reformulating_Video_CVPR_2022_supplemental.pdf)
1592. Transformer-Empowered Multi-Scale Contextual Matching and Aggregation for Multi-Contrast MRI Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Transformer-Empowered_Multi-Scale_Contextual_Matching_and_Aggregation_for_Multi-Contrast_MRI_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Transformer-Empowered_Multi-Scale_Contextual_Matching_and_Aggregation_for_Multi-Contrast_MRI_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Transformer-Empowered_Multi-Scale_Contextual_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13963)
1593. GateHUB- Gated History Unit With Background Suppression for Online Action Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_GateHUB_Gated_History_Unit_With_Background_Suppression_for_Online_Action_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_GateHUB_Gated_History_Unit_With_Background_Suppression_for_Online_Action_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_GateHUB_Gated_History_CVPR_2022_supplemental.pdf)
1594. Bridging Video-Text Retrieval With Multiple Choice Questions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ge_Bridging_Video-Text_Retrieval_With_Multiple_Choice_Questions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ge_Bridging_Video-Text_Retrieval_With_Multiple_Choice_Questions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ge_Bridging_Video-Text_Retrieval_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.04850)
1595. DF-GAN- A Simple and Effective Baseline for Text-to-Image Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tao_DF-GAN_A_Simple_and_Effective_Baseline_for_Text-to-Image_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_DF-GAN_A_Simple_and_Effective_Baseline_for_Text-to-Image_Synthesis_CVPR_2022_paper.pdf)
1596. CoNeRF- Controllable Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kania_CoNeRF_Controllable_Neural_Radiance_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kania_CoNeRF_Controllable_Neural_Radiance_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kania_CoNeRF_Controllable_Neural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01983)
1597. Noise2NoiseFlow- Realistic Camera Noise Modeling Without Clean Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Maleky_Noise2NoiseFlow_Realistic_Camera_Noise_Modeling_Without_Clean_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Maleky_Noise2NoiseFlow_Realistic_Camera_Noise_Modeling_Without_Clean_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Maleky_Noise2NoiseFlow_Realistic_Camera_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2206.01103)
1598. ZeroWaste Dataset- Towards Deformable Object Segmentation in Cluttered Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bashkirova_ZeroWaste_Dataset_Towards_Deformable_Object_Segmentation_in_Cluttered_Scenes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bashkirova_ZeroWaste_Dataset_Towards_Deformable_Object_Segmentation_in_Cluttered_Scenes_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2106.02740)
1599. UNIST- Unpaired Neural Implicit Shape Translation Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_UNIST_Unpaired_Neural_Implicit_Shape_Translation_Network_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_UNIST_Unpaired_Neural_Implicit_Shape_Translation_Network_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_UNIST_Unpaired_Neural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.05381)
1600. Local-Adaptive Face Recognition via Graph-Based Meta-Clustering and Regularized Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Local-Adaptive_Face_Recognition_via_Graph-Based_Meta-Clustering_and_Regularized_Adaptation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Local-Adaptive_Face_Recognition_via_Graph-Based_Meta-Clustering_and_Regularized_Adaptation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Local-Adaptive_Face_Recognition_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14327)
1601. The DEVIL Is in the Details- A Diagnostic Evaluation Benchmark for Video Inpainting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Szeto_The_DEVIL_Is_in_the_Details_A_Diagnostic_Evaluation_Benchmark_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Szeto_The_DEVIL_Is_in_the_Details_A_Diagnostic_Evaluation_Benchmark_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Szeto_The_DEVIL_Is_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2105.05332)
1602. Generating Useful Accident-Prone Driving Scenarios via a Learned Traffic Prior | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rempe_Generating_Useful_Accident-Prone_Driving_Scenarios_via_a_Learned_Traffic_Prior_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rempe_Generating_Useful_Accident-Prone_Driving_Scenarios_via_a_Learned_Traffic_Prior_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rempe_Generating_Useful_Accident-Prone_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2112.05077)
1603. Efficient Geometry-Aware 3D Generative Adversarial Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chan_Efficient_Geometry-Aware_3D_Generative_Adversarial_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Efficient_Geometry-Aware_3D_Generative_Adversarial_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chan_Efficient_Geometry-Aware_3D_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2112.07945)
1604. Dancing Under the Stars- Video Denoising in Starlight | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Monakhova_Dancing_Under_the_Stars_Video_Denoising_in_Starlight_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Monakhova_Dancing_Under_the_Stars_Video_Denoising_in_Starlight_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Monakhova_Dancing_Under_the_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.04210)
1605. SPAct- Self-Supervised Privacy Preservation for Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dave_SPAct_Self-Supervised_Privacy_Preservation_for_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dave_SPAct_Self-Supervised_Privacy_Preservation_for_Action_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dave_SPAct_Self-Supervised_Privacy_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.15205)
1606. De-Rendering 3D Objects in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wimbauer_De-Rendering_3D_Objects_in_the_Wild_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wimbauer_De-Rendering_3D_Objects_in_the_Wild_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wimbauer_De-Rendering_3D_Objects_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.02279)
1607. Representing 3D Shapes With Probabilistic Directed Distance Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Aumentado-Armstrong_Representing_3D_Shapes_With_Probabilistic_Directed_Distance_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Aumentado-Armstrong_Representing_3D_Shapes_With_Probabilistic_Directed_Distance_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Aumentado-Armstrong_Representing_3D_Shapes_CVPR_2022_supplemental.pdf)
1608. Learning ABCs- Approximate Bijective Correspondence for Isolating Factors of Variation With Weak Supervision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Murphy_Learning_ABCs_Approximate_Bijective_Correspondence_for_Isolating_Factors_of_Variation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Murphy_Learning_ABCs_Approximate_Bijective_Correspondence_for_Isolating_Factors_of_Variation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Murphy_Learning_ABCs_Approximate_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2103.03240)
1609. ABO- Dataset and Benchmarks for Real-World 3D Object Understanding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Collins_ABO_Dataset_and_Benchmarks_for_Real-World_3D_Object_Understanding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Collins_ABO_Dataset_and_Benchmarks_for_Real-World_3D_Object_Understanding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Collins_ABO_Dataset_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.06199)
1610. MS-TCT- Multi-Scale Temporal ConvTransformer for Action Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dai_MS-TCT_Multi-Scale_Temporal_ConvTransformer_for_Action_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_MS-TCT_Multi-Scale_Temporal_ConvTransformer_for_Action_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dai_MS-TCT_Multi-Scale_Temporal_CVPR_2022_supplemental.pdf)
1611. Make It Move- Controllable Image-to-Video Generation With Text Descriptions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Make_It_Move_Controllable_Image-to-Video_Generation_With_Text_Descriptions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Make_It_Move_Controllable_Image-to-Video_Generation_With_Text_Descriptions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_Make_It_Move_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02815)
1612. Neural Points- Point Cloud Representation With Neural Fields for Arbitrary Upsampling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Neural_Points_Point_Cloud_Representation_With_Neural_Fields_for_Arbitrary_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Neural_Points_Point_Cloud_Representation_With_Neural_Fields_for_Arbitrary_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.04148)
1613. FIFO- Learning Fog-Invariant Features for Foggy Scene Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_FIFO_Learning_Fog-Invariant_Features_for_Foggy_Scene_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_FIFO_Learning_Fog-Invariant_Features_for_Foggy_Scene_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_FIFO_Learning_Fog-Invariant_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01587)
1614. Unsupervised Visual Representation Learning by Online Constrained K-Means | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qian_Unsupervised_Visual_Representation_Learning_by_Online_Constrained_K-Means_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qian_Unsupervised_Visual_Representation_Learning_by_Online_Constrained_K-Means_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Qian_Unsupervised_Visual_Representation_CVPR_2022_supplemental.pdf)
1615. Neural Point Light Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ost_Neural_Point_Light_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ost_Neural_Point_Light_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ost_Neural_Point_Light_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2112.01473)
1616. Vehicle Trajectory Prediction Works, but Not Everywhere | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bahari_Vehicle_Trajectory_Prediction_Works_but_Not_Everywhere_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bahari_Vehicle_Trajectory_Prediction_Works_but_Not_Everywhere_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bahari_Vehicle_Trajectory_Prediction_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.03909)
1617. Instance-Wise Occlusion and Depth Orders in Natural Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Instance-Wise_Occlusion_and_Depth_Orders_in_Natural_Scenes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Instance-Wise_Occlusion_and_Depth_Orders_in_Natural_Scenes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Instance-Wise_Occlusion_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14562)
1618. Contour-Hugging Heatmaps for Landmark Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/McCouat_Contour-Hugging_Heatmaps_for_Landmark_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/McCouat_Contour-Hugging_Heatmaps_for_Landmark_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/McCouat_Contour-Hugging_Heatmaps_for_CVPR_2022_supplemental.pdf)
1619. DisARM- Displacement Aware Relation Module for 3D Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Duan_DisARM_Displacement_Aware_Relation_Module_for_3D_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_DisARM_Displacement_Aware_Relation_Module_for_3D_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Duan_DisARM_Displacement_Aware_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01152)
1620. NeRF-Editing- Geometry Editing of Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_NeRF-Editing_Geometry_Editing_of_Neural_Radiance_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_NeRF-Editing_Geometry_Editing_of_Neural_Radiance_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yuan_NeRF-Editing_Geometry_Editing_CVPR_2022_supplemental.zip)
1621. Optimal Correction Cost for Object Detection Evaluation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Otani_Optimal_Correction_Cost_for_Object_Detection_Evaluation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Otani_Optimal_Correction_Cost_for_Object_Detection_Evaluation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Otani_Optimal_Correction_Cost_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.14438)
1622. Artistic Style Discovery With Independent Components | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Artistic_Style_Discovery_With_Independent_Components_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Artistic_Style_Discovery_With_Independent_Components_CVPR_2022_paper.pdf)
1623. HyperStyle- StyleGAN Inversion With HyperNetworks for Real Image Editing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Alaluf_HyperStyle_StyleGAN_Inversion_With_HyperNetworks_for_Real_Image_Editing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Alaluf_HyperStyle_StyleGAN_Inversion_With_HyperNetworks_for_Real_Image_Editing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Alaluf_HyperStyle_StyleGAN_Inversion_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15666)
1624. LTP- Lane-Based Trajectory Prediction for Autonomous Driving | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_LTP_Lane-Based_Trajectory_Prediction_for_Autonomous_Driving_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_LTP_Lane-Based_Trajectory_Prediction_for_Autonomous_Driving_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_LTP_Lane-Based_Trajectory_CVPR_2022_supplemental.pdf)
1625. AP-BSN- Self-Supervised Denoising for Real-World Images via Asymmetric PD and Blind-Spot Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_AP-BSN_Self-Supervised_Denoising_for_Real-World_Images_via_Asymmetric_PD_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_AP-BSN_Self-Supervised_Denoising_for_Real-World_Images_via_Asymmetric_PD_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_AP-BSN_Self-Supervised_Denoising_CVPR_2022_supplemental.pdf)
1626. Not All Points Are Equal- Learning Highly Efficient Point-Based Detectors for 3D LiDAR Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Not_All_Points_Are_Equal_Learning_Highly_Efficient_Point-Based_Detectors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Not_All_Points_Are_Equal_Learning_Highly_Efficient_Point-Based_Detectors_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Not_All_Points_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11139)
1627. RigNeRF- Fully Controllable Neural 3D Portraits | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Athar_RigNeRF_Fully_Controllable_Neural_3D_Portraits_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Athar_RigNeRF_Fully_Controllable_Neural_3D_Portraits_CVPR_2022_paper.pdf)
1628. CLIP-Forge- Towards Zero-Shot Text-To-Shape Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sanghi_CLIP-Forge_Towards_Zero-Shot_Text-To-Shape_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sanghi_CLIP-Forge_Towards_Zero-Shot_Text-To-Shape_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sanghi_CLIP-Forge_Towards_Zero-Shot_CVPR_2022_supplemental.pdf)
1629. Instance-Dependent Label-Noise Learning With Manifold-Regularized Transition Matrix Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Instance-Dependent_Label-Noise_Learning_With_Manifold-Regularized_Transition_Matrix_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Instance-Dependent_Label-Noise_Learning_With_Manifold-Regularized_Transition_Matrix_Estimation_CVPR_2022_paper.pdf)
1630. Rethinking the Augmentation Module in Contrastive Learning- Learning Hierarchical Augmentation Invariance With Expanded Views | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Rethinking_the_Augmentation_Module_in_Contrastive_Learning_Learning_Hierarchical_Augmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Rethinking_the_Augmentation_Module_in_Contrastive_Learning_Learning_Hierarchical_Augmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2206.00227)
1631. Equivariant Point Cloud Analysis via Learning Orientations for Message Passing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Luo_Equivariant_Point_Cloud_Analysis_via_Learning_Orientations_for_Message_Passing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Equivariant_Point_Cloud_Analysis_via_Learning_Orientations_for_Message_Passing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Luo_Equivariant_Point_Cloud_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14486)
1632. Node Representation Learning in Graph via Node-to-Neighbourhood Mutual Information Maximization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Node_Representation_Learning_in_Graph_via_Node-to-Neighbourhood_Mutual_Information_Maximization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Node_Representation_Learning_in_Graph_via_Node-to-Neighbourhood_Mutual_Information_Maximization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_Node_Representation_Learning_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.12265)
1633. Point Cloud Pre-Training With Natural 3D Structures | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yamada_Point_Cloud_Pre-Training_With_Natural_3D_Structures_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yamada_Point_Cloud_Pre-Training_With_Natural_3D_Structures_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yamada_Point_Cloud_Pre-Training_CVPR_2022_supplemental.pdf)
1634. StyleT2I- Toward Compositional and High-Fidelity Text-to-Image Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_StyleT2I_Toward_Compositional_and_High-Fidelity_Text-to-Image_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_StyleT2I_Toward_Compositional_and_High-Fidelity_Text-to-Image_Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_StyleT2I_Toward_Compositional_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15799)
1635. V-Doc- Visual Questions Answers With Documents | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_V-Doc_Visual_Questions_Answers_With_Documents_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_V-Doc_Visual_Questions_Answers_With_Documents_CVPR_2022_paper.pdf)
1636. Uncertainty-Guided Probabilistic Transformer for Complex Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Uncertainty-Guided_Probabilistic_Transformer_for_Complex_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Uncertainty-Guided_Probabilistic_Transformer_for_Complex_Action_Recognition_CVPR_2022_paper.pdf)
1637. V2C- Visual Voice Cloning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_V2C_Visual_Voice_Cloning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_V2C_Visual_Voice_Cloning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_V2C_Visual_Voice_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12890)
1638. EvUnroll- Neuromorphic Events Based Rolling Shutter Image Correction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_EvUnroll_Neuromorphic_Events_Based_Rolling_Shutter_Image_Correction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_EvUnroll_Neuromorphic_Events_Based_Rolling_Shutter_Image_Correction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_EvUnroll_Neuromorphic_Events_CVPR_2022_supplemental.zip)
1639. Gait Recognition in the Wild With Dense 3D Representations and a Benchmark | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Gait_Recognition_in_the_Wild_With_Dense_3D_Representations_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Gait_Recognition_in_the_Wild_With_Dense_3D_Representations_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_Gait_Recognition_in_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02569)
1640. Temporal Context Matters- Enhancing Single Image Prediction With Disease Progression Representations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Konwer_Temporal_Context_Matters_Enhancing_Single_Image_Prediction_With_Disease_Progression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Konwer_Temporal_Context_Matters_Enhancing_Single_Image_Prediction_With_Disease_Progression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Konwer_Temporal_Context_Matters_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01933)
1641. Learning From All Vehicles | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Learning_From_All_Vehicles_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Learning_From_All_Vehicles_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Learning_From_All_CVPR_2022_supplemental.pdf)
1642. Towards Driving-Oriented Metric for Lane Detection Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sato_Towards_Driving-Oriented_Metric_for_Lane_Detection_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sato_Towards_Driving-Oriented_Metric_for_Lane_Detection_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sato_Towards_Driving-Oriented_Metric_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16851)
1643. XYDeblur- Divide and Conquer for Single Image Deblurring | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ji_XYDeblur_Divide_and_Conquer_for_Single_Image_Deblurring_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ji_XYDeblur_Divide_and_Conquer_for_Single_Image_Deblurring_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ji_XYDeblur_Divide_and_CVPR_2022_supplemental.pdf)
1644. STCrowd- A Multimodal Dataset for Pedestrian Perception in Crowded Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cong_STCrowd_A_Multimodal_Dataset_for_Pedestrian_Perception_in_Crowded_Scenes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cong_STCrowd_A_Multimodal_Dataset_for_Pedestrian_Perception_in_Crowded_Scenes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cong_STCrowd_A_Multimodal_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01026)
1645. Deep Decomposition for Stochastic Normal-Abnormal Transport | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Deep_Decomposition_for_Stochastic_Normal-Abnormal_Transport_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Deep_Decomposition_for_Stochastic_Normal-Abnormal_Transport_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Deep_Decomposition_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14777)
1646. Multimodal Material Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Multimodal_Material_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Multimodal_Material_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liang_Multimodal_Material_Segmentation_CVPR_2022_supplemental.zip)
1647. DynamicEarthNet- Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Toker_DynamicEarthNet_Daily_Multi-Spectral_Satellite_Dataset_for_Semantic_Change_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Toker_DynamicEarthNet_Daily_Multi-Spectral_Satellite_Dataset_for_Semantic_Change_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Toker_DynamicEarthNet_Daily_Multi-Spectral_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12560)
1648. Quantization-Aware Deep Optics for Diffractive Snapshot Hyperspectral Imaging | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Quantization-Aware_Deep_Optics_for_Diffractive_Snapshot_Hyperspectral_Imaging_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Quantization-Aware_Deep_Optics_for_Diffractive_Snapshot_Hyperspectral_Imaging_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Quantization-Aware_Deep_Optics_CVPR_2022_supplemental.pdf)
1649. Improving Video Model Transfer With Dynamic Representation Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Improving_Video_Model_Transfer_With_Dynamic_Representation_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Improving_Video_Model_Transfer_With_Dynamic_Representation_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Improving_Video_Model_CVPR_2022_supplemental.pdf)
1650. PIE-Net- Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Das_PIE-Net_Photometric_Invariant_Edge_Guided_Network_for_Intrinsic_Image_Decomposition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Das_PIE-Net_Photometric_Invariant_Edge_Guided_Network_for_Intrinsic_Image_Decomposition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Das_PIE-Net_Photometric_Invariant_CVPR_2022_supplemental.pdf)
1651. QS-Attn- Query-Selected Attention for Contrastive Learning in I2I Translation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_QS-Attn_Query-Selected_Attention_for_Contrastive_Learning_in_I2I_Translation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_QS-Attn_Query-Selected_Attention_for_Contrastive_Learning_in_I2I_Translation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_QS-Attn_Query-Selected_Attention_CVPR_2022_supplemental.pdf)
1652. Adaptive Gating for Single-Photon 3D Imaging | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Po_Adaptive_Gating_for_Single-Photon_3D_Imaging_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Po_Adaptive_Gating_for_Single-Photon_3D_Imaging_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Po_Adaptive_Gating_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15047)
1653. H4D- Human 4D Modeling by Learning Neural Compositional Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_H4D_Human_4D_Modeling_by_Learning_Neural_Compositional_Representation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_H4D_Human_4D_Modeling_by_Learning_Neural_Compositional_Representation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jiang_H4D_Human_4D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01247)
1654. Cannot See the Forest for the Trees- Aggregating Multiple Viewpoints To Better Classify Objects in Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hwang_Cannot_See_the_Forest_for_the_Trees_Aggregating_Multiple_Viewpoints_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hwang_Cannot_See_the_Forest_for_the_Trees_Aggregating_Multiple_Viewpoints_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hwang_Cannot_See_the_CVPR_2022_supplemental.pdf)
1655. Learning Canonical F-Correlation Projection for Compact Multiview Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_Learning_Canonical_F-Correlation_Projection_for_Compact_Multiview_Representation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Learning_Canonical_F-Correlation_Projection_for_Compact_Multiview_Representation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yuan_Learning_Canonical_F-Correlation_CVPR_2022_supplemental.pdf)
1656. DIFNet- Boosting Visual Information Flow for Image Captioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_DIFNet_Boosting_Visual_Information_Flow_for_Image_Captioning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_DIFNet_Boosting_Visual_Information_Flow_for_Image_Captioning_CVPR_2022_paper.pdf)
1657. Tree Energy Loss- Towards Sparsely Annotated Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Tree_Energy_Loss_Towards_Sparsely_Annotated_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Tree_Energy_Loss_Towards_Sparsely_Annotated_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liang_Tree_Energy_Loss_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10739)
1658. Grounding Answers for Visual Questions Asked by Visually Impaired People | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Grounding_Answers_for_Visual_Questions_Asked_by_Visually_Impaired_People_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Grounding_Answers_for_Visual_Questions_Asked_by_Visually_Impaired_People_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Grounding_Answers_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.01993)
1659. Automatic Color Image Stitching Using Quaternion Rank-1 Alignment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Automatic_Color_Image_Stitching_Using_Quaternion_Rank-1_Alignment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Automatic_Color_Image_Stitching_Using_Quaternion_Rank-1_Alignment_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Automatic_Color_Image_CVPR_2022_supplemental.zip)
1660. VisualGPT- Data-Efficient Adaptation of Pretrained Language Models for Image Captioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_VisualGPT_Data-Efficient_Adaptation_of_Pretrained_Language_Models_for_Image_Captioning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_VisualGPT_Data-Efficient_Adaptation_of_Pretrained_Language_Models_for_Image_Captioning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_VisualGPT_Data-Efficient_Adaptation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2102.10407)
1661. All-Photon Polarimetric Time-of-Flight Imaging | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Baek_All-Photon_Polarimetric_Time-of-Flight_Imaging_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Baek_All-Photon_Polarimetric_Time-of-Flight_Imaging_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Baek_All-Photon_Polarimetric_Time-of-Flight_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.09278)
1662. Towards Implicit Text-Guided 3D Shape Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Towards_Implicit_Text-Guided_3D_Shape_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Implicit_Text-Guided_3D_Shape_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Towards_Implicit_Text-Guided_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14622)
1663. A Versatile Multi-View Framework for LiDAR-Based 3D Object Detection With Guidance From Panoptic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fazlali_A_Versatile_Multi-View_Framework_for_LiDAR-Based_3D_Object_Detection_With_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fazlali_A_Versatile_Multi-View_Framework_for_LiDAR-Based_3D_Object_Detection_With_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fazlali_A_Versatile_Multi-View_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02133)
1664. RFNet- Unsupervised Network for Mutually Reinforcing Multi-Modal Image Registration and Fusion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_RFNet_Unsupervised_Network_for_Mutually_Reinforcing_Multi-Modal_Image_Registration_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_RFNet_Unsupervised_Network_for_Mutually_Reinforcing_Multi-Modal_Image_Registration_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_RFNet_Unsupervised_Network_CVPR_2022_supplemental.pdf)
1665. CellTypeGraph- A New Geometric Computer Vision Benchmark | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cerrone_CellTypeGraph_A_New_Geometric_Computer_Vision_Benchmark_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cerrone_CellTypeGraph_A_New_Geometric_Computer_Vision_Benchmark_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cerrone_CellTypeGraph_A_New_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.08166)
1666. Clustering Plotted Data by Image Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Naous_Clustering_Plotted_Data_by_Image_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Naous_Clustering_Plotted_Data_by_Image_Segmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2110.05187)
1667. Animal Kingdom- A Large and Diverse Dataset for Animal Behavior Understanding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ng_Animal_Kingdom_A_Large_and_Diverse_Dataset_for_Animal_Behavior_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ng_Animal_Kingdom_A_Large_and_Diverse_Dataset_for_Animal_Behavior_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ng_Animal_Kingdom_A_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.08129)
1668. EI-CLIP- Entity-Aware Interventional Contrastive Learning for E-Commerce Cross-Modal Retrieval | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_EI-CLIP_Entity-Aware_Interventional_Contrastive_Learning_for_E-Commerce_Cross-Modal_Retrieval_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_EI-CLIP_Entity-Aware_Interventional_Contrastive_Learning_for_E-Commerce_Cross-Modal_Retrieval_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_EI-CLIP_Entity-Aware_Interventional_CVPR_2022_supplemental.pdf)
1669. Multi-Dimensional, Nuanced and Subjective - Measuring the Perception of Facial Expressions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bryant_Multi-Dimensional_Nuanced_and_Subjective_-_Measuring_the_Perception_of_Facial_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bryant_Multi-Dimensional_Nuanced_and_Subjective_-_Measuring_the_Perception_of_Facial_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bryant_Multi-Dimensional_Nuanced_and_CVPR_2022_supplemental.zip)
1670. PyMiceTracking- An Open-Source Toolbox for Real-Time Behavioral Neuroscience Experiments | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Menezes_PyMiceTracking_An_Open-Source_Toolbox_for_Real-Time_Behavioral_Neuroscience_Experiments_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Menezes_PyMiceTracking_An_Open-Source_Toolbox_for_Real-Time_Behavioral_Neuroscience_Experiments_CVPR_2022_paper.pdf)
1671. Fine-Grained Temporal Contrastive Learning for Weakly-Supervised Temporal Action Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gao_Fine-Grained_Temporal_Contrastive_Learning_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Fine-Grained_Temporal_Contrastive_Learning_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16800)
1672. UTC- A Unified Transformer With Inter-Task Contrastive Learning for Visual Dialog | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_UTC_A_Unified_Transformer_With_Inter-Task_Contrastive_Learning_for_Visual_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_UTC_A_Unified_Transformer_With_Inter-Task_Contrastive_Learning_for_Visual_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.00423)
1673. Mimicking the Oracle- An Initial Phase Decorrelation Approach for Class Incremental Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_Mimicking_the_Oracle_An_Initial_Phase_Decorrelation_Approach_for_Class_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Mimicking_the_Oracle_An_Initial_Phase_Decorrelation_Approach_for_Class_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shi_Mimicking_the_Oracle_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.04731)
1674. RIDDLE- Lidar Data Compression With Range Image Deep Delta Encoding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_RIDDLE_Lidar_Data_Compression_With_Range_Image_Deep_Delta_Encoding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_RIDDLE_Lidar_Data_Compression_With_Range_Image_Deep_Delta_Encoding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_RIDDLE_Lidar_Data_CVPR_2022_supplemental.pdf)
1675. RelTransformer- A Transformer-Based Long-Tail Visual Relationship Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_RelTransformer_A_Transformer-Based_Long-Tail_Visual_Relationship_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_RelTransformer_A_Transformer-Based_Long-Tail_Visual_Relationship_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_RelTransformer_A_Transformer-Based_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.11934)
1676. RigidFlow- Self-Supervised Scene Flow Learning on Point Clouds by Local Rigidity Prior | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_RigidFlow_Self-Supervised_Scene_Flow_Learning_on_Point_Clouds_by_Local_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_RigidFlow_Self-Supervised_Scene_Flow_Learning_on_Point_Clouds_by_Local_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_RigidFlow_Self-Supervised_Scene_CVPR_2022_supplemental.pdf)
1677. Personalized Image Aesthetics Assessment With Rich Attributes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Personalized_Image_Aesthetics_Assessment_With_Rich_Attributes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Personalized_Image_Aesthetics_Assessment_With_Rich_Attributes_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16754)
1678. HDNet- High-Resolution Dual-Domain Learning for Spectral Compressive Imaging | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_HDNet_High-Resolution_Dual-Domain_Learning_for_Spectral_Compressive_Imaging_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_HDNet_High-Resolution_Dual-Domain_Learning_for_Spectral_Compressive_Imaging_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.02149)
1679. Amodal Panoptic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mohan_Amodal_Panoptic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mohan_Amodal_Panoptic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mohan_Amodal_Panoptic_Segmentation_CVPR_2022_supplemental.pdf)
1680. Gravitationally Lensed Black Hole Emission Tomography | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Levis_Gravitationally_Lensed_Black_Hole_Emission_Tomography_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Levis_Gravitationally_Lensed_Black_Hole_Emission_Tomography_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Levis_Gravitationally_Lensed_Black_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.03715)
1681. 3D-Aware Image Synthesis via Learning Structural and Textural Representations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_3D-Aware_Image_Synthesis_via_Learning_Structural_and_Textural_Representations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_3D-Aware_Image_Synthesis_via_Learning_Structural_and_Textural_Representations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_3D-Aware_Image_Synthesis_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.10759)
1682. Text-to-Image Synthesis Based on Object-Guided Joint-Decoding Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Text-to-Image_Synthesis_Based_on_Object-Guided_Joint-Decoding_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Text-to-Image_Synthesis_Based_on_Object-Guided_Joint-Decoding_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_Text-to-Image_Synthesis_Based_CVPR_2022_supplemental.pdf)
1683. Unsupervised Vision-and-Language Pre-Training via Retrieval-Based Multi-Granular Alignment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Unsupervised_Vision-and-Language_Pre-Training_via_Retrieval-Based_Multi-Granular_Alignment_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Unsupervised_Vision-and-Language_Pre-Training_via_Retrieval-Based_Multi-Granular_Alignment_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Unsupervised_Vision-and-Language_Pre-Training_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.00242)
1684. PONI- Potential Functions for ObjectGoal Navigation With Interaction-Free Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ramakrishnan_PONI_Potential_Functions_for_ObjectGoal_Navigation_With_Interaction-Free_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ramakrishnan_PONI_Potential_Functions_for_ObjectGoal_Navigation_With_Interaction-Free_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ramakrishnan_PONI_Potential_Functions_CVPR_2022_supplemental.zip)
1685. Exploring Structure-Aware Transformer Over Interaction Proposals for Human-Object Interaction Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Exploring_Structure-Aware_Transformer_Over_Interaction_Proposals_for_Human-Object_Interaction_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Exploring_Structure-Aware_Transformer_Over_Interaction_Proposals_for_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Exploring_Structure-Aware_Transformer_CVPR_2022_supplemental.pdf)
1686. Glass- Geometric Latent Augmentation for Shape Spaces | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Muralikrishnan_Glass_Geometric_Latent_Augmentation_for_Shape_Spaces_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Muralikrishnan_Glass_Geometric_Latent_Augmentation_for_Shape_Spaces_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2108.03225)
1687. Evading the Simplicity Bias- Training a Diverse Set of Models Discovers Solutions With Superior OOD Generalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Teney_Evading_the_Simplicity_Bias_Training_a_Diverse_Set_of_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Teney_Evading_the_Simplicity_Bias_Training_a_Diverse_Set_of_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Teney_Evading_the_Simplicity_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2105.05612)
1688. Assembly101- A Large-Scale Multi-View Video Dataset for Understanding Procedural Activities | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sener_Assembly101_A_Large-Scale_Multi-View_Video_Dataset_for_Understanding_Procedural_Activities_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sener_Assembly101_A_Large-Scale_Multi-View_Video_Dataset_for_Understanding_Procedural_Activities_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sener_Assembly101_A_Large-Scale_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14712)
1689. DPICT- Deep Progressive Image Compression Using Trit-Planes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_DPICT_Deep_Progressive_Image_Compression_Using_Trit-Planes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_DPICT_Deep_Progressive_Image_Compression_Using_Trit-Planes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_DPICT_Deep_Progressive_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2112.06334)
1690. Text to Image Generation With Semantic-Spatial Aware GAN | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liao_Text_to_Image_Generation_With_Semantic-Spatial_Aware_GAN_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Text_to_Image_Generation_With_Semantic-Spatial_Aware_GAN_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2104.00567)
1691. PixMix- Dreamlike Pictures Comprehensively Improve Safety Measures | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hendrycks_PixMix_Dreamlike_Pictures_Comprehensively_Improve_Safety_Measures_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hendrycks_PixMix_Dreamlike_Pictures_Comprehensively_Improve_Safety_Measures_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hendrycks_PixMix_Dreamlike_Pictures_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.05135)
1692. Generalizable Cross-Modality Medical Image Segmentation via Style Augmentation and Dual Normalization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Generalizable_Cross-Modality_Medical_Image_Segmentation_via_Style_Augmentation_and_Dual_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Generalizable_Cross-Modality_Medical_Image_Segmentation_via_Style_Augmentation_and_Dual_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Generalizable_Cross-Modality_Medical_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.11177)
1693. TimeReplayer- Unlocking the Potential of Event Cameras for Video Interpolation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_TimeReplayer_Unlocking_the_Potential_of_Event_Cameras_for_Video_Interpolation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_TimeReplayer_Unlocking_the_Potential_of_Event_Cameras_for_Video_Interpolation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_TimeReplayer_Unlocking_the_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.13859)
1694. Interactive Segmentation and Visualization for Tiny Objects in Multi-Megapixel Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Interactive_Segmentation_and_Visualization_for_Tiny_Objects_in_Multi-Megapixel_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Interactive_Segmentation_and_Visualization_for_Tiny_Objects_in_Multi-Megapixel_Images_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.10356)
1695. Scaling Vision Transformers to Gigapixel Images via Hierarchical Self-Supervised Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Scaling_Vision_Transformers_to_Gigapixel_Images_via_Hierarchical_Self-Supervised_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Scaling_Vision_Transformers_to_Gigapixel_Images_via_Hierarchical_Self-Supervised_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Scaling_Vision_Transformers_CVPR_2022_supplemental.pdf)
1696. Neural Reflectance for Shape Recovery With Shadow Handling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Neural_Reflectance_for_Shape_Recovery_With_Shadow_Handling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Neural_Reflectance_for_Shape_Recovery_With_Shadow_Handling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Neural_Reflectance_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12909)
1697. Surface Representation for Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ran_Surface_Representation_for_Point_Clouds_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ran_Surface_Representation_for_Point_Clouds_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ran_Surface_Representation_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.05740)
1698. DeepLIIF- An Online Platform for Quantification of Clinical Pathology Slides | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ghahremani_DeepLIIF_An_Online_Platform_for_Quantification_of_Clinical_Pathology_Slides_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ghahremani_DeepLIIF_An_Online_Platform_for_Quantification_of_Clinical_Pathology_Slides_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.04494)
1699. Joint Video Summarization and Moment Localization by Cross-Task Sample Transfer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Joint_Video_Summarization_and_Moment_Localization_by_Cross-Task_Sample_Transfer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Joint_Video_Summarization_and_Moment_Localization_by_Cross-Task_Sample_Transfer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jiang_Joint_Video_Summarization_CVPR_2022_supplemental.pdf)
1700. Optical Flow Estimation for Spiking Camera | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Optical_Flow_Estimation_for_Spiking_Camera_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Optical_Flow_Estimation_for_Spiking_Camera_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_Optical_Flow_Estimation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.03916)
1701. InstaFormer- Instance-Aware Image-to-Image Translation With Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_InstaFormer_Instance-Aware_Image-to-Image_Translation_With_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_InstaFormer_Instance-Aware_Image-to-Image_Translation_With_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_InstaFormer_Instance-Aware_Image-to-Image_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16248)
1702. 3D-VField- Adversarial Augmentation of Point Clouds for Domain Generalization in 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lehner_3D-VField_Adversarial_Augmentation_of_Point_Clouds_for_Domain_Generalization_in_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lehner_3D-VField_Adversarial_Augmentation_of_Point_Clouds_for_Domain_Generalization_in_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lehner_3D-VField_Adversarial_Augmentation_CVPR_2022_supplemental.pdf)
1703. AutoMine- An Unmanned Mine Dataset | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_AutoMine_An_Unmanned_Mine_Dataset_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_AutoMine_An_Unmanned_Mine_Dataset_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_AutoMine_An_Unmanned_CVPR_2022_supplemental.pdf)
1704. Neural Data-Dependent Transform for Learned Image Compression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Neural_Data-Dependent_Transform_for_Learned_Image_Compression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Neural_Data-Dependent_Transform_for_Learned_Image_Compression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Neural_Data-Dependent_Transform_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04963)
1705. Evaluation-Oriented Knowledge Distillation for Deep Face Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Evaluation-Oriented_Knowledge_Distillation_for_Deep_Face_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Evaluation-Oriented_Knowledge_Distillation_for_Deep_Face_Recognition_CVPR_2022_paper.pdf)
1706. Improving Subgraph Recognition With Variational Graph Information Bottleneck | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Improving_Subgraph_Recognition_With_Variational_Graph_Information_Bottleneck_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Improving_Subgraph_Recognition_With_Variational_Graph_Information_Bottleneck_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.09899)
1707. Synthetic Generation of Face Videos With Plethysmograph Physiology | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Synthetic_Generation_of_Face_Videos_With_Plethysmograph_Physiology_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Synthetic_Generation_of_Face_Videos_With_Plethysmograph_Physiology_CVPR_2022_paper.pdf)
1708. TransRAC- Encoding Multi-Scale Temporal Correlation With Transformers for Repetitive Action Counting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_TransRAC_Encoding_Multi-Scale_Temporal_Correlation_With_Transformers_for_Repetitive_Action_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_TransRAC_Encoding_Multi-Scale_Temporal_Correlation_With_Transformers_for_Repetitive_Action_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hu_TransRAC_Encoding_Multi-Scale_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01018)
1709. AdaInt- Learning Adaptive Intervals for 3D Lookup Tables on Real-Time Image Enhancement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_AdaInt_Learning_Adaptive_Intervals_for_3D_Lookup_Tables_on_Real-Time_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_AdaInt_Learning_Adaptive_Intervals_for_3D_Lookup_Tables_on_Real-Time_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_AdaInt_Learning_Adaptive_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.13983)
1710. RegionCLIP- Region-Based Language-Image Pretraining | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_RegionCLIP_Region-Based_Language-Image_Pretraining_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_RegionCLIP_Region-Based_Language-Image_Pretraining_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhong_RegionCLIP_Region-Based_Language-Image_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.09106)
1711. Video Frame Interpolation Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_Video_Frame_Interpolation_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Video_Frame_Interpolation_Transformer_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.13817)
1712. An Empirical Study of End-to-End Temporal Action Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_An_Empirical_Study_of_End-to-End_Temporal_Action_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_An_Empirical_Study_of_End-to-End_Temporal_Action_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_An_Empirical_Study_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02932)
1713. Brain-Supervised Image Editing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Davis_Brain-Supervised_Image_Editing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Davis_Brain-Supervised_Image_Editing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Davis_Brain-Supervised_Image_Editing_CVPR_2022_supplemental.zip)
1714. 3D Shape Variational Autoencoder Latent Disentanglement via Mini-Batch Feature Swapping for Bodies and Faces | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Foti_3D_Shape_Variational_Autoencoder_Latent_Disentanglement_via_Mini-Batch_Feature_Swapping_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Foti_3D_Shape_Variational_Autoencoder_Latent_Disentanglement_via_Mini-Batch_Feature_Swapping_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Foti_3D_Shape_Variational_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12448)
1715. RestoreFormer- High-Quality Blind Face Restoration From Undegraded Key-Value Pairs | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_RestoreFormer_High-Quality_Blind_Face_Restoration_From_Undegraded_Key-Value_Pairs_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RestoreFormer_High-Quality_Blind_Face_Restoration_From_Undegraded_Key-Value_Pairs_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_RestoreFormer_High-Quality_Blind_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.06374)
1716. Mask-Guided Spectral-Wise Transformer for Efficient Hyperspectral Image Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cai_Mask-Guided_Spectral-Wise_Transformer_for_Efficient_Hyperspectral_Image_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Mask-Guided_Spectral-Wise_Transformer_for_Efficient_Hyperspectral_Image_Reconstruction_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.07910)
1717. PPDL- Predicate Probability Distribution Based Loss for Unbiased Scene Graph Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_PPDL_Predicate_Probability_Distribution_Based_Loss_for_Unbiased_Scene_Graph_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_PPDL_Predicate_Probability_Distribution_Based_Loss_for_Unbiased_Scene_Graph_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_PPDL_Predicate_Probability_CVPR_2022_supplemental.pdf)
1718. Coupling Vision and Proprioception for Navigation of Legged Robots | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fu_Coupling_Vision_and_Proprioception_for_Navigation_of_Legged_Robots_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_Coupling_Vision_and_Proprioception_for_Navigation_of_Legged_Robots_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fu_Coupling_Vision_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02094)
1719. Fine-Grained Predicates Learning for Scene Graph Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lyu_Fine-Grained_Predicates_Learning_for_Scene_Graph_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lyu_Fine-Grained_Predicates_Learning_for_Scene_Graph_Generation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.02597)
1720. Neural Head Avatars From Monocular RGB Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Grassal_Neural_Head_Avatars_From_Monocular_RGB_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Grassal_Neural_Head_Avatars_From_Monocular_RGB_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Grassal_Neural_Head_Avatars_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01554)
1721. EMOCA- Emotion Driven Monocular Face Capture and Animation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Danecek_EMOCA_Emotion_Driven_Monocular_Face_Capture_and_Animation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Danecek_EMOCA_Emotion_Driven_Monocular_Face_Capture_and_Animation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Danecek_EMOCA_Emotion_Driven_CVPR_2022_supplemental.pdf)
1722. Towards Diverse and Natural Scene-Aware 3D Human Motion Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Towards_Diverse_and_Natural_Scene-Aware_3D_Human_Motion_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Towards_Diverse_and_Natural_Scene-Aware_3D_Human_Motion_Synthesis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Towards_Diverse_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.13001)
1723. How Much Does Input Data Type Impact Final Face Model Accuracy- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Luo_How_Much_Does_Input_Data_Type_Impact_Final_Face_Model_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_How_Much_Does_Input_Data_Type_Impact_Final_Face_Model_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Luo_How_Much_Does_CVPR_2022_supplemental.pdf)
1724. HumanNeRF- Free-Viewpoint Rendering of Moving People From Monocular Video | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Weng_HumanNeRF_Free-Viewpoint_Rendering_of_Moving_People_From_Monocular_Video_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Weng_HumanNeRF_Free-Viewpoint_Rendering_of_Moving_People_From_Monocular_Video_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Weng_HumanNeRF_Free-Viewpoint_Rendering_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.04127)
1725. Which Images To Label for Few-Shot Medical Landmark Detection- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Quan_Which_Images_To_Label_for_Few-Shot_Medical_Landmark_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Quan_Which_Images_To_Label_for_Few-Shot_Medical_Landmark_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.04386)
1726. UBoCo- Unsupervised Boundary Contrastive Learning for Generic Event Boundary Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kang_UBoCo_Unsupervised_Boundary_Contrastive_Learning_for_Generic_Event_Boundary_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_UBoCo_Unsupervised_Boundary_Contrastive_Learning_for_Generic_Event_Boundary_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kang_UBoCo_Unsupervised_Boundary_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14799)
1727. Both Style and Fog Matter- Cumulative Domain Adaptation for Semantic Foggy Scene Understanding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Both_Style_and_Fog_Matter_Cumulative_Domain_Adaptation_for_Semantic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Both_Style_and_Fog_Matter_Cumulative_Domain_Adaptation_for_Semantic_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.00484)
1728. Ev-TTA- Test-Time Adaptation for Event-Based Object Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Ev-TTA_Test-Time_Adaptation_for_Event-Based_Object_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Ev-TTA_Test-Time_Adaptation_for_Event-Based_Object_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Ev-TTA_Test-Time_Adaptation_CVPR_2022_supplemental.pdf)
1729. NODEO- A Neural Ordinary Differential Equation Based Optimization Framework for Deformable Image Registration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_NODEO_A_Neural_Ordinary_Differential_Equation_Based_Optimization_Framework_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_NODEO_A_Neural_Ordinary_Differential_Equation_Based_Optimization_Framework_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_NODEO_A_Neural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2108.03443)
1730. Pyramid Architecture for Multi-Scale Processing in Point Cloud Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nie_Pyramid_Architecture_for_Multi-Scale_Processing_in_Point_Cloud_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nie_Pyramid_Architecture_for_Multi-Scale_Processing_in_Point_Cloud_Segmentation_CVPR_2022_paper.pdf)
1731. Cross-Architecture Self-Supervised Video Representation Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Cross-Architecture_Self-Supervised_Video_Representation_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Cross-Architecture_Self-Supervised_Video_Representation_Learning_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.13313)
1732. High-Resolution Image Harmonization via Collaborative Dual Transformations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cong_High-Resolution_Image_Harmonization_via_Collaborative_Dual_Transformations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cong_High-Resolution_Image_Harmonization_via_Collaborative_Dual_Transformations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cong_High-Resolution_Image_Harmonization_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2109.06671)
1733. MM-TTA- Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shin_MM-TTA_Multi-Modal_Test-Time_Adaptation_for_3D_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shin_MM-TTA_Multi-Modal_Test-Time_Adaptation_for_3D_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shin_MM-TTA_Multi-Modal_Test-Time_CVPR_2022_supplemental.pdf)
1734. Towards Bidirectional Arbitrary Image Rescaling- Joint Optimization and Cycle Idempotence | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pan_Towards_Bidirectional_Arbitrary_Image_Rescaling_Joint_Optimization_and_Cycle_Idempotence_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Towards_Bidirectional_Arbitrary_Image_Rescaling_Joint_Optimization_and_Cycle_Idempotence_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.00911)
1735. Topology Preserving Local Road Network Estimation From Single Onboard Camera Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Can_Topology_Preserving_Local_Road_Network_Estimation_From_Single_Onboard_Camera_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Can_Topology_Preserving_Local_Road_Network_Estimation_From_Single_Onboard_Camera_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Can_Topology_Preserving_Local_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.10155)
1736. Eigenlanes- Data-Driven Lane Descriptors for Structurally Diverse Lanes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jin_Eigenlanes_Data-Driven_Lane_Descriptors_for_Structurally_Diverse_Lanes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Eigenlanes_Data-Driven_Lane_Descriptors_for_Structurally_Diverse_Lanes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jin_Eigenlanes_Data-Driven_Lane_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.15302)
1737. SpaceEdit- Learning a Unified Editing Space for Open-Domain Image Color Editing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_SpaceEdit_Learning_a_Unified_Editing_Space_for_Open-Domain_Image_Color_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_SpaceEdit_Learning_a_Unified_Editing_Space_for_Open-Domain_Image_Color_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shi_SpaceEdit_Learning_a_CVPR_2022_supplemental.pdf)
1738. Multi-Level Feature Learning for Contrastive Multi-View Clustering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Multi-Level_Feature_Learning_for_Contrastive_Multi-View_Clustering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Multi-Level_Feature_Learning_for_Contrastive_Multi-View_Clustering_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2106.11193)
1739. Egocentric Prediction of Action Target in 3D | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Egocentric_Prediction_of_Action_Target_in_3D_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Egocentric_Prediction_of_Action_Target_in_3D_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Egocentric_Prediction_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13116)
1740. Towards Real-World Navigation With Deep Differentiable Planners | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ishida_Towards_Real-World_Navigation_With_Deep_Differentiable_Planners_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ishida_Towards_Real-World_Navigation_With_Deep_Differentiable_Planners_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ishida_Towards_Real-World_Navigation_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2108.05713)
1741. Video K-Net- A Simple, Strong, and Unified Baseline for Video Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Video_K-Net_A_Simple_Strong_and_Unified_Baseline_for_Video_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Video_K-Net_A_Simple_Strong_and_Unified_Baseline_for_Video_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Video_K-Net_A_CVPR_2022_supplemental.zip)
1742. NeRFReN- Neural Radiance Fields With Reflections | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_NeRFReN_Neural_Radiance_Fields_With_Reflections_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_NeRFReN_Neural_Radiance_Fields_With_Reflections_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_NeRFReN_Neural_Radiance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.15234)
1743. SCS-Co- Self-Consistent Style Contrastive Learning for Image Harmonization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hang_SCS-Co_Self-Consistent_Style_Contrastive_Learning_for_Image_Harmonization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hang_SCS-Co_Self-Consistent_Style_Contrastive_Learning_for_Image_Harmonization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hang_SCS-Co_Self-Consistent_Style_CVPR_2022_supplemental.pdf)
1744. Neural Convolutional Surfaces | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Morreale_Neural_Convolutional_Surfaces_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Morreale_Neural_Convolutional_Surfaces_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Morreale_Neural_Convolutional_Surfaces_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02289)
1745. HyperSegNAS- Bridging One-Shot Neural Architecture Search With 3D Medical Image Segmentation Using HyperNet | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Peng_HyperSegNAS_Bridging_One-Shot_Neural_Architecture_Search_With_3D_Medical_Image_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_HyperSegNAS_Bridging_One-Shot_Neural_Architecture_Search_With_3D_Medical_Image_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Peng_HyperSegNAS_Bridging_One-Shot_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.10652)
1746. A Comprehensive Study of Image Classification Model Sensitivity to Foregrounds, Backgrounds, and Visual Attributes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Moayeri_A_Comprehensive_Study_of_Image_Classification_Model_Sensitivity_to_Foregrounds_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Moayeri_A_Comprehensive_Study_of_Image_Classification_Model_Sensitivity_to_Foregrounds_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Moayeri_A_Comprehensive_Study_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.10766)
1747. ConDor- Self-Supervised Canonicalization of 3D Pose for Partial Shapes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sajnani_ConDor_Self-Supervised_Canonicalization_of_3D_Pose_for_Partial_Shapes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sajnani_ConDor_Self-Supervised_Canonicalization_of_3D_Pose_for_Partial_Shapes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sajnani_ConDor_Self-Supervised_Canonicalization_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.07788)
1748. Exploring Endogenous Shift for Cross-Domain Detection- A Large-Scale Benchmark and Perturbation Suppression Network | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tao_Exploring_Endogenous_Shift_for_Cross-Domain_Detection_A_Large-Scale_Benchmark_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Exploring_Endogenous_Shift_for_Cross-Domain_Detection_A_Large-Scale_Benchmark_and_CVPR_2022_paper.pdf)
1749. VisCUIT- Visual Auditor for Bias in CNN Image Classifier | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_VisCUIT_Visual_Auditor_for_Bias_in_CNN_Image_Classifier_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_VisCUIT_Visual_Auditor_for_Bias_in_CNN_Image_Classifier_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.05899)
1750. DirecFormer- A Directed Attention in Transformer Approach to Robust Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Truong_DirecFormer_A_Directed_Attention_in_Transformer_Approach_to_Robust_Action_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Truong_DirecFormer_A_Directed_Attention_in_Transformer_Approach_to_Robust_Action_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.10233)
1751. Robust Egocentric Photo-Realistic Facial Expression Transfer for Virtual Reality | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jourabloo_Robust_Egocentric_Photo-Realistic_Facial_Expression_Transfer_for_Virtual_Reality_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jourabloo_Robust_Egocentric_Photo-Realistic_Facial_Expression_Transfer_for_Virtual_Reality_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2104.04794)
1752. Distillation Using Oracle Queries for Transformer-Based Human-Object Interaction Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qu_Distillation_Using_Oracle_Queries_for_Transformer-Based_Human-Object_Interaction_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qu_Distillation_Using_Oracle_Queries_for_Transformer-Based_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Qu_Distillation_Using_Oracle_CVPR_2022_supplemental.pdf)
1753. Learning Video Representations of Human Motion From Synthetic Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Learning_Video_Representations_of_Human_Motion_From_Synthetic_Data_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Learning_Video_Representations_of_Human_Motion_From_Synthetic_Data_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_Learning_Video_Representations_CVPR_2022_supplemental.pdf)
1754. BoostMIS- Boosting Medical Image Semi-Supervised Learning With Adaptive Pseudo Labeling and Informative Active Annotation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_BoostMIS_Boosting_Medical_Image_Semi-Supervised_Learning_With_Adaptive_Pseudo_Labeling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_BoostMIS_Boosting_Medical_Image_Semi-Supervised_Learning_With_Adaptive_Pseudo_Labeling_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.02533)
1755. HOI4D- A 4D Egocentric Dataset for Category-Level Human-Object Interaction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_HOI4D_A_4D_Egocentric_Dataset_for_Category-Level_Human-Object_Interaction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_HOI4D_A_4D_Egocentric_Dataset_for_Category-Level_Human-Object_Interaction_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.01577)
1756. Collaborative Transformers for Grounded Situation Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cho_Collaborative_Transformers_for_Grounded_Situation_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cho_Collaborative_Transformers_for_Grounded_Situation_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cho_Collaborative_Transformers_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16518)
1757. Vox2Cortex- Fast Explicit Reconstruction of Cortical Surfaces From 3D MRI Scans With Geometric Deep Neural Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bongratz_Vox2Cortex_Fast_Explicit_Reconstruction_of_Cortical_Surfaces_From_3D_MRI_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bongratz_Vox2Cortex_Fast_Explicit_Reconstruction_of_Cortical_Surfaces_From_3D_MRI_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bongratz_Vox2Cortex_Fast_Explicit_CVPR_2022_supplemental.pdf)
1758. ScanQA- 3D Question Answering for Spatial Scene Understanding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Azuma_ScanQA_3D_Question_Answering_for_Spatial_Scene_Understanding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Azuma_ScanQA_3D_Question_Answering_for_Spatial_Scene_Understanding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Azuma_ScanQA_3D_Question_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.10482)
1759. Class-Incremental Learning by Knowledge Distillation With Adaptive Feature Consolidation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kang_Class-Incremental_Learning_by_Knowledge_Distillation_With_Adaptive_Feature_Consolidation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Class-Incremental_Learning_by_Knowledge_Distillation_With_Adaptive_Feature_Consolidation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kang_Class-Incremental_Learning_by_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00895)
1760. Learning Program Representations for Food Images and Cooking Recipes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Papadopoulos_Learning_Program_Representations_for_Food_Images_and_Cooking_Recipes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Papadopoulos_Learning_Program_Representations_for_Food_Images_and_Cooking_Recipes_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.16071)
1761. Directional Self-Supervised Learning for Heavy Image Augmentations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bai_Directional_Self-Supervised_Learning_for_Heavy_Image_Augmentations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Directional_Self-Supervised_Learning_for_Heavy_Image_Augmentations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bai_Directional_Self-Supervised_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2110.13555)
1762. No-Reference Point Cloud Quality Assessment via Domain Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_No-Reference_Point_Cloud_Quality_Assessment_via_Domain_Adaptation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_No-Reference_Point_Cloud_Quality_Assessment_via_Domain_Adaptation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.02851)
1763. Comprehending and Ordering Semantics for Image Captioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Comprehending_and_Ordering_Semantics_for_Image_Captioning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Comprehending_and_Ordering_Semantics_for_Image_Captioning_CVPR_2022_paper.pdf)
1764. A Large-Scale Comprehensive Dataset and Copy-Overlap Aware Evaluation Protocol for Segment-Level Video Copy Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_A_Large-Scale_Comprehensive_Dataset_and_Copy-Overlap_Aware_Evaluation_Protocol_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_A_Large-Scale_Comprehensive_Dataset_and_Copy-Overlap_Aware_Evaluation_Protocol_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_A_Large-Scale_Comprehensive_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02654)
1765. GaTector- A Unified Framework for Gaze Object Prediction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_GaTector_A_Unified_Framework_for_Gaze_Object_Prediction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_GaTector_A_Unified_Framework_for_Gaze_Object_Prediction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_GaTector_A_Unified_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.03549)
1766. LaTr- Layout-Aware Transformer for Scene-Text VQA | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Biten_LaTr_Layout-Aware_Transformer_for_Scene-Text_VQA_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Biten_LaTr_Layout-Aware_Transformer_for_Scene-Text_VQA_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Biten_LaTr_Layout-Aware_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.12494)
1767. HeadNeRF- A Real-Time NeRF-Based Parametric Head Model | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hong_HeadNeRF_A_Real-Time_NeRF-Based_Parametric_Head_Model_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_HeadNeRF_A_Real-Time_NeRF-Based_Parametric_Head_Model_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.05637)
1768. Replacing Labeled Real-Image Datasets With Auto-Generated Contours | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kataoka_Replacing_Labeled_Real-Image_Datasets_With_Auto-Generated_Contours_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kataoka_Replacing_Labeled_Real-Image_Datasets_With_Auto-Generated_Contours_CVPR_2022_paper.pdf)
1769. WebQA- Multihop and Multimodal QA | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chang_WebQA_Multihop_and_Multimodal_QA_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_WebQA_Multihop_and_Multimodal_QA_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chang_WebQA_Multihop_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2109.00590)
1770. Towards Language-Free Training for Text-to-Image Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Towards_Language-Free_Training_for_Text-to-Image_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Towards_Language-Free_Training_for_Text-to-Image_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Towards_Language-Free_Training_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13792)
1771. Learning Affinity From Attention- End-to-End Weakly-Supervised Semantic Segmentation With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ru_Learning_Affinity_From_Attention_End-to-End_Weakly-Supervised_Semantic_Segmentation_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ru_Learning_Affinity_From_Attention_End-to-End_Weakly-Supervised_Semantic_Segmentation_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ru_Learning_Affinity_From_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02664)
1772. FERV39k- A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_FERV39k_A_Large-Scale_Multi-Scene_Dataset_for_Facial_Expression_Recognition_in_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_FERV39k_A_Large-Scale_Multi-Scene_Dataset_for_Facial_Expression_Recognition_in_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_FERV39k_A_Large-Scale_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09463)
1773. Omnivore- A Single Model for Many Visual Modalities | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Girdhar_Omnivore_A_Single_Model_for_Many_Visual_Modalities_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Girdhar_Omnivore_A_Single_Model_for_Many_Visual_Modalities_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Girdhar_Omnivore_A_Single_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.08377)
1774. DAIR-V2X- A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_DAIR-V2X_A_Large-Scale_Dataset_for_Vehicle-Infrastructure_Cooperative_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_DAIR-V2X_A_Large-Scale_Dataset_for_Vehicle-Infrastructure_Cooperative_3D_Object_Detection_CVPR_2022_paper.pdf)
1775. Uncertainty-Aware Adaptation for Self-Supervised 3D Human Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kundu_Uncertainty-Aware_Adaptation_for_Self-Supervised_3D_Human_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kundu_Uncertainty-Aware_Adaptation_for_Self-Supervised_3D_Human_Pose_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kundu_Uncertainty-Aware_Adaptation_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15293)
1776. Semi-Supervised Wide-Angle Portraits Correction by Multi-Scale Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Semi-Supervised_Wide-Angle_Portraits_Correction_by_Multi-Scale_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Semi-Supervised_Wide-Angle_Portraits_Correction_by_Multi-Scale_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Semi-Supervised_Wide-Angle_Portraits_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2109.08024)
1777. Is Mapping Necessary for Realistic PointGoal Navigation- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Partsey_Is_Mapping_Necessary_for_Realistic_PointGoal_Navigation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Partsey_Is_Mapping_Necessary_for_Realistic_PointGoal_Navigation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Partsey_Is_Mapping_Necessary_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2206.00997)
1778. Node-Aligned Graph Convolutional Network for Whole-Slide Image Representation and Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guan_Node-Aligned_Graph_Convolutional_Network_for_Whole-Slide_Image_Representation_and_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Node-Aligned_Graph_Convolutional_Network_for_Whole-Slide_Image_Representation_and_Classification_CVPR_2022_paper.pdf)
1779. Object-Relation Reasoning Graph for Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ou_Object-Relation_Reasoning_Graph_for_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ou_Object-Relation_Reasoning_Graph_for_Action_Recognition_CVPR_2022_paper.pdf)
1780. FaceVerse- A Fine-Grained and Detail-Controllable 3D Face Morphable Model From a Hybrid Dataset | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_FaceVerse_A_Fine-Grained_and_Detail-Controllable_3D_Face_Morphable_Model_From_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_FaceVerse_A_Fine-Grained_and_Detail-Controllable_3D_Face_Morphable_Model_From_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_FaceVerse_A_Fine-Grained_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14057)
1781. Bring Evanescent Representations to Life in Lifelong Class Incremental Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Toldo_Bring_Evanescent_Representations_to_Life_in_Lifelong_Class_Incremental_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Toldo_Bring_Evanescent_Representations_to_Life_in_Lifelong_Class_Incremental_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Toldo_Bring_Evanescent_Representations_CVPR_2022_supplemental.pdf)
1782. Look Back and Forth- Video Super-Resolution With Explicit Temporal Difference Modeling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Isobe_Look_Back_and_Forth_Video_Super-Resolution_With_Explicit_Temporal_Difference_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Isobe_Look_Back_and_Forth_Video_Super-Resolution_With_Explicit_Temporal_Difference_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.07114)
1783. A Stitch in Time Saves Nine- A Train-Time Regularizing Loss for Improved Neural Network Calibration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hebbalaguppe_A_Stitch_in_Time_Saves_Nine_A_Train-Time_Regularizing_Loss_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hebbalaguppe_A_Stitch_in_Time_Saves_Nine_A_Train-Time_Regularizing_Loss_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hebbalaguppe_A_Stitch_in_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13834)
1784. Deep Image-Based Illumination Harmonization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bao_Deep_Image-Based_Illumination_Harmonization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_Deep_Image-Based_Illumination_Harmonization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bao_Deep_Image-Based_Illumination_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2108.00150)
1785. Harmony- A Generic Unsupervised Approach for Disentangling Semantic Content From Parameterized Transformations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Uddin_Harmony_A_Generic_Unsupervised_Approach_for_Disentangling_Semantic_Content_From_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Uddin_Harmony_A_Generic_Unsupervised_Approach_for_Disentangling_Semantic_Content_From_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Uddin_Harmony_A_Generic_CVPR_2022_supplemental.pdf)
1786. Talking Face Generation With Multilingual TTS | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Song_Talking_Face_Generation_With_Multilingual_TTS_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Song_Talking_Face_Generation_With_Multilingual_TTS_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.06421)
1787. Kernelized Few-Shot Object Detection With Efficient Integral Aggregation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Kernelized_Few-Shot_Object_Detection_With_Efficient_Integral_Aggregation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Kernelized_Few-Shot_Object_Detection_With_Efficient_Integral_Aggregation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Kernelized_Few-Shot_Object_CVPR_2022_supplemental.pdf)
1788. Context-Aware Video Reconstruction for Rolling Shutter Cameras | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Context-Aware_Video_Reconstruction_for_Rolling_Shutter_Cameras_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Context-Aware_Video_Reconstruction_for_Rolling_Shutter_Cameras_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fan_Context-Aware_Video_Reconstruction_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2205.12912)
1789. Robust Contrastive Learning Against Noisy Views | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chuang_Robust_Contrastive_Learning_Against_Noisy_Views_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chuang_Robust_Contrastive_Learning_Against_Noisy_Views_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chuang_Robust_Contrastive_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.04309)
1790. RSTT- Real-Time Spatial Temporal Transformer for Space-Time Video Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Geng_RSTT_Real-Time_Spatial_Temporal_Transformer_for_Space-Time_Video_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Geng_RSTT_Real-Time_Spatial_Temporal_Transformer_for_Space-Time_Video_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Geng_RSTT_Real-Time_Spatial_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14186)
1791. Learning Memory-Augmented Unidirectional Metrics for Cross-Modality Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_Memory-Augmented_Unidirectional_Metrics_for_Cross-Modality_Person_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Memory-Augmented_Unidirectional_Metrics_for_Cross-Modality_Person_Re-Identification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Learning_Memory-Augmented_Unidirectional_CVPR_2022_supplemental.pdf)
1792. Partial Class Activation Attention for Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Partial_Class_Activation_Attention_for_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Partial_Class_Activation_Attention_for_Semantic_Segmentation_CVPR_2022_paper.pdf)
1793. SkinningNet- Two-Stream Graph Convolutional Neural Network for Skinning Prediction of Synthetic Characters | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mosella-Montoro_SkinningNet_Two-Stream_Graph_Convolutional_Neural_Network_for_Skinning_Prediction_of_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mosella-Montoro_SkinningNet_Two-Stream_Graph_Convolutional_Neural_Network_for_Skinning_Prediction_of_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mosella-Montoro_SkinningNet_Two-Stream_Graph_CVPR_2022_supplemental.zip)
1794. Cross-Modal Representation Learning for Zero-Shot Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Cross-Modal_Representation_Learning_for_Zero-Shot_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Cross-Modal_Representation_Learning_for_Zero-Shot_Action_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_Cross-Modal_Representation_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.01657)
1795. Conditional Prompt Learning for Vision-Language Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Conditional_Prompt_Learning_for_Vision-Language_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Conditional_Prompt_Learning_for_Vision-Language_Models_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.05557)
1796. Affine Medical Image Registration With Coarse-To-Fine Vision Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mok_Affine_Medical_Image_Registration_With_Coarse-To-Fine_Vision_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mok_Affine_Medical_Image_Registration_With_Coarse-To-Fine_Vision_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mok_Affine_Medical_Image_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15216)
1797. SMPL-A- Modeling Person-Specific Deformable Anatomy | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_SMPL-A_Modeling_Person-Specific_Deformable_Anatomy_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_SMPL-A_Modeling_Person-Specific_Deformable_Anatomy_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_SMPL-A_Modeling_Person-Specific_CVPR_2022_supplemental.pdf)
1798. A Differentiable Two-Stage Alignment Scheme for Burst Image Reconstruction With Large Shift | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Guo_A_Differentiable_Two-Stage_Alignment_Scheme_for_Burst_Image_Reconstruction_With_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_A_Differentiable_Two-Stage_Alignment_Scheme_for_Burst_Image_Reconstruction_With_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Guo_A_Differentiable_Two-Stage_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09294)
1799. Unifying Panoptic Segmentation for Autonomous Driving | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zendel_Unifying_Panoptic_Segmentation_for_Autonomous_Driving_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zendel_Unifying_Panoptic_Segmentation_for_Autonomous_Driving_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zendel_Unifying_Panoptic_Segmentation_CVPR_2022_supplemental.pdf)
1800. On the Road to Online Adaptation for Semantic Image Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Volpi_On_the_Road_to_Online_Adaptation_for_Semantic_Image_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Volpi_On_the_Road_to_Online_Adaptation_for_Semantic_Image_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Volpi_On_the_Road_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16195)
1801. Masked Autoencoders Are Scalable Vision Learners | [link](https://openaccess.thecvf.com/content/CVPR2022/html/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/He_Masked_Autoencoders_Are_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.06377)
1802. Point-BERT- Pre-Training 3D Point Cloud Transformers With Masked Point Modeling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Point-BERT_Pre-Training_3D_Point_Cloud_Transformers_With_Masked_Point_Modeling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Point-BERT_Pre-Training_3D_Point_Cloud_Transformers_With_Masked_Point_Modeling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yu_Point-BERT_Pre-Training_3D_CVPR_2022_supplemental.pdf)
1803. Crowd Counting in the Frequency Domain | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shu_Crowd_Counting_in_the_Frequency_Domain_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shu_Crowd_Counting_in_the_Frequency_Domain_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shu_Crowd_Counting_in_CVPR_2022_supplemental.pdf)
1804. Aladdin- Joint Atlas Building and Diffeomorphic Registration Learning With Pairwise Alignment | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Aladdin_Joint_Atlas_Building_and_Diffeomorphic_Registration_Learning_With_Pairwise_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Aladdin_Joint_Atlas_Building_and_Diffeomorphic_Registration_Learning_With_Pairwise_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ding_Aladdin_Joint_Atlas_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.03563)
1805. Learning sRGB-to-Raw-RGB De-Rendering With Content-Aware Metadata | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nam_Learning_sRGB-to-Raw-RGB_De-Rendering_With_Content-Aware_Metadata_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nam_Learning_sRGB-to-Raw-RGB_De-Rendering_With_Content-Aware_Metadata_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nam_Learning_sRGB-to-Raw-RGB_De-Rendering_CVPR_2022_supplemental.pdf)
1806. Point Cloud Color Constancy | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xing_Point_Cloud_Color_Constancy_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xing_Point_Cloud_Color_Constancy_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xing_Point_Cloud_Color_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.11280)
1807. Towards an End-to-End Framework for Flow-Guided Video Inpainting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Towards_an_End-to-End_Framework_for_Flow-Guided_Video_Inpainting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_an_End-to-End_Framework_for_Flow-Guided_Video_Inpainting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Towards_an_End-to-End_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02663)
1808. CrossLoc- Scalable Aerial Localization Assisted by Multimodal Synthetic Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yan_CrossLoc_Scalable_Aerial_Localization_Assisted_by_Multimodal_Synthetic_Data_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_CrossLoc_Scalable_Aerial_Localization_Assisted_by_Multimodal_Synthetic_Data_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yan_CrossLoc_Scalable_Aerial_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.09081)
1809. On Learning Contrastive Representations for Learning With Noisy Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yi_On_Learning_Contrastive_Representations_for_Learning_With_Noisy_Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yi_On_Learning_Contrastive_Representations_for_Learning_With_Noisy_Labels_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yi_On_Learning_Contrastive_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01785)
1810. Modeling Indirect Illumination for Inverse Rendering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Modeling_Indirect_Illumination_for_Inverse_Rendering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Modeling_Indirect_Illumination_for_Inverse_Rendering_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.06837)
1811. BACON- Band-Limited Coordinate Networks for Multiscale Scene Representation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lindell_BACON_Band-Limited_Coordinate_Networks_for_Multiscale_Scene_Representation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lindell_BACON_Band-Limited_Coordinate_Networks_for_Multiscale_Scene_Representation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lindell_BACON_Band-Limited_Coordinate_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.04645)
1812. Modeling sRGB Camera Noise With Normalizing Flows | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kousha_Modeling_sRGB_Camera_Noise_With_Normalizing_Flows_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kousha_Modeling_sRGB_Camera_Noise_With_Normalizing_Flows_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kousha_Modeling_sRGB_Camera_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2206.00812)
1813. Reference-Based Video Super-Resolution Using Multi-Camera Video Triplets | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Reference-Based_Video_Super-Resolution_Using_Multi-Camera_Video_Triplets_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Reference-Based_Video_Super-Resolution_Using_Multi-Camera_Video_Triplets_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Reference-Based_Video_Super-Resolution_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14537)
1814. Self-Supervised Image Representation Learning With Geometric Set Consistency | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Self-Supervised_Image_Representation_Learning_With_Geometric_Set_Consistency_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Self-Supervised_Image_Representation_Learning_With_Geometric_Set_Consistency_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Self-Supervised_Image_Representation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15361)
1815. GEN-VLKT- Simplify Association and Enhance Interaction Understanding for HOI Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liao_GEN-VLKT_Simplify_Association_and_Enhance_Interaction_Understanding_for_HOI_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_GEN-VLKT_Simplify_Association_and_Enhance_Interaction_Understanding_for_HOI_Detection_CVPR_2022_paper.pdf)
1816. Global Matching With Overlapping Attention for Optical Flow Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Global_Matching_With_Overlapping_Attention_for_Optical_Flow_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Global_Matching_With_Overlapping_Attention_for_Optical_Flow_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhao_Global_Matching_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11335)
1817. Rethinking Efficient Lane Detection via Curve Modeling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Rethinking_Efficient_Lane_Detection_via_Curve_Modeling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Rethinking_Efficient_Lane_Detection_via_Curve_Modeling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Feng_Rethinking_Efficient_Lane_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.02431)
1818. Co-Advise- Cross Inductive Bias Distillation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Co-Advise_Cross_Inductive_Bias_Distillation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Co-Advise_Cross_Inductive_Bias_Distillation_CVPR_2022_paper.pdf)
1819. DTFD-MIL- Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_DTFD-MIL_Double-Tier_Feature_Distillation_Multiple_Instance_Learning_for_Histopathology_Whole_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_DTFD-MIL_Double-Tier_Feature_Distillation_Multiple_Instance_Learning_for_Histopathology_Whole_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_DTFD-MIL_Double-Tier_Feature_CVPR_2022_supplemental.pdf)
1820. Deep Generalized Unfolding Networks for Image Restoration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mou_Deep_Generalized_Unfolding_Networks_for_Image_Restoration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mou_Deep_Generalized_Unfolding_Networks_for_Image_Restoration_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.13348)
1821. Robust Cross-Modal Representation Learning With Progressive Self-Distillation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Andonian_Robust_Cross-Modal_Representation_Learning_With_Progressive_Self-Distillation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Andonian_Robust_Cross-Modal_Representation_Learning_With_Progressive_Self-Distillation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Andonian_Robust_Cross-Modal_Representation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04588)
1822. Compressive Single-Photon 3D Cameras | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gutierrez-Barragan_Compressive_Single-Photon_3D_Cameras_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gutierrez-Barragan_Compressive_Single-Photon_3D_Cameras_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gutierrez-Barragan_Compressive_Single-Photon_3D_CVPR_2022_supplemental.zip)
1823. Rethinking Controllable Variational Autoencoders | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shao_Rethinking_Controllable_Variational_Autoencoders_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shao_Rethinking_Controllable_Variational_Autoencoders_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shao_Rethinking_Controllable_Variational_CVPR_2022_supplemental.pdf)
1824. Boosting Crowd Counting via Multifaceted Attention | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Boosting_Crowd_Counting_via_Multifaceted_Attention_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Boosting_Crowd_Counting_via_Multifaceted_Attention_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.02636)
1825. BigDL 2.0- Seamless Scaling of AI Pipelines From Laptops to Distributed Cluster | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dai_BigDL_2.0_Seamless_Scaling_of_AI_Pipelines_From_Laptops_to_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_BigDL_2.0_Seamless_Scaling_of_AI_Pipelines_From_Laptops_to_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dai_BigDL_2.0_Seamless_CVPR_2022_supplemental.pdf)
1826. Acquiring a Dynamic Light Field Through a Single-Shot Coded Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mizuno_Acquiring_a_Dynamic_Light_Field_Through_a_Single-Shot_Coded_Image_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mizuno_Acquiring_a_Dynamic_Light_Field_Through_a_Single-Shot_Coded_Image_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mizuno_Acquiring_a_Dynamic_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.12089)
1827. Attentive Fine-Grained Structured Sparsity for Image Restoration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Oh_Attentive_Fine-Grained_Structured_Sparsity_for_Image_Restoration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Oh_Attentive_Fine-Grained_Structured_Sparsity_for_Image_Restoration_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Oh_Attentive_Fine-Grained_Structured_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.12266)
1828. StylizedNeRF- Consistent 3D Scene Stylization As Stylized NeRF via 2D-3D Mutual Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_StylizedNeRF_Consistent_3D_Scene_Stylization_As_Stylized_NeRF_via_2D-3D_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_StylizedNeRF_Consistent_3D_Scene_Stylization_As_Stylized_NeRF_via_2D-3D_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_StylizedNeRF_Consistent_3D_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2205.12183)
1829. NightLab- A Dual-Level Architecture With Hardness Detection for Segmentation at Night | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Deng_NightLab_A_Dual-Level_Architecture_With_Hardness_Detection_for_Segmentation_at_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_NightLab_A_Dual-Level_Architecture_With_Hardness_Detection_for_Segmentation_at_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Deng_NightLab_A_Dual-Level_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.05538)
1830. InfoGCN- Representation Learning for Human Skeleton-Based Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chi_InfoGCN_Representation_Learning_for_Human_Skeleton-Based_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chi_InfoGCN_Representation_Learning_for_Human_Skeleton-Based_Action_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chi_InfoGCN_Representation_Learning_CVPR_2022_supplemental.pdf)
1831. Sparse to Dense Dynamic 3D Facial Expression Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Otberdout_Sparse_to_Dense_Dynamic_3D_Facial_Expression_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Otberdout_Sparse_to_Dense_Dynamic_3D_Facial_Expression_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Otberdout_Sparse_to_Dense_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2105.07463)
1832. Crafting Better Contrastive Views for Siamese Representation Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Peng_Crafting_Better_Contrastive_Views_for_Siamese_Representation_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Crafting_Better_Contrastive_Views_for_Siamese_Representation_Learning_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2202.03278)
1833. Continual Learning for Visual Search With Backward Consistent Feature Embedding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wan_Continual_Learning_for_Visual_Search_With_Backward_Consistent_Feature_Embedding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wan_Continual_Learning_for_Visual_Search_With_Backward_Consistent_Feature_Embedding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wan_Continual_Learning_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.13384)
1834. EyePAD++- A Distillation-Based Approach for Joint Eye Authentication and Presentation Attack Detection Using Periocular Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dhar_EyePAD_A_Distillation-Based_Approach_for_Joint_Eye_Authentication_and_Presentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dhar_EyePAD_A_Distillation-Based_Approach_for_Joint_Eye_Authentication_and_Presentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dhar_EyePAD_A_Distillation-Based_CVPR_2022_supplemental.zip)
1835. Efficient Two-Stage Detection of Human-Object Interactions With a Novel Unary-Pairwise Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Efficient_Two-Stage_Detection_of_Human-Object_Interactions_With_a_Novel_Unary-Pairwise_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Efficient_Two-Stage_Detection_of_Human-Object_Interactions_With_a_Novel_Unary-Pairwise_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Efficient_Two-Stage_Detection_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01838)
1836. A Low-Cost & Real-Time Motion Capture System | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chatzitofis_A_Low-Cost__Real-Time_Motion_Capture_System_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chatzitofis_A_Low-Cost__Real-Time_Motion_Capture_System_CVPR_2022_paper.pdf)
1837. Unified Contrastive Learning in Image-Text-Label Space | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Unified_Contrastive_Learning_in_Image-Text-Label_Space_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Unified_Contrastive_Learning_in_Image-Text-Label_Space_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Unified_Contrastive_Learning_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03610)
1838. Unifying Motion Deblurring and Frame Interpolation With Events | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Unifying_Motion_Deblurring_and_Frame_Interpolation_With_Events_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Unifying_Motion_Deblurring_and_Frame_Interpolation_With_Events_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Unifying_Motion_Deblurring_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12178)
1839. Fast Point Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Park_Fast_Point_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Fast_Point_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Park_Fast_Point_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.04702)
1840. Unimodal-Concentrated Loss- Fully Adaptive Label Distribution Learning for Ordinal Regression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Unimodal-Concentrated_Loss_Fully_Adaptive_Label_Distribution_Learning_for_Ordinal_Regression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Unimodal-Concentrated_Loss_Fully_Adaptive_Label_Distribution_Learning_for_Ordinal_Regression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Unimodal-Concentrated_Loss_Fully_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00309)
1841. Deep Stereo Image Compression via Bi-Directional Coding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lei_Deep_Stereo_Image_Compression_via_Bi-Directional_Coding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_Deep_Stereo_Image_Compression_via_Bi-Directional_Coding_CVPR_2022_paper.pdf)
1842. How Good Is Aesthetic Ability of a Fashion Model- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zou_How_Good_Is_Aesthetic_Ability_of_a_Fashion_Model_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zou_How_Good_Is_Aesthetic_Ability_of_a_Fashion_Model_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zou_How_Good_Is_CVPR_2022_supplemental.pdf)
1843. Mining Multi-View Information- A Strong Self-Supervised Framework for Depth-Based 3D Hand Pose and Mesh Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Mining_Multi-View_Information_A_Strong_Self-Supervised_Framework_for_Depth-Based_3D_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Mining_Multi-View_Information_A_Strong_Self-Supervised_Framework_for_Depth-Based_3D_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ren_Mining_Multi-View_Information_CVPR_2022_supplemental.pdf)
1844. BTS- A Bi-Lingual Benchmark for Text Segmentation in the Wild | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_BTS_A_Bi-Lingual_Benchmark_for_Text_Segmentation_in_the_Wild_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_BTS_A_Bi-Lingual_Benchmark_for_Text_Segmentation_in_the_Wild_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_BTS_A_Bi-Lingual_CVPR_2022_supplemental.pdf)
1845. Hierarchical Modular Network for Video Captioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Hierarchical_Modular_Network_for_Video_Captioning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Hierarchical_Modular_Network_for_Video_Captioning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_Hierarchical_Modular_Network_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.12476)
1846. Alignment-Uniformity Aware Representation Learning for Zero-Shot Video Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Pu_Alignment-Uniformity_Aware_Representation_Learning_for_Zero-Shot_Video_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Pu_Alignment-Uniformity_Aware_Representation_Learning_for_Zero-Shot_Video_Classification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Pu_Alignment-Uniformity_Aware_Representation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15381)
1847. LiDARCap- Long-Range Marker-Less 3D Human Motion Capture With LiDAR Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_LiDARCap_Long-Range_Marker-Less_3D_Human_Motion_Capture_With_LiDAR_Point_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_LiDARCap_Long-Range_Marker-Less_3D_Human_Motion_Capture_With_LiDAR_Point_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_LiDARCap_Long-Range_Marker-Less_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.14698)
1848. GeoEngine- A Platform for Production-Ready Geospatial Research | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Verma_GeoEngine_A_Platform_for_Production-Ready_Geospatial_Research_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Verma_GeoEngine_A_Platform_for_Production-Ready_Geospatial_Research_CVPR_2022_paper.pdf)
1849. GroupViT- Semantic Segmentation Emerges From Text Supervision | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_GroupViT_Semantic_Segmentation_Emerges_From_Text_Supervision_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_GroupViT_Semantic_Segmentation_Emerges_From_Text_Supervision_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_GroupViT_Semantic_Segmentation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.11094)
1850. Occlusion-Aware Cost Constructor for Light Field Depth Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Occlusion-Aware_Cost_Constructor_for_Light_Field_Depth_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Occlusion-Aware_Cost_Constructor_for_Light_Field_Depth_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Occlusion-Aware_Cost_Constructor_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01576)
1851. SmartPortraits- Depth Powered Handheld Smartphone Dataset of Human Portraits for State Estimation, Reconstruction and Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kornilova_SmartPortraits_Depth_Powered_Handheld_Smartphone_Dataset_of_Human_Portraits_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kornilova_SmartPortraits_Depth_Powered_Handheld_Smartphone_Dataset_of_Human_Portraits_for_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.10211)
1852. Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Stacked_Hybrid-Attention_and_Group_Collaborative_Learning_for_Unbiased_Scene_Graph_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Stacked_Hybrid-Attention_and_Group_Collaborative_Learning_for_Unbiased_Scene_Graph_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_Stacked_Hybrid-Attention_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.09811)
1853. Topology-Preserving Shape Reconstruction and Registration via Neural Diffeomorphic Flow | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Topology-Preserving_Shape_Reconstruction_and_Registration_via_Neural_Diffeomorphic_Flow_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Topology-Preserving_Shape_Reconstruction_and_Registration_via_Neural_Diffeomorphic_Flow_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sun_Topology-Preserving_Shape_Reconstruction_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.08652)
1854. Learning Part Segmentation Through Unsupervised Domain Adaptation From Synthetic Vehicles | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_Part_Segmentation_Through_Unsupervised_Domain_Adaptation_From_Synthetic_Vehicles_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Part_Segmentation_Through_Unsupervised_Domain_Adaptation_From_Synthetic_Vehicles_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Learning_Part_Segmentation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2103.14098)
1855. Learning Object Context for Novel-View Scene Layout Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qiao_Learning_Object_Context_for_Novel-View_Scene_Layout_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qiao_Learning_Object_Context_for_Novel-View_Scene_Layout_Generation_CVPR_2022_paper.pdf)
1856. Neural Fields As Learnable Kernels for 3D Reconstruction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Williams_Neural_Fields_As_Learnable_Kernels_for_3D_Reconstruction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Williams_Neural_Fields_As_Learnable_Kernels_for_3D_Reconstruction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Williams_Neural_Fields_As_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13674)
1857. Detector-Free Weakly Supervised Group Activity Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Detector-Free_Weakly_Supervised_Group_Activity_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Detector-Free_Weakly_Supervised_Group_Activity_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Detector-Free_Weakly_Supervised_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02139)
1858. HairCLIP- Design Your Hair by Text and Reference Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wei_HairCLIP_Design_Your_Hair_by_Text_and_Reference_Image_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_HairCLIP_Design_Your_Hair_by_Text_and_Reference_Image_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wei_HairCLIP_Design_Your_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.05142)
1859. OakInk- A Large-Scale Knowledge Repository for Understanding Hand-Object Interaction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_OakInk_A_Large-Scale_Knowledge_Repository_for_Understanding_Hand-Object_Interaction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_OakInk_A_Large-Scale_Knowledge_Repository_for_Understanding_Hand-Object_Interaction_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_OakInk_A_Large-Scale_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15709)
1860. SwinBERT- End-to-End Transformers With Sparse Attention for Video Captioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_SwinBERT_End-to-End_Transformers_With_Sparse_Attention_for_Video_Captioning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SwinBERT_End-to-End_Transformers_With_Sparse_Attention_for_Video_Captioning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_SwinBERT_End-to-End_Transformers_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13196)
1861. Maximum Spatial Perturbation Consistency for Unpaired Image-to-Image Translation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Maximum_Spatial_Perturbation_Consistency_for_Unpaired_Image-to-Image_Translation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Maximum_Spatial_Perturbation_Consistency_for_Unpaired_Image-to-Image_Translation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Maximum_Spatial_Perturbation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12707)
1862. Bringing Old Films Back to Life | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wan_Bringing_Old_Films_Back_to_Life_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wan_Bringing_Old_Films_Back_to_Life_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wan_Bringing_Old_Films_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.17276)
1863. E2(GO)MOTION- Motion Augmented Event Stream for Egocentric Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Plizzari_E2GOMOTION_Motion_Augmented_Event_Stream_for_Egocentric_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Plizzari_E2GOMOTION_Motion_Augmented_Event_Stream_for_Egocentric_Action_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Plizzari_E2GOMOTION_Motion_Augmented_CVPR_2022_supplemental.pdf)
1864. An Empirical Study of Training End-to-End Vision-and-Language Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dou_An_Empirical_Study_of_Training_End-to-End_Vision-and-Language_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dou_An_Empirical_Study_of_Training_End-to-End_Vision-and-Language_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dou_An_Empirical_Study_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.02387)
1865. Multimodal Dynamics- Dynamical Fusion for Trustworthy Multimodal Classification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Han_Multimodal_Dynamics_Dynamical_Fusion_for_Trustworthy_Multimodal_Classification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Multimodal_Dynamics_Dynamical_Fusion_for_Trustworthy_Multimodal_Classification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Han_Multimodal_Dynamics_Dynamical_CVPR_2022_supplemental.pdf)
1866. Unsupervised Homography Estimation With Coplanarity-Aware GAN | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Unsupervised_Homography_Estimation_With_Coplanarity-Aware_GAN_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Unsupervised_Homography_Estimation_With_Coplanarity-Aware_GAN_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hong_Unsupervised_Homography_Estimation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.03821)
1867. LIFT- Learning 4D LiDAR Image Fusion Transformer for 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zeng_LIFT_Learning_4D_LiDAR_Image_Fusion_Transformer_for_3D_Object_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_LIFT_Learning_4D_LiDAR_Image_Fusion_Transformer_for_3D_Object_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zeng_LIFT_Learning_4D_CVPR_2022_supplemental.pdf)
1868. PatchNet- A Simple Face Anti-Spoofing Framework via Fine-Grained Patch Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_PatchNet_A_Simple_Face_Anti-Spoofing_Framework_via_Fine-Grained_Patch_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_PatchNet_A_Simple_Face_Anti-Spoofing_Framework_via_Fine-Grained_Patch_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_PatchNet_A_Simple_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14325)
1869. Rethinking Minimal Sufficient Representation in Contrastive Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Rethinking_Minimal_Sufficient_Representation_in_Contrastive_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Rethinking_Minimal_Sufficient_Representation_in_Contrastive_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Rethinking_Minimal_Sufficient_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.07004)
1870. Effective Conditioned and Composed Image Retrieval Combining CLIP-Based Features | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Baldrati_Effective_Conditioned_and_Composed_Image_Retrieval_Combining_CLIP-Based_Features_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Baldrati_Effective_Conditioned_and_Composed_Image_Retrieval_Combining_CLIP-Based_Features_CVPR_2022_paper.pdf)
1871. Practical Stereo Matching via Cascaded Recurrent Network With Adaptive Correlation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Practical_Stereo_Matching_via_Cascaded_Recurrent_Network_With_Adaptive_Correlation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Practical_Stereo_Matching_via_Cascaded_Recurrent_Network_With_Adaptive_Correlation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Practical_Stereo_Matching_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.11483)
1872. D-Grasp- Physically Plausible Dynamic Grasp Synthesis for Hand-Object Interactions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Christen_D-Grasp_Physically_Plausible_Dynamic_Grasp_Synthesis_for_Hand-Object_Interactions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Christen_D-Grasp_Physically_Plausible_Dynamic_Grasp_Synthesis_for_Hand-Object_Interactions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Christen_D-Grasp_Physically_Plausible_CVPR_2022_supplemental.zip)
1873. Show, Deconfound and Tell- Image Captioning With Causal Inference | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Show_Deconfound_and_Tell_Image_Captioning_With_Causal_Inference_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Show_Deconfound_and_Tell_Image_Captioning_With_Causal_Inference_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Show_Deconfound_and_CVPR_2022_supplemental.pdf)
1874. ImFace- A Nonlinear 3D Morphable Face Model With Implicit Neural Representations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_ImFace_A_Nonlinear_3D_Morphable_Face_Model_With_Implicit_Neural_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_ImFace_A_Nonlinear_3D_Morphable_Face_Model_With_Implicit_Neural_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_ImFace_A_Nonlinear_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14510)
1875. MobRecon- Mobile-Friendly Hand Mesh Reconstruction From Monocular Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_MobRecon_Mobile-Friendly_Hand_Mesh_Reconstruction_From_Monocular_Image_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_MobRecon_Mobile-Friendly_Hand_Mesh_Reconstruction_From_Monocular_Image_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_MobRecon_Mobile-Friendly_Hand_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02753)
1876. AlignMixup- Improving Representations by Interpolating Aligned Features | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Venkataramanan_AlignMixup_Improving_Representations_by_Interpolating_Aligned_Features_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Venkataramanan_AlignMixup_Improving_Representations_by_Interpolating_Aligned_Features_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Venkataramanan_AlignMixup_Improving_Representations_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2103.15375)
1877. HerosNet- Hyperspectral Explicable Reconstruction and Optimal Sampling Deep Network for Snapshot Compressive Imaging | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_HerosNet_Hyperspectral_Explicable_Reconstruction_and_Optimal_Sampling_Deep_Network_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_HerosNet_Hyperspectral_Explicable_Reconstruction_and_Optimal_Sampling_Deep_Network_for_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2112.06238)
1878. Detecting Deepfakes With Self-Blended Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shiohara_Detecting_Deepfakes_With_Self-Blended_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shiohara_Detecting_Deepfakes_With_Self-Blended_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shiohara_Detecting_Deepfakes_With_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.08376)
1879. Learnable Irrelevant Modality Dropout for Multimodal Action Recognition on Modality-Specific Annotated Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Alfasly_Learnable_Irrelevant_Modality_Dropout_for_Multimodal_Action_Recognition_on_Modality-Specific_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Alfasly_Learnable_Irrelevant_Modality_Dropout_for_Multimodal_Action_Recognition_on_Modality-Specific_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Alfasly_Learnable_Irrelevant_Modality_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03014)
1880. Bi-Level Doubly Variational Learning for Energy-Based Latent Variable Models | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kan_Bi-Level_Doubly_Variational_Learning_for_Energy-Based_Latent_Variable_Models_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kan_Bi-Level_Doubly_Variational_Learning_for_Energy-Based_Latent_Variable_Models_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kan_Bi-Level_Doubly_Variational_CVPR_2022_supplemental.pdf)
1881. AxIoU- An Axiomatically Justified Measure for Video Moment Retrieval | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Togashi_AxIoU_An_Axiomatically_Justified_Measure_for_Video_Moment_Retrieval_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Togashi_AxIoU_An_Axiomatically_Justified_Measure_for_Video_Moment_Retrieval_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Togashi_AxIoU_An_Axiomatically_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16062)
1882. NOC-REK- Novel Object Captioning With Retrieved Vocabulary From External Knowledge | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Vo_NOC-REK_Novel_Object_Captioning_With_Retrieved_Vocabulary_From_External_Knowledge_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Vo_NOC-REK_Novel_Object_Captioning_With_Retrieved_Vocabulary_From_External_Knowledge_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Vo_NOC-REK_Novel_Object_CVPR_2022_supplemental.pdf)
1883. Speech Driven Tongue Animation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Medina_Speech_Driven_Tongue_Animation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Medina_Speech_Driven_Tongue_Animation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Medina_Speech_Driven_Tongue_CVPR_2022_supplemental.pdf)
1884. Hybrid Relation Guided Set Matching for Few-Shot Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Hybrid_Relation_Guided_Set_Matching_for_Few-Shot_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Hybrid_Relation_Guided_Set_Matching_for_Few-Shot_Action_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Hybrid_Relation_Guided_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.13423)
1885. SHIFT- A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_SHIFT_A_Synthetic_Driving_Dataset_for_Continuous_Multi-Task_Domain_Adaptation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_SHIFT_A_Synthetic_Driving_Dataset_for_Continuous_Multi-Task_Domain_Adaptation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sun_SHIFT_A_Synthetic_CVPR_2022_supplemental.pdf)
1886. FlexIT- Towards Flexible Semantic Image Translation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Couairon_FlexIT_Towards_Flexible_Semantic_Image_Translation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Couairon_FlexIT_Towards_Flexible_Semantic_Image_Translation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Couairon_FlexIT_Towards_Flexible_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.04705)
1887. Face2Exp- Combating Data Biases for Facial Expression Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zeng_Face2Exp_Combating_Data_Biases_for_Facial_Expression_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_Face2Exp_Combating_Data_Biases_for_Facial_Expression_Recognition_CVPR_2022_paper.pdf)
1888. PINA- Learning a Personalized Implicit Neural Avatar From a Single RGB-D Video Sequence | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_PINA_Learning_a_Personalized_Implicit_Neural_Avatar_From_a_Single_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_PINA_Learning_a_Personalized_Implicit_Neural_Avatar_From_a_Single_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_PINA_Learning_a_CVPR_2022_supplemental.pdf)
1889. Forecasting From LiDAR via Future Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Peri_Forecasting_From_LiDAR_via_Future_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Peri_Forecasting_From_LiDAR_via_Future_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Peri_Forecasting_From_LiDAR_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16297)
1890. CRAFT- Cross-Attentional Flow Transformer for Robust Optical Flow | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sui_CRAFT_Cross-Attentional_Flow_Transformer_for_Robust_Optical_Flow_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sui_CRAFT_Cross-Attentional_Flow_Transformer_for_Robust_Optical_Flow_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sui_CRAFT_Cross-Attentional_Flow_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16896)
1891. Privacy Preserving Partial Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Geppert_Privacy_Preserving_Partial_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Geppert_Privacy_Preserving_Partial_Localization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Geppert_Privacy_Preserving_Partial_CVPR_2022_supplemental.pdf)
1892. Cross-Modal Background Suppression for Audio-Visual Event Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xia_Cross-Modal_Background_Suppression_for_Audio-Visual_Event_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Cross-Modal_Background_Suppression_for_Audio-Visual_Event_Localization_CVPR_2022_paper.pdf)
1893. Lagrange Motion Analysis and View Embeddings for Improved Gait Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chai_Lagrange_Motion_Analysis_and_View_Embeddings_for_Improved_Gait_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chai_Lagrange_Motion_Analysis_and_View_Embeddings_for_Improved_Gait_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chai_Lagrange_Motion_Analysis_CVPR_2022_supplemental.zip)
1894. Neural Mesh Simplification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Potamias_Neural_Mesh_Simplification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Potamias_Neural_Mesh_Simplification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Potamias_Neural_Mesh_Simplification_CVPR_2022_supplemental.pdf)
1895. Deep Hyperspectral-Depth Reconstruction Using Single Color-Dot Projection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Deep_Hyperspectral-Depth_Reconstruction_Using_Single_Color-Dot_Projection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Deep_Hyperspectral-Depth_Reconstruction_Using_Single_Color-Dot_Projection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Deep_Hyperspectral-Depth_Reconstruction_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2204.03929)
1896. M3T- Three-Dimensional Medical Image Classifier Using Multi-Plane and Multi-Slice Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jang_M3T_Three-Dimensional_Medical_Image_Classifier_Using_Multi-Plane_and_Multi-Slice_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jang_M3T_Three-Dimensional_Medical_Image_Classifier_Using_Multi-Plane_and_Multi-Slice_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jang_M3T_Three-Dimensional_Medical_CVPR_2022_supplemental.pdf)
1897. 3MASSIV- Multilingual, Multimodal and Multi-Aspect Dataset of Social Media Short Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gupta_3MASSIV_Multilingual_Multimodal_and_Multi-Aspect_Dataset_of_Social_Media_Short_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gupta_3MASSIV_Multilingual_Multimodal_and_Multi-Aspect_Dataset_of_Social_Media_Short_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gupta_3MASSIV_Multilingual_Multimodal_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14456)
1898. Structured Sparse R-CNN for Direct Scene Graph Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Teng_Structured_Sparse_R-CNN_for_Direct_Scene_Graph_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Teng_Structured_Sparse_R-CNN_for_Direct_Scene_Graph_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Teng_Structured_Sparse_R-CNN_CVPR_2022_supplemental.pdf)
1899. Multi-Grained Spatio-Temporal Features Perceived Network for Event-Based Lip-Reading | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tan_Multi-Grained_Spatio-Temporal_Features_Perceived_Network_for_Event-Based_Lip-Reading_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tan_Multi-Grained_Spatio-Temporal_Features_Perceived_Network_for_Event-Based_Lip-Reading_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tan_Multi-Grained_Spatio-Temporal_Features_CVPR_2022_supplemental.zip)
1900. AnyFace- Free-Style Text-To-Face Synthesis and Manipulation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_AnyFace_Free-Style_Text-To-Face_Synthesis_and_Manipulation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_AnyFace_Free-Style_Text-To-Face_Synthesis_and_Manipulation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.15334)
1901. HL-Net- Heterophily Learning Network for Scene Graph Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_HL-Net_Heterophily_Learning_Network_for_Scene_Graph_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_HL-Net_Heterophily_Learning_Network_for_Scene_Graph_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_HL-Net_Heterophily_Learning_CVPR_2022_supplemental.pdf)
1902. MERLOT Reserve- Neural Script Knowledge Through Vision and Language and Sound | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zellers_MERLOT_Reserve_Neural_Script_Knowledge_Through_Vision_and_Language_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zellers_MERLOT_Reserve_Neural_Script_Knowledge_Through_Vision_and_Language_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zellers_MERLOT_Reserve_Neural_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.02639)
1903. A Conservative Approach for Unbiased Learning on Unknown Biases | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jeon_A_Conservative_Approach_for_Unbiased_Learning_on_Unknown_Biases_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jeon_A_Conservative_Approach_for_Unbiased_Learning_on_Unknown_Biases_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Jeon_A_Conservative_Approach_CVPR_2022_supplemental.pdf)
1904. Large-Scale Video Panoptic Segmentation in the Wild- A Benchmark | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Miao_Large-Scale_Video_Panoptic_Segmentation_in_the_Wild_A_Benchmark_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Miao_Large-Scale_Video_Panoptic_Segmentation_in_the_Wild_A_Benchmark_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Miao_Large-Scale_Video_Panoptic_CVPR_2022_supplemental.pdf)
1905. GrainSpace- A Large-Scale Dataset for Fine-Grained and Domain-Adaptive Recognition of Cereal Grains | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_GrainSpace_A_Large-Scale_Dataset_for_Fine-Grained_and_Domain-Adaptive_Recognition_of_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_GrainSpace_A_Large-Scale_Dataset_for_Fine-Grained_and_Domain-Adaptive_Recognition_of_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fan_GrainSpace_A_Large-Scale_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05306)
1906. BokehMe- When Neural Rendering Meets Classical Rendering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Peng_BokehMe_When_Neural_Rendering_Meets_Classical_Rendering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_BokehMe_When_Neural_Rendering_Meets_Classical_Rendering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Peng_BokehMe_When_Neural_CVPR_2022_supplemental.pdf)
1907. Learning Modal-Invariant and Temporal-Memory for Video-Based Visible-Infrared Person Re-Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Learning_Modal-Invariant_and_Temporal-Memory_for_Video-Based_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Learning_Modal-Invariant_and_Temporal-Memory_for_Video-Based_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_Learning_Modal-Invariant_and_CVPR_2022_supplemental.pdf)
1908. BigDatasetGAN- Synthesizing ImageNet With Pixel-Wise Annotations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_BigDatasetGAN_Synthesizing_ImageNet_With_Pixel-Wise_Annotations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_BigDatasetGAN_Synthesizing_ImageNet_With_Pixel-Wise_Annotations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_BigDatasetGAN_Synthesizing_ImageNet_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.04684)
1909. Align Representations With Base- A New Approach to Self-Supervised Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Align_Representations_With_Base_A_New_Approach_to_Self-Supervised_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Align_Representations_With_Base_A_New_Approach_to_Self-Supervised_Learning_CVPR_2022_paper.pdf)
1910. Exploring Denoised Cross-Video Contrast for Weakly-Supervised Temporal Action Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Exploring_Denoised_Cross-Video_Contrast_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Exploring_Denoised_Cross-Video_Contrast_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.pdf)
1911. SVIP- Sequence VerIfication for Procedures in Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qian_SVIP_Sequence_VerIfication_for_Procedures_in_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qian_SVIP_Sequence_VerIfication_for_Procedures_in_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Qian_SVIP_Sequence_VerIfication_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.06447)
1912. Low-Resource Adaptation for Personalized Co-Speech Gesture Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ahuja_Low-Resource_Adaptation_for_Personalized_Co-Speech_Gesture_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ahuja_Low-Resource_Adaptation_for_Personalized_Co-Speech_Gesture_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ahuja_Low-Resource_Adaptation_for_CVPR_2022_supplemental.pdf)
1913. HDR-NeRF- High Dynamic Range Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Huang_HDR-NeRF_High_Dynamic_Range_Neural_Radiance_Fields_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_HDR-NeRF_High_Dynamic_Range_Neural_Radiance_Fields_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Huang_HDR-NeRF_High_Dynamic_CVPR_2022_supplemental.pdf)
1914. Neural Emotion Director- Speech-Preserving Semantic Control of Facial Expressions in "In-the-Wild" Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Papantoniou_Neural_Emotion_Director_Speech-Preserving_Semantic_Control_of_Facial_Expressions_in_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Papantoniou_Neural_Emotion_Director_Speech-Preserving_Semantic_Control_of_Facial_Expressions_in_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Papantoniou_Neural_Emotion_Director_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00585)
1915. Learning To Listen- Modeling Non-Deterministic Dyadic Facial Motion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ng_Learning_To_Listen_Modeling_Non-Deterministic_Dyadic_Facial_Motion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ng_Learning_To_Listen_Modeling_Non-Deterministic_Dyadic_Facial_Motion_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.08451)
1916. 3PSDF- Three-Pole Signed Distance Function for Learning Surfaces With Arbitrary Topologies | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_3PSDF_Three-Pole_Signed_Distance_Function_for_Learning_Surfaces_With_Arbitrary_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_3PSDF_Three-Pole_Signed_Distance_Function_for_Learning_Surfaces_With_Arbitrary_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_3PSDF_Three-Pole_Signed_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.15572)
1917. GIRAFFE HD- A High-Resolution 3D-Aware Generative Model | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xue_GIRAFFE_HD_A_High-Resolution_3D-Aware_Generative_Model_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_GIRAFFE_HD_A_High-Resolution_3D-Aware_Generative_Model_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xue_GIRAFFE_HD_A_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14954)
1918. Knowledge-Driven Self-Supervised Representation Learning for Facial Action Unit Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chang_Knowledge-Driven_Self-Supervised_Representation_Learning_for_Facial_Action_Unit_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_Knowledge-Driven_Self-Supervised_Representation_Learning_for_Facial_Action_Unit_Recognition_CVPR_2022_paper.pdf)
1919. Learning Second Order Local Anomaly for General Face Forgery Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fei_Learning_Second_Order_Local_Anomaly_for_General_Face_Forgery_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fei_Learning_Second_Order_Local_Anomaly_for_General_Face_Forgery_Detection_CVPR_2022_paper.pdf)
1920. ADAS- A Direct Adaptation Strategy for Multi-Target Domain Adaptive Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_ADAS_A_Direct_Adaptation_Strategy_for_Multi-Target_Domain_Adaptive_Semantic_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_ADAS_A_Direct_Adaptation_Strategy_for_Multi-Target_Domain_Adaptive_Semantic_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_ADAS_A_Direct_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.06811)
1921. The Devil Is in the Labels- Noisy Label Correction for Robust Scene Graph Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_The_Devil_Is_in_the_Labels_Noisy_Label_Correction_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_The_Devil_Is_in_the_Labels_Noisy_Label_Correction_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_The_Devil_Is_CVPR_2022_supplemental.pdf)
1922. LAVT- Language-Aware Vision Transformer for Referring Image Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_LAVT_Language-Aware_Vision_Transformer_for_Referring_Image_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_LAVT_Language-Aware_Vision_Transformer_for_Referring_Image_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_LAVT_Language-Aware_Vision_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.02244)
1923. Video Demoireing With Relation-Based Temporal Consistency | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dai_Video_Demoireing_With_Relation-Based_Temporal_Consistency_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_Video_Demoireing_With_Relation-Based_Temporal_Consistency_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.02957)
1924. GraFormer- Graph-Oriented Transformer for 3D Pose Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_GraFormer_Graph-Oriented_Transformer_for_3D_Pose_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_GraFormer_Graph-Oriented_Transformer_for_3D_Pose_Estimation_CVPR_2022_paper.pdf)
1925. DeepCurrents- Learning Implicit Representations of Shapes With Boundaries | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Palmer_DeepCurrents_Learning_Implicit_Representations_of_Shapes_With_Boundaries_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Palmer_DeepCurrents_Learning_Implicit_Representations_of_Shapes_With_Boundaries_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.09383)
1926. Zero Experience Required- Plug & Play Modular Transfer Learning for Semantic Visual Navigation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Al-Halah_Zero_Experience_Required_Plug__Play_Modular_Transfer_Learning_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Al-Halah_Zero_Experience_Required_Plug__Play_Modular_Transfer_Learning_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Al-Halah_Zero_Experience_Required_CVPR_2022_supplemental.pdf)
1927. The Wanderings of Odysseus in 3D Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_The_Wanderings_of_Odysseus_in_3D_Scenes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_The_Wanderings_of_Odysseus_in_3D_Scenes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_The_Wanderings_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.09251)
1928. All-in-One Image Restoration for Unknown Corruption | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_All-in-One_Image_Restoration_for_Unknown_Corruption_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_All-in-One_Image_Restoration_for_Unknown_Corruption_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_All-in-One_Image_Restoration_CVPR_2022_supplemental.pdf)
1929. Optimizing Video Prediction via Video Frame Interpolation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Optimizing_Video_Prediction_via_Video_Frame_Interpolation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Optimizing_Video_Prediction_via_Video_Frame_Interpolation_CVPR_2022_paper.pdf)
1930. Episodic Memory Question Answering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Datta_Episodic_Memory_Question_Answering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Datta_Episodic_Memory_Question_Answering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Datta_Episodic_Memory_Question_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.01652)
1931. Continual Stereo Matching of Continuous Driving Scenes With Growing Architecture | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Continual_Stereo_Matching_of_Continuous_Driving_Scenes_With_Growing_Architecture_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Continual_Stereo_Matching_of_Continuous_Driving_Scenes_With_Growing_Architecture_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Continual_Stereo_Matching_CVPR_2022_supplemental.pdf)
1932. Learning To Zoom Inside Camera Imaging Pipeline | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Learning_To_Zoom_Inside_Camera_Imaging_Pipeline_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Learning_To_Zoom_Inside_Camera_Imaging_Pipeline_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_Learning_To_Zoom_CVPR_2022_supplemental.pdf)
1933. gDNA- Towards Generative Detailed Neural Avatars | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_gDNA_Towards_Generative_Detailed_Neural_Avatars_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_gDNA_Towards_Generative_Detailed_Neural_Avatars_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_gDNA_Towards_Generative_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.04123)
1934. Degree-of-Linear-Polarization-Based Color Constancy | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ono_Degree-of-Linear-Polarization-Based_Color_Constancy_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ono_Degree-of-Linear-Polarization-Based_Color_Constancy_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ono_Degree-of-Linear-Polarization-Based_Color_Constancy_CVPR_2022_supplemental.zip)
1935. On the Importance of Asymmetry for Siamese Representation Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_On_the_Importance_of_Asymmetry_for_Siamese_Representation_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_On_the_Importance_of_Asymmetry_for_Siamese_Representation_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_On_the_Importance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.00613)
1936. Probing Representation Forgetting in Supervised and Unsupervised Continual Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Davari_Probing_Representation_Forgetting_in_Supervised_and_Unsupervised_Continual_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Davari_Probing_Representation_Forgetting_in_Supervised_and_Unsupervised_Continual_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Davari_Probing_Representation_Forgetting_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13381)
1937. DenseCLIP- Language-Guided Dense Prediction With Context-Aware Prompting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rao_DenseCLIP_Language-Guided_Dense_Prediction_With_Context-Aware_Prompting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rao_DenseCLIP_Language-Guided_Dense_Prediction_With_Context-Aware_Prompting_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rao_DenseCLIP_Language-Guided_Dense_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01518)
1938. JRDB-Act- A Large-Scale Dataset for Spatio-Temporal Action, Social Group and Activity Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ehsanpour_JRDB-Act_A_Large-Scale_Dataset_for_Spatio-Temporal_Action_Social_Group_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ehsanpour_JRDB-Act_A_Large-Scale_Dataset_for_Spatio-Temporal_Action_Social_Group_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ehsanpour_JRDB-Act_A_Large-Scale_CVPR_2022_supplemental.pdf)
1939. AR-NeRF- Unsupervised Learning of Depth and Defocus Effects From Natural Images With Aperture Rendering Neural Radiance Fields | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kaneko_AR-NeRF_Unsupervised_Learning_of_Depth_and_Defocus_Effects_From_Natural_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kaneko_AR-NeRF_Unsupervised_Learning_of_Depth_and_Defocus_Effects_From_Natural_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kaneko_AR-NeRF_Unsupervised_Learning_CVPR_2022_supplemental.pdf)
1940. Decoupling and Recoupling Spatiotemporal Representation for RGB-D-Based Motion Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Decoupling_and_Recoupling_Spatiotemporal_Representation_for_RGB-D-Based_Motion_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Decoupling_and_Recoupling_Spatiotemporal_Representation_for_RGB-D-Based_Motion_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhou_Decoupling_and_Recoupling_CVPR_2022_supplemental.pdf)
1941. Towards Robust and Adaptive Motion Forecasting- A Causal Representation Perspective | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Towards_Robust_and_Adaptive_Motion_Forecasting_A_Causal_Representation_Perspective_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Robust_and_Adaptive_Motion_Forecasting_A_Causal_Representation_Perspective_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Towards_Robust_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14820)
1942. Escaping Data Scarcity for High-Resolution Heterogeneous Face Hallucination | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mei_Escaping_Data_Scarcity_for_High-Resolution_Heterogeneous_Face_Hallucination_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mei_Escaping_Data_Scarcity_for_High-Resolution_Heterogeneous_Face_Hallucination_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mei_Escaping_Data_Scarcity_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16669)
1943. Visual Acoustic Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Visual_Acoustic_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Visual_Acoustic_Matching_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Visual_Acoustic_Matching_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2202.06875)
1944. Unified Multivariate Gaussian Mixture for Efficient Neural Image Compression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Unified_Multivariate_Gaussian_Mixture_for_Efficient_Neural_Image_Compression_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Unified_Multivariate_Gaussian_Mixture_for_Efficient_Neural_Image_Compression_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhu_Unified_Multivariate_Gaussian_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10897)
1945. 3D Photo Stylization- Learning To Generate Stylized Novel Views From a Single Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mu_3D_Photo_Stylization_Learning_To_Generate_Stylized_Novel_Views_From_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mu_3D_Photo_Stylization_Learning_To_Generate_Stylized_Novel_Views_From_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mu_3D_Photo_Stylization_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00169)
1946. SelfD- Self-Learning Large-Scale Driving Policies From the Web | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_SelfD_Self-Learning_Large-Scale_Driving_Policies_From_the_Web_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_SelfD_Self-Learning_Large-Scale_Driving_Policies_From_the_Web_CVPR_2022_paper.pdf)
1947. "The Pedestrian Next to the Lamppost" Adaptive Object Graphs for Better Instantaneous Mapping | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Saha_The_Pedestrian_Next_to_the_Lamppost_Adaptive_Object_Graphs_for_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Saha_The_Pedestrian_Next_to_the_Lamppost_Adaptive_Object_Graphs_for_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Saha_The_Pedestrian_Next_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.02944)
1948. Surpassing the Human Accuracy- Detecting Gallbladder Cancer From USG Images With Curriculum Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Basu_Surpassing_the_Human_Accuracy_Detecting_Gallbladder_Cancer_From_USG_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Basu_Surpassing_the_Human_Accuracy_Detecting_Gallbladder_Cancer_From_USG_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Basu_Surpassing_the_Human_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.11433)
1949. Autofocus for Event Cameras | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Autofocus_for_Event_Cameras_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Autofocus_for_Event_Cameras_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_Autofocus_for_Event_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.12321)
1950. Learning Multiple Adverse Weather Removal via Two-Stage Knowledge Learning and Multi-Contrastive Regularization- Toward a Unified Model | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Learning_Multiple_Adverse_Weather_Removal_via_Two-Stage_Knowledge_Learning_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Learning_Multiple_Adverse_Weather_Removal_via_Two-Stage_Knowledge_Learning_and_CVPR_2022_paper.pdf)
1951. L-Verse- Bidirectional Generation Between Image and Text | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_L-Verse_Bidirectional_Generation_Between_Image_and_Text_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_L-Verse_Bidirectional_Generation_Between_Image_and_Text_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_L-Verse_Bidirectional_Generation_CVPR_2022_supplemental.pdf)
1952. Self-Supervised Learning of Adversarial Example- Towards Good Generalizations for Deepfake Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Self-Supervised_Learning_of_Adversarial_Example_Towards_Good_Generalizations_for_Deepfake_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Self-Supervised_Learning_of_Adversarial_Example_Towards_Good_Generalizations_for_Deepfake_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Self-Supervised_Learning_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.12208)
1953. Ego4D- Around the World in 3,000 Hours of Egocentric Video | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Grauman_Ego4D_Around_the_World_in_3000_Hours_of_Egocentric_Video_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Grauman_Ego4D_Around_the_World_in_3000_Hours_of_Egocentric_Video_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Grauman_Ego4D_Around_the_CVPR_2022_supplemental.pdf)
1954. Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Self-Supervised_Pre-Training_of_Swin_Transformers_for_3D_Medical_Image_Analysis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Self-Supervised_Pre-Training_of_Swin_Transformers_for_3D_Medical_Image_Analysis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tang_Self-Supervised_Pre-Training_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14791)
1955. Camera-Conditioned Stable Feature Generation for Isolated Camera Supervised Person Re-IDentification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Camera-Conditioned_Stable_Feature_Generation_for_Isolated_Camera_Supervised_Person_Re-IDentification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Camera-Conditioned_Stable_Feature_Generation_for_Isolated_Camera_Supervised_Person_Re-IDentification_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.15210)
1956. Weakly Supervised Semantic Segmentation Using Out-of-Distribution Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Weakly_Supervised_Semantic_Segmentation_Using_Out-of-Distribution_Data_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Weakly_Supervised_Semantic_Segmentation_Using_Out-of-Distribution_Data_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Weakly_Supervised_Semantic_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.03860)
1957. Point-Level Region Contrast for Object Detection Pre-Training | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Bai_Point-Level_Region_Contrast_for_Object_Detection_Pre-Training_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Point-Level_Region_Contrast_for_Object_Detection_Pre-Training_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bai_Point-Level_Region_Contrast_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.04639)
1958. Spatial-Temporal Parallel Transformer for Arm-Hand Dynamic Estimation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Spatial-Temporal_Parallel_Transformer_for_Arm-Hand_Dynamic_Estimation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Spatial-Temporal_Parallel_Transformer_for_Arm-Hand_Dynamic_Estimation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Spatial-Temporal_Parallel_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16202)
1959. Failure Modes of Domain Generalization Algorithms | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Galstyan_Failure_Modes_of_Domain_Generalization_Algorithms_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Galstyan_Failure_Modes_of_Domain_Generalization_Algorithms_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Galstyan_Failure_Modes_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13733)
1960. Class Similarity Weighted Knowledge Distillation for Continual Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Phan_Class_Similarity_Weighted_Knowledge_Distillation_for_Continual_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Phan_Class_Similarity_Weighted_Knowledge_Distillation_for_Continual_Semantic_Segmentation_CVPR_2022_paper.pdf)
1961. DAD-3DHeads- A Large-Scale Dense, Accurate and Diverse Dataset for 3D Head Alignment From a Single Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Martyniuk_DAD-3DHeads_A_Large-Scale_Dense_Accurate_and_Diverse_Dataset_for_3D_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Martyniuk_DAD-3DHeads_A_Large-Scale_Dense_Accurate_and_Diverse_Dataset_for_3D_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Martyniuk_DAD-3DHeads_A_Large-Scale_CVPR_2022_supplemental.pdf)
1962. vCLIMB- A Novel Video Class Incremental Learning Benchmark | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Villa_vCLIMB_A_Novel_Video_Class_Incremental_Learning_Benchmark_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Villa_vCLIMB_A_Novel_Video_Class_Incremental_Learning_Benchmark_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Villa_vCLIMB_A_Novel_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2201.09381)
1963. Bending Reality- Distortion-Aware Transformers for Adapting to Panoramic Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Bending_Reality_Distortion-Aware_Transformers_for_Adapting_to_Panoramic_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Bending_Reality_Distortion-Aware_Transformers_for_Adapting_to_Panoramic_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Bending_Reality_Distortion-Aware_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.01452)
1964. INS-Conv- Incremental Sparse Convolution for Online 3D Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_INS-Conv_Incremental_Sparse_Convolution_for_Online_3D_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_INS-Conv_Incremental_Sparse_Convolution_for_Online_3D_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_INS-Conv_Incremental_Sparse_CVPR_2022_supplemental.zip)
1965. Visual Vibration Tomography- Estimating Interior Material Properties From Monocular Video | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Visual_Vibration_Tomography_Estimating_Interior_Material_Properties_From_Monocular_Video_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Visual_Vibration_Tomography_Estimating_Interior_Material_Properties_From_Monocular_Video_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Feng_Visual_Vibration_Tomography_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.02735)
1966. Rope3D- The Roadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Rope3D_The_Roadside_Perception_Dataset_for_Autonomous_Driving_and_Monocular_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Rope3D_The_Roadside_Perception_Dataset_for_Autonomous_Driving_and_Monocular_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_Rope3D_The_Roadside_CVPR_2022_supplemental.pdf)
1967. Noisy Boundaries- Lemon or Lemonade for Semi-Supervised Instance Segmentation- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Noisy_Boundaries_Lemon_or_Lemonade_for_Semi-Supervised_Instance_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Noisy_Boundaries_Lemon_or_Lemonade_for_Semi-Supervised_Instance_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Noisy_Boundaries_Lemon_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.13427)
1968. Boosting View Synthesis With Residual Transfer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rong_Boosting_View_Synthesis_With_Residual_Transfer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rong_Boosting_View_Synthesis_With_Residual_Transfer_CVPR_2022_paper.pdf)
1969. Think Global, Act Local- Dual-Scale Graph Transformer for Vision-and-Language Navigation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Think_Global_Act_Local_Dual-Scale_Graph_Transformer_for_Vision-and-Language_Navigation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Think_Global_Act_Local_Dual-Scale_Graph_Transformer_for_Vision-and-Language_Navigation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Think_Global_Act_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.11742)
1970. Towards Layer-Wise Image Vectorization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Towards_Layer-Wise_Image_Vectorization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Towards_Layer-Wise_Image_Vectorization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ma_Towards_Layer-Wise_Image_CVPR_2022_supplemental.pdf)
1971. Scenic- A JAX Library for Computer Vision Research and Beyond | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dehghani_Scenic_A_JAX_Library_for_Computer_Vision_Research_and_Beyond_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dehghani_Scenic_A_JAX_Library_for_Computer_Vision_Research_and_Beyond_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2110.11403)
1972. CNN Filter DB- An Empirical Investigation of Trained Convolutional Filters | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Gavrikov_CNN_Filter_DB_An_Empirical_Investigation_of_Trained_Convolutional_Filters_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gavrikov_CNN_Filter_DB_An_Empirical_Investigation_of_Trained_Convolutional_Filters_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Gavrikov_CNN_Filter_DB_CVPR_2022_supplemental.zip), [arXiv](http://arxiv.org/abs/2203.15331)
1973. ScePT- Scene-Consistent, Policy-Based Trajectory Predictions for Planning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_ScePT_Scene-Consistent_Policy-Based_Trajectory_Predictions_for_Planning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_ScePT_Scene-Consistent_Policy-Based_Trajectory_Predictions_for_Planning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_ScePT_Scene-Consistent_Policy-Based_CVPR_2022_supplemental.pdf)
1974. Deep Saliency Prior for Reducing Visual Distraction | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Aberman_Deep_Saliency_Prior_for_Reducing_Visual_Distraction_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Aberman_Deep_Saliency_Prior_for_Reducing_Visual_Distraction_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2109.01980)
1975. Efficient Large-Scale Localization by Global Instance Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Efficient_Large-Scale_Localization_by_Global_Instance_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Efficient_Large-Scale_Localization_by_Global_Instance_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xue_Efficient_Large-Scale_Localization_CVPR_2022_supplemental.pdf)
1976. Spatial Commonsense Graph for Object Localisation in Partial Scenes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Giuliari_Spatial_Commonsense_Graph_for_Object_Localisation_in_Partial_Scenes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Giuliari_Spatial_Commonsense_Graph_for_Object_Localisation_in_Partial_Scenes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Giuliari_Spatial_Commonsense_Graph_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.05380)
1977. Physically-Guided Disentangled Implicit Rendering for 3D Face Modeling | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Physically-Guided_Disentangled_Implicit_Rendering_for_3D_Face_Modeling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Physically-Guided_Disentangled_Implicit_Rendering_for_3D_Face_Modeling_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Physically-Guided_Disentangled_Implicit_CVPR_2022_supplemental.pdf)
1978. M5Product- Self-Harmonized Contrastive Learning for E-Commercial Multi-Modal Pretraining | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_M5Product_Self-Harmonized_Contrastive_Learning_for_E-Commercial_Multi-Modal_Pretraining_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_M5Product_Self-Harmonized_Contrastive_Learning_for_E-Commercial_Multi-Modal_Pretraining_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_M5Product_Self-Harmonized_Contrastive_CVPR_2022_supplemental.pdf)
1979. On Guiding Visual Attention With Language Specification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Petryk_On_Guiding_Visual_Attention_With_Language_Specification_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Petryk_On_Guiding_Visual_Attention_With_Language_Specification_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Petryk_On_Guiding_Visual_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.08926)
1980. ReSTR- Convolution-Free Referring Image Segmentation Using Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_ReSTR_Convolution-Free_Referring_Image_Segmentation_Using_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_ReSTR_Convolution-Free_Referring_Image_Segmentation_Using_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_ReSTR_Convolution-Free_Referring_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16768)
1981. Use All the Labels- A Hierarchical Multi-Label Contrastive Learning Framework | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Use_All_the_Labels_A_Hierarchical_Multi-Label_Contrastive_Learning_Framework_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Use_All_the_Labels_A_Hierarchical_Multi-Label_Contrastive_Learning_Framework_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Use_All_the_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.13207)
1982. SGTR- End-to-End Scene Graph Generation With Transformer | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_SGTR_End-to-End_Scene_Graph_Generation_With_Transformer_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_SGTR_End-to-End_Scene_Graph_Generation_With_Transformer_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_SGTR_End-to-End_Scene_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.12970)
1983. Set-Supervised Action Learning in Procedural Task Videos via Pairwise Order Consistency | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Set-Supervised_Action_Learning_in_Procedural_Task_Videos_via_Pairwise_Order_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Set-Supervised_Action_Learning_in_Procedural_Task_Videos_via_Pairwise_Order_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lu_Set-Supervised_Action_Learning_CVPR_2022_supplemental.pdf)
1984. DeepFusion- Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_DeepFusion_Lidar-Camera_Deep_Fusion_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_DeepFusion_Lidar-Camera_Deep_Fusion_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_DeepFusion_Lidar-Camera_Deep_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08195)
1985. DeepFace-EMD- Re-Ranking Using Patch-Wise Earth Mover's Distance Improves Out-of-Distribution Face Identification | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Phan_DeepFace-EMD_Re-Ranking_Using_Patch-Wise_Earth_Movers_Distance_Improves_Out-of-Distribution_Face_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Phan_DeepFace-EMD_Re-Ranking_Using_Patch-Wise_Earth_Movers_Distance_Improves_Out-of-Distribution_Face_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Phan_DeepFace-EMD_Re-Ranking_Using_CVPR_2022_supplemental.pdf)
1986. General Facial Representation Learning in a Visual-Linguistic Manner | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_General_Facial_Representation_Learning_in_a_Visual-Linguistic_Manner_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_General_Facial_Representation_Learning_in_a_Visual-Linguistic_Manner_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_General_Facial_Representation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.03109)
1987. Improving Segmentation of the Inferior Alveolar Nerve Through Deep Label Propagation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cipriano_Improving_Segmentation_of_the_Inferior_Alveolar_Nerve_Through_Deep_Label_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cipriano_Improving_Segmentation_of_the_Inferior_Alveolar_Nerve_Through_Deep_Label_CVPR_2022_paper.pdf)
1988. Dual-Shutter Optical Vibration Sensing | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sheinin_Dual-Shutter_Optical_Vibration_Sensing_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sheinin_Dual-Shutter_Optical_Vibration_Sensing_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Sheinin_Dual-Shutter_Optical_Vibration_CVPR_2022_supplemental.zip)
1989. Interactiveness Field in Human-Object Interactions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Interactiveness_Field_in_Human-Object_Interactions_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Interactiveness_Field_in_Human-Object_Interactions_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Interactiveness_Field_in_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07718)
1990. Self-Supervised Dense Consistency Regularization for Image-to-Image Translation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ko_Self-Supervised_Dense_Consistency_Regularization_for_Image-to-Image_Translation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ko_Self-Supervised_Dense_Consistency_Regularization_for_Image-to-Image_Translation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ko_Self-Supervised_Dense_Consistency_CVPR_2022_supplemental.pdf)
1991. The Devil Is in the Details- Window-Based Attention for Image Compression | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zou_The_Devil_Is_in_the_Details_Window-Based_Attention_for_Image_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zou_The_Devil_Is_in_the_Details_Window-Based_Attention_for_Image_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zou_The_Devil_Is_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08450)
1992. Category-Aware Transformer Network for Better Human-Object Interaction Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Category-Aware_Transformer_Network_for_Better_Human-Object_Interaction_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Category-Aware_Transformer_Network_for_Better_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_Category-Aware_Transformer_Network_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04911)
1993. LARGE- Latent-Based Regression Through GAN Semantics | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Nitzan_LARGE_Latent-Based_Regression_Through_GAN_Semantics_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Nitzan_LARGE_Latent-Based_Regression_Through_GAN_Semantics_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Nitzan_LARGE_Latent-Based_Regression_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2107.11186)
1994. Are Multimodal Transformers Robust to Missing Modality- | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Are_Multimodal_Transformers_Robust_to_Missing_Modality_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Are_Multimodal_Transformers_Robust_to_Missing_Modality_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.05454)
1995. Fisher Information Guidance for Learned Time-of-Flight Imaging | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Fisher_Information_Guidance_for_Learned_Time-of-Flight_Imaging_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Fisher_Information_Guidance_for_Learned_Time-of-Flight_Imaging_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Fisher_Information_Guidance_CVPR_2022_supplemental.pdf)
1996. VRDFormer- End-to-End Video Visual Relation Detection With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_VRDFormer_End-to-End_Video_Visual_Relation_Detection_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_VRDFormer_End-to-End_Video_Visual_Relation_Detection_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zheng_VRDFormer_End-to-End_Video_CVPR_2022_supplemental.pdf)
1997. CLIPstyler- Image Style Transfer With a Single Text Condition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kwon_CLIPstyler_Image_Style_Transfer_With_a_Single_Text_Condition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kwon_CLIPstyler_Image_Style_Transfer_With_a_Single_Text_Condition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kwon_CLIPstyler_Image_Style_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.00374)
1998. Ray Priors Through Reprojection- Improving Neural Radiance Fields for Novel View Extrapolation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Ray_Priors_Through_Reprojection_Improving_Neural_Radiance_Fields_for_Novel_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Ray_Priors_Through_Reprojection_Improving_Neural_Radiance_Fields_for_Novel_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2205.05922)
1999. Spatio-Temporal Relation Modeling for Few-Shot Action Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Thatipelli_Spatio-Temporal_Relation_Modeling_for_Few-Shot_Action_Recognition_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Thatipelli_Spatio-Temporal_Relation_Modeling_for_Few-Shot_Action_Recognition_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Thatipelli_Spatio-Temporal_Relation_Modeling_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.05132)
2000. Pop-Out Motion- 3D-Aware Image Deformation via Learning the Shape Laplacian | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Pop-Out_Motion_3D-Aware_Image_Deformation_via_Learning_the_Shape_Laplacian_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Pop-Out_Motion_3D-Aware_Image_Deformation_via_Learning_the_Shape_Laplacian_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lee_Pop-Out_Motion_3D-Aware_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15235)
2001. Towards Noiseless Object Contours for Weakly Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Towards_Noiseless_Object_Contours_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_Noiseless_Object_Contours_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Towards_Noiseless_Object_CVPR_2022_supplemental.pdf)
2002. Unsupervised Image-to-Image Translation With Generative Prior | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Unsupervised_Image-to-Image_Translation_With_Generative_Prior_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Unsupervised_Image-to-Image_Translation_With_Generative_Prior_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_Unsupervised_Image-to-Image_Translation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.03641)
2003. Multi-Marginal Contrastive Learning for Multi-Label Subcellular Protein Localization | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Multi-Marginal_Contrastive_Learning_for_Multi-Label_Subcellular_Protein_Localization_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Multi-Marginal_Contrastive_Learning_for_Multi-Label_Subcellular_Protein_Localization_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Multi-Marginal_Contrastive_Learning_CVPR_2022_supplemental.pdf)
2004. Predict, Prevent, and Evaluate- Disentangled Text-Driven Image Manipulation Empowered by Pre-Trained Vision-Language Model | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Predict_Prevent_and_Evaluate_Disentangled_Text-Driven_Image_Manipulation_Empowered_by_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Predict_Prevent_and_Evaluate_Disentangled_Text-Driven_Image_Manipulation_Empowered_by_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Predict_Prevent_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13333)
2005. RU-Net- Regularized Unrolling Network for Scene Graph Generation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lin_RU-Net_Regularized_Unrolling_Network_for_Scene_Graph_Generation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_RU-Net_Regularized_Unrolling_Network_for_Scene_Graph_Generation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lin_RU-Net_Regularized_Unrolling_CVPR_2022_supplemental.pdf)
2006. Integrating Language Guidance Into Vision-Based Deep Metric Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Roth_Integrating_Language_Guidance_Into_Vision-Based_Deep_Metric_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Roth_Integrating_Language_Guidance_Into_Vision-Based_Deep_Metric_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Roth_Integrating_Language_Guidance_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.08543)
2007. PartGlot- Learning Shape Part Segmentation From Language Reference Games | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Koo_PartGlot_Learning_Shape_Part_Segmentation_From_Language_Reference_Games_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Koo_PartGlot_Learning_Shape_Part_Segmentation_From_Language_Reference_Games_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Koo_PartGlot_Learning_Shape_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.06390)
2008. DIVeR- Real-Time and Accurate Neural Radiance Fields With Deterministic Integration for Volume Rendering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wu_DIVeR_Real-Time_and_Accurate_Neural_Radiance_Fields_With_Deterministic_Integration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_DIVeR_Real-Time_and_Accurate_Neural_Radiance_Fields_With_Deterministic_Integration_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wu_DIVeR_Real-Time_and_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.10427)
2009. ContIG- Self-Supervised Multimodal Contrastive Learning for Medical Imaging With Genetics | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Taleb_ContIG_Self-Supervised_Multimodal_Contrastive_Learning_for_Medical_Imaging_With_Genetics_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Taleb_ContIG_Self-Supervised_Multimodal_Contrastive_Learning_for_Medical_Imaging_With_Genetics_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Taleb_ContIG_Self-Supervised_Multimodal_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.13424)
2010. Disentangling Visual and Written Concepts in CLIP | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Materzynska_Disentangling_Visual_and_Written_Concepts_in_CLIP_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Materzynska_Disentangling_Visual_and_Written_Concepts_in_CLIP_CVPR_2022_paper.pdf)
2011. Bilateral Video Magnification Filter | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Takeda_Bilateral_Video_Magnification_Filter_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Takeda_Bilateral_Video_Magnification_Filter_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Takeda_Bilateral_Video_Magnification_CVPR_2022_supplemental.zip)
2012. AdaFocus V2- End-to-End Training of Spatial Dynamic Networks for Video Recognition | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_AdaFocus_V2_End-to-End_Training_of_Spatial_Dynamic_Networks_for_Video_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_AdaFocus_V2_End-to-End_Training_of_Spatial_Dynamic_Networks_for_Video_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_AdaFocus_V2_End-to-End_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.14238)
2013. Neural Mean Discrepancy for Efficient Out-of-Distribution Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Neural_Mean_Discrepancy_for_Efficient_Out-of-Distribution_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Neural_Mean_Discrepancy_for_Efficient_Out-of-Distribution_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Dong_Neural_Mean_Discrepancy_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.11408)
2014. Time Lens++- Event-Based Frame Interpolation With Parametric Non-Linear Flow and Multi-Scale Fusion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Tulyakov_Time_Lens_Event-Based_Frame_Interpolation_With_Parametric_Non-Linear_Flow_and_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Tulyakov_Time_Lens_Event-Based_Frame_Interpolation_With_Parametric_Non-Linear_Flow_and_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Tulyakov_Time_Lens_Event-Based_CVPR_2022_supplemental.pdf)
2015. It Is Okay To Not Be Okay- Overcoming Emotional Bias in Affective Image Captioning by Contrastive Data Collection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mohamed_It_Is_Okay_To_Not_Be_Okay_Overcoming_Emotional_Bias_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mohamed_It_Is_Okay_To_Not_Be_Okay_Overcoming_Emotional_Bias_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mohamed_It_Is_Okay_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.07660)
2016. Neural Global Shutter- Learn To Restore Video From a Rolling Shutter Camera With Global Reset Feature | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Neural_Global_Shutter_Learn_To_Restore_Video_From_a_Rolling_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Neural_Global_Shutter_Learn_To_Restore_Video_From_a_Rolling_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.00974)
2017. DiRA- Discriminative, Restorative, and Adversarial Learning for Self-Supervised Medical Image Analysis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Haghighi_DiRA_Discriminative_Restorative_and_Adversarial_Learning_for_Self-Supervised_Medical_Image_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Haghighi_DiRA_Discriminative_Restorative_and_Adversarial_Learning_for_Self-Supervised_Medical_Image_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Haghighi_DiRA_Discriminative_Restorative_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.10437)
2018. Open Challenges in Deep Stereo- The Booster Dataset | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ramirez_Open_Challenges_in_Deep_Stereo_The_Booster_Dataset_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ramirez_Open_Challenges_in_Deep_Stereo_The_Booster_Dataset_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ramirez_Open_Challenges_in_CVPR_2022_supplemental.pdf)
2019. Self-Supervised Bulk Motion Artifact Removal in Optical Coherence Tomography Angiography | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Self-Supervised_Bulk_Motion_Artifact_Removal_in_Optical_Coherence_Tomography_Angiography_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Self-Supervised_Bulk_Motion_Artifact_Removal_in_Optical_Coherence_Tomography_Angiography_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2202.10360)
2020. PoseTrack21- A Dataset for Person Search, Multi-Object Tracking and Multi-Person Pose Tracking | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Doring_PoseTrack21_A_Dataset_for_Person_Search_Multi-Object_Tracking_and_Multi-Person_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Doring_PoseTrack21_A_Dataset_for_Person_Search_Multi-Object_Tracking_and_Multi-Person_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Doring_PoseTrack21_A_Dataset_CVPR_2022_supplemental.pdf)
2021. Ithaca365- Dataset and Driving Perception Under Repeated and Challenging Weather Conditions | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Diaz-Ruiz_Ithaca365_Dataset_and_Driving_Perception_Under_Repeated_and_Challenging_Weather_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Diaz-Ruiz_Ithaca365_Dataset_and_Driving_Perception_Under_Repeated_and_Challenging_Weather_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Diaz-Ruiz_Ithaca365_Dataset_and_CVPR_2022_supplemental.pdf)
2022. YouMVOS- An Actor-Centric Multi-Shot Video Object Segmentation Dataset | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wei_YouMVOS_An_Actor-Centric_Multi-Shot_Video_Object_Segmentation_Dataset_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_YouMVOS_An_Actor-Centric_Multi-Shot_Video_Object_Segmentation_Dataset_CVPR_2022_paper.pdf)
2023. Rethinking Spatial Invariance of Convolutional Networks for Object Counting | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Rethinking_Spatial_Invariance_of_Convolutional_Networks_for_Object_Counting_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Rethinking_Spatial_Invariance_of_Convolutional_Networks_for_Object_Counting_CVPR_2022_paper.pdf)
2024. Geometric Anchor Correspondence Mining With Uncertainty Modeling for Universal Domain Adaptation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Geometric_Anchor_Correspondence_Mining_With_Uncertainty_Modeling_for_Universal_Domain_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Geometric_Anchor_Correspondence_Mining_With_Uncertainty_Modeling_for_Universal_Domain_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Chen_Geometric_Anchor_Correspondence_CVPR_2022_supplemental.pdf)
2025. Coopernaut- End-to-End Driving With Cooperative Perception for Networked Vehicles | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Cui_Coopernaut_End-to-End_Driving_With_Cooperative_Perception_for_Networked_Vehicles_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Cui_Coopernaut_End-to-End_Driving_With_Cooperative_Perception_for_Networked_Vehicles_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Cui_Coopernaut_End-to-End_Driving_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.02222)
2026. Few-Shot Keypoint Detection With Uncertainty Learning for Unseen Species | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Few-Shot_Keypoint_Detection_With_Uncertainty_Learning_for_Unseen_Species_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Few-Shot_Keypoint_Detection_With_Uncertainty_Learning_for_Unseen_Species_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Lu_Few-Shot_Keypoint_Detection_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.06183)
2027. 3D-SPS- Single-Stage 3D Visual Grounding via Referred Point Progressive Selection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Luo_3D-SPS_Single-Stage_3D_Visual_Grounding_via_Referred_Point_Progressive_Selection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_3D-SPS_Single-Stage_3D_Visual_Grounding_via_Referred_Point_Progressive_Selection_CVPR_2022_paper.pdf)
2028. Learning Multiple Dense Prediction Tasks From Partially Annotated Data | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Learning_Multiple_Dense_Prediction_Tasks_From_Partially_Annotated_Data_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_Multiple_Dense_Prediction_Tasks_From_Partially_Annotated_Data_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Learning_Multiple_Dense_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14893)
2029. Towards Low-Cost and Efficient Malaria Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sultani_Towards_Low-Cost_and_Efficient_Malaria_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sultani_Towards_Low-Cost_and_Efficient_Malaria_Detection_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.13656)
2030. Learning Neural Light Fields With Ray-Space Embedding | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Attal_Learning_Neural_Light_Fields_With_Ray-Space_Embedding_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Attal_Learning_Neural_Light_Fields_With_Ray-Space_Embedding_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Attal_Learning_Neural_Light_CVPR_2022_supplemental.pdf)
2031. Clean Implicit 3D Structure From Noisy 2D STEM Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kniesel_Clean_Implicit_3D_Structure_From_Noisy_2D_STEM_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kniesel_Clean_Implicit_3D_Structure_From_Noisy_2D_STEM_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kniesel_Clean_Implicit_3D_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15434)
2032. UKPGAN- A General Self-Supervised Keypoint Detector | [link](https://openaccess.thecvf.com/content/CVPR2022/html/You_UKPGAN_A_General_Self-Supervised_Keypoint_Detector_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/You_UKPGAN_A_General_Self-Supervised_Keypoint_Detector_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/You_UKPGAN_A_General_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2011.11974)
2033. Learning Optimal K-Space Acquisition and Reconstruction Using Physics-Informed Neural Networks | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Peng_Learning_Optimal_K-Space_Acquisition_and_Reconstruction_Using_Physics-Informed_Neural_Networks_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Learning_Optimal_K-Space_Acquisition_and_Reconstruction_Using_Physics-Informed_Neural_Networks_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Peng_Learning_Optimal_K-Space_CVPR_2022_supplemental.zip)
2034. Raw High-Definition Radar for Multi-Task Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Rebut_Raw_High-Definition_Radar_for_Multi-Task_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Rebut_Raw_High-Definition_Radar_for_Multi-Task_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Rebut_Raw_High-Definition_Radar_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.10646)
2035. Exploring Set Similarity for Dense Self-Supervised Representation Learning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Exploring_Set_Similarity_for_Dense_Self-Supervised_Representation_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Exploring_Set_Similarity_for_Dense_Self-Supervised_Representation_Learning_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2107.08712)
2036. ONCE-3DLanes- Building Monocular 3D Lane Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yan_ONCE-3DLanes_Building_Monocular_3D_Lane_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_ONCE-3DLanes_Building_Monocular_3D_Lane_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yan_ONCE-3DLanes_Building_Monocular_CVPR_2022_supplemental.pdf)
2037. Weakly but Deeply Supervised Occlusion-Reasoned Parametric Road Layouts | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Weakly_but_Deeply_Supervised_Occlusion-Reasoned_Parametric_Road_Layouts_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Weakly_but_Deeply_Supervised_Occlusion-Reasoned_Parametric_Road_Layouts_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Weakly_but_Deeply_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2104.06730)
2038. Modulated Contrast for Versatile Image Synthesis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhan_Modulated_Contrast_for_Versatile_Image_Synthesis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhan_Modulated_Contrast_for_Versatile_Image_Synthesis_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.09333)
2039. Identifying Ambiguous Similarity Conditions via Semantic Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Identifying_Ambiguous_Similarity_Conditions_via_Semantic_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Identifying_Ambiguous_Similarity_Conditions_via_Semantic_Matching_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ye_Identifying_Ambiguous_Similarity_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04053)
2040. MSTR- Multi-Scale Transformer for End-to-End Human-Object Interaction Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_MSTR_Multi-Scale_Transformer_for_End-to-End_Human-Object_Interaction_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_MSTR_Multi-Scale_Transformer_for_End-to-End_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_MSTR_Multi-Scale_Transformer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14709)
2041. DetectorDetective- Investigating the Effects of Adversarial Examples on Object Detectors | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Vellaichamy_DetectorDetective_Investigating_the_Effects_of_Adversarial_Examples_on_Object_Detectors_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Vellaichamy_DetectorDetective_Investigating_the_Effects_of_Adversarial_Examples_on_Object_Detectors_CVPR_2022_paper.pdf)
2042. EMScore- Evaluating Video Captioning via Coarse-Grained and Fine-Grained Embedding Matching | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_EMScore_Evaluating_Video_Captioning_via_Coarse-Grained_and_Fine-Grained_Embedding_Matching_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_EMScore_Evaluating_Video_Captioning_via_Coarse-Grained_and_Fine-Grained_Embedding_Matching_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shi_EMScore_Evaluating_Video_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.08919)
2043. SNR-Aware Low-Light Image Enhancement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_SNR-Aware_Low-Light_Image_Enhancement_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_SNR-Aware_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf)
2044. 3D Common Corruptions and Data Augmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kar_3D_Common_Corruptions_and_Data_Augmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kar_3D_Common_Corruptions_and_Data_Augmentation_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2203.01441)
2045. Injecting Semantic Concepts Into End-to-End Image Captioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Fang_Injecting_Semantic_Concepts_Into_End-to-End_Image_Captioning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_Injecting_Semantic_Concepts_Into_End-to-End_Image_Captioning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Fang_Injecting_Semantic_Concepts_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.05230)
2046. L2G- A Simple Local-to-Global Knowledge Transfer Framework for Weakly Supervised Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_L2G_A_Simple_Local-to-Global_Knowledge_Transfer_Framework_for_Weakly_Supervised_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_L2G_A_Simple_Local-to-Global_Knowledge_Transfer_Framework_for_Weakly_Supervised_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2204.03206)
2047. VL-InterpreT- An Interactive Visualization Tool for Interpreting Vision-Language Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Aflalo_VL-InterpreT_An_Interactive_Visualization_Tool_for_Interpreting_Vision-Language_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Aflalo_VL-InterpreT_An_Interactive_Visualization_Tool_for_Interpreting_Vision-Language_Transformers_CVPR_2022_paper.pdf)
2048. LiDAR Snowfall Simulation for Robust 3D Object Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hahner_LiDAR_Snowfall_Simulation_for_Robust_3D_Object_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hahner_LiDAR_Snowfall_Simulation_for_Robust_3D_Object_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Hahner_LiDAR_Snowfall_Simulation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.15118)
2049. Structural and Statistical Texture Knowledge Distillation for Semantic Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ji_Structural_and_Statistical_Texture_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ji_Structural_and_Statistical_Texture_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.pdf)
2050. Blended Diffusion for Text-Driven Editing of Natural Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Avrahami_Blended_Diffusion_for_Text-Driven_Editing_of_Natural_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Avrahami_Blended_Diffusion_for_Text-Driven_Editing_of_Natural_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Avrahami_Blended_Diffusion_for_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.14818)
2051. BE-STI- Spatial-Temporal Integrated Network for Class-Agnostic Motion Prediction With Bidirectional Enhancement | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Wang_BE-STI_Spatial-Temporal_Integrated_Network_for_Class-Agnostic_Motion_Prediction_With_Bidirectional_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_BE-STI_Spatial-Temporal_Integrated_Network_for_Class-Agnostic_Motion_Prediction_With_Bidirectional_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_BE-STI_Spatial-Temporal_Integrated_CVPR_2022_supplemental.pdf)
2052. A Structured Dictionary Perspective on Implicit Neural Representations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yuce_A_Structured_Dictionary_Perspective_on_Implicit_Neural_Representations_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yuce_A_Structured_Dictionary_Perspective_on_Implicit_Neural_Representations_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yuce_A_Structured_Dictionary_CVPR_2022_supplemental.pdf)
2053. Learning To Answer Questions in Dynamic Audio-Visual Scenarios | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Learning_To_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_To_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Learning_To_Answer_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.14072)
2054. Synthetic Aperture Imaging With Events and Frames | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liao_Synthetic_Aperture_Imaging_With_Events_and_Frames_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Synthetic_Aperture_Imaging_With_Events_and_Frames_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liao_Synthetic_Aperture_Imaging_CVPR_2022_supplemental.pdf)
2055. CLIP-Event- Connecting Text and Images With Event Structures | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_CLIP-Event_Connecting_Text_and_Images_With_Event_Structures_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_CLIP-Event_Connecting_Text_and_Images_With_Event_Structures_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_CLIP-Event_Connecting_Text_CVPR_2022_supplemental.pdf)
2056. Scaling Up Vision-Language Pre-Training for Image Captioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Scaling_Up_Vision-Language_Pre-Training_for_Image_Captioning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Scaling_Up_Vision-Language_Pre-Training_for_Image_Captioning_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.12233)
2057. Unsupervised Action Segmentation by Joint Representation Learning and Online Clustering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kumar_Unsupervised_Action_Segmentation_by_Joint_Representation_Learning_and_Online_Clustering_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kumar_Unsupervised_Action_Segmentation_by_Joint_Representation_Learning_and_Online_Clustering_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kumar_Unsupervised_Action_Segmentation_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2105.13353)
2058. LISA- Learning Implicit Shape and Appearance of Hands | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Corona_LISA_Learning_Implicit_Shape_and_Appearance_of_Hands_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Corona_LISA_Learning_Implicit_Shape_and_Appearance_of_Hands_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Corona_LISA_Learning_Implicit_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.01695)
2059. DiGS- Divergence Guided Shape Implicit Neural Representation for Unoriented Point Clouds | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Ben-Shabat_DiGS_Divergence_Guided_Shape_Implicit_Neural_Representation_for_Unoriented_Point_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Ben-Shabat_DiGS_Divergence_Guided_Shape_Implicit_Neural_Representation_for_Unoriented_Point_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Ben-Shabat_DiGS_Divergence_Guided_CVPR_2022_supplemental.zip)
2060. Semi-Supervised Learning of Semantic Correspondence With Pseudo-Labels | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Semi-Supervised_Learning_of_Semantic_Correspondence_With_Pseudo-Labels_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Semi-Supervised_Learning_of_Semantic_Correspondence_With_Pseudo-Labels_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kim_Semi-Supervised_Learning_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16038)
2061. HLRTF- Hierarchical Low-Rank Tensor Factorization for Inverse Problems in Multi-Dimensional Imaging | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Luo_HLRTF_Hierarchical_Low-Rank_Tensor_Factorization_for_Inverse_Problems_in_Multi-Dimensional_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_HLRTF_Hierarchical_Low-Rank_Tensor_Factorization_for_Inverse_Problems_in_Multi-Dimensional_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Luo_HLRTF_Hierarchical_Low-Rank_CVPR_2022_supplemental.pdf)
2062. FIBA- Frequency-Injection Based Backdoor Attack in Medical Image Analysis | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Feng_FIBA_Frequency-Injection_Based_Backdoor_Attack_in_Medical_Image_Analysis_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_FIBA_Frequency-Injection_Based_Backdoor_Attack_in_Medical_Image_Analysis_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Feng_FIBA_Frequency-Injection_Based_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2112.01148)
2063. Deep Constrained Least Squares for Blind Image Super-Resolution | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Luo_Deep_Constrained_Least_Squares_for_Blind_Image_Super-Resolution_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Deep_Constrained_Least_Squares_for_Blind_Image_Super-Resolution_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Luo_Deep_Constrained_Least_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2202.07508)
2064. Beyond a Pre-Trained Object Detector- Cross-Modal Textual and Visual Context for Image Captioning | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Kuo_Beyond_a_Pre-Trained_Object_Detector_Cross-Modal_Textual_and_Visual_Context_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Kuo_Beyond_a_Pre-Trained_Object_Detector_Cross-Modal_Textual_and_Visual_Context_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Kuo_Beyond_a_Pre-Trained_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.04363)
2065. Symmetry-Aware Neural Architecture for Embodied Visual Exploration | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Symmetry-Aware_Neural_Architecture_for_Embodied_Visual_Exploration_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Symmetry-Aware_Neural_Architecture_for_Embodied_Visual_Exploration_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Symmetry-Aware_Neural_Architecture_CVPR_2022_supplemental.pdf)
2066. From Representation to Reasoning- Towards Both Evidence and Commonsense Reasoning for Video Question-Answering | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Li_From_Representation_to_Reasoning_Towards_Both_Evidence_and_Commonsense_Reasoning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_From_Representation_to_Reasoning_Towards_Both_Evidence_and_Commonsense_Reasoning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_From_Representation_to_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2205.14895)
2067. DanceTrack- Multi-Object Tracking in Uniform Appearance and Diverse Motion | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Sun_DanceTrack_Multi-Object_Tracking_in_Uniform_Appearance_and_Diverse_Motion_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_DanceTrack_Multi-Object_Tracking_in_Uniform_Appearance_and_Diverse_Motion_CVPR_2022_paper.pdf), [arXiv](http://arxiv.org/abs/2111.14690)
2068. Unsupervised Learning of Debiased Representations With Pseudo-Attributes | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Seo_Unsupervised_Learning_of_Debiased_Representations_With_Pseudo-Attributes_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Seo_Unsupervised_Learning_of_Debiased_Representations_With_Pseudo-Attributes_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Seo_Unsupervised_Learning_of_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2108.02943)
2069. TubeDETR- Spatio-Temporal Video Grounding With Transformers | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_TubeDETR_Spatio-Temporal_Video_Grounding_With_Transformers_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_TubeDETR_Spatio-Temporal_Video_Grounding_With_Transformers_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Yang_TubeDETR_Spatio-Temporal_Video_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.16434)
2070. SLIC- Self-Supervised Learning With Iterative Clustering for Human Action Videos | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Khorasgani_SLIC_Self-Supervised_Learning_With_Iterative_Clustering_for_Human_Action_Videos_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Khorasgani_SLIC_Self-Supervised_Learning_With_Iterative_Clustering_for_Human_Action_Videos_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Khorasgani_SLIC_Self-Supervised_Learning_CVPR_2022_supplemental.zip)
2071. UBnormal- New Benchmark for Supervised Open-Set Video Anomaly Detection | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Acsintoae_UBnormal_New_Benchmark_for_Supervised_Open-Set_Video_Anomaly_Detection_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Acsintoae_UBnormal_New_Benchmark_for_Supervised_Open-Set_Video_Anomaly_Detection_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Acsintoae_UBnormal_New_Benchmark_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2111.08644)
2072. Beyond Cross-View Image Retrieval- Highly Accurate Vehicle Localization Using Satellite Image | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Shi_Beyond_Cross-View_Image_Retrieval_Highly_Accurate_Vehicle_Localization_Using_Satellite_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Beyond_Cross-View_Image_Retrieval_Highly_Accurate_Vehicle_Localization_Using_Satellite_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Shi_Beyond_Cross-View_Image_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2204.04752)
2073. Closing the Generalization Gap of Cross-Silo Federated Medical Image Segmentation | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Closing_the_Generalization_Gap_of_Cross-Silo_Federated_Medical_Image_Segmentation_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Closing_the_Generalization_Gap_of_Cross-Silo_Federated_Medical_Image_Segmentation_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xu_Closing_the_Generalization_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.10144)
2074. Leverage Your Local and Global Representations- A New Self-Supervised Learning Strategy | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Leverage_Your_Local_and_Global_Representations_A_New_Self-Supervised_Learning_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Leverage_Your_Local_and_Global_Representations_A_New_Self-Supervised_Learning_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Zhang_Leverage_Your_Local_CVPR_2022_supplemental.pdf), [arXiv](http://arxiv.org/abs/2203.17205)
2075. NeRF in the Dark- High Dynamic Range View Synthesis From Noisy Raw Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Mildenhall_NeRF_in_the_Dark_High_Dynamic_Range_View_Synthesis_From_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Mildenhall_NeRF_in_the_Dark_High_Dynamic_Range_View_Synthesis_From_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Mildenhall_NeRF_in_the_CVPR_2022_supplemental.pdf)
2076. DArch- Dental Arch Prior-Assisted 3D Tooth Instance Segmentation With Weak Annotations | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Qiu_DArch_Dental_Arch_Prior-Assisted_3D_Tooth_Instance_Segmentation_With_Weak_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Qiu_DArch_Dental_Arch_Prior-Assisted_3D_Tooth_Instance_Segmentation_With_Weak_CVPR_2022_paper.pdf)
2077. Globetrotter- Connecting Languages by Connecting Images | [link](https://openaccess.thecvf.com/content/CVPR2022/html/Suris_Globetrotter_Connecting_Languages_by_Connecting_Images_CVPR_2022_paper.html), [pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Suris_Globetrotter_Connecting_Languages_by_Connecting_Images_CVPR_2022_paper.pdf), [supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Suris_Globetrotter_Connecting_Languages_CVPR_2022_supplemental.pdf)